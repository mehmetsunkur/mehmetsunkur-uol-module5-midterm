[
    {
        "element_id": "0118932348ae6115b6d8bd2163ca94a9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        316.6,
                        23.4
                    ],
                    [
                        316.6,
                        46.6
                    ],
                    [
                        1510.0,
                        46.6
                    ],
                    [
                        1510.0,
                        23.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79017,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1
        },
        "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "type": "Header"
    },
    {
        "element_id": "af9f3a21c21692e3fea53756b5d78d7d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        85.1
                    ],
                    [
                        136.0,
                        104.6
                    ],
                    [
                        816.0,
                        104.6
                    ],
                    [
                        816.0,
                        85.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80231,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "0118932348ae6115b6d8bd2163ca94a9"
        },
        "text": "IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS",
        "type": "NarrativeText"
    },
    {
        "element_id": "3f883452e4c67a8a9a4c223582949b5d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        149.5,
                        165.3
                    ],
                    [
                        149.5,
                        309.2
                    ],
                    [
                        1544.9,
                        309.2
                    ],
                    [
                        1544.9,
                        165.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.71505,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "0118932348ae6115b6d8bd2163ca94a9"
        },
        "text": "Boosting Reinforcement Learning via Hierarchical Game Playing With State Relay",
        "type": "Title"
    },
    {
        "element_id": "75fdbb344b9151d799ffec6e3e302994",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        162.0,
                        350.9
                    ],
                    [
                        162.0,
                        382.1
                    ],
                    [
                        1534.8,
                        382.1
                    ],
                    [
                        1534.8,
                        350.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81574,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "3f883452e4c67a8a9a4c223582949b5d"
        },
        "text": "Chanjuan Liu , Member, IEEE, Jinmiao Cong, Guangyuan Liu, Guifei Jiang, Xirong Xu, and Enqiang Zhu",
        "type": "NarrativeText"
    },
    {
        "element_id": "05abfcc6bf085385a81768cdacac9ab6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        132.5,
                        471.2
                    ],
                    [
                        132.5,
                        1105.0
                    ],
                    [
                        836.4,
                        1105.0
                    ],
                    [
                        836.4,
                        471.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94947,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "3f883452e4c67a8a9a4c223582949b5d"
        },
        "text": "Abstract\u2014 Due to its wide application, deep reinforcement learning (DRL) has been extensively studied in the motion planning community in recent years. However, in the current DRL research, regardless of task completion, the state infor- mation of the agent will be reset afterward. This leads to a low sample utilization rate and hinders further explorations of the environment. Moreover, in the initial training stage, the agent has a weak learning ability in general, which affects the training efficiency in complex tasks. In this study, a new hierarchical reinforcement learning (HRL) framework dubbed hierarchical learning based on game playing with state relay (HGR) is proposed. In particular, we introduce an auxiliary penalty to regulate task difficulty, and one training mechanism, the state relay mechanism, is designed. The relay mechanism can make full use of the intermediate states of the agent and expand the environment exploration of low-level policy. Our algorithm can improve the sample utilization rate, reduce the sparse reward problem, and thereby enhance the training performance in complex environments. Simulation tests are carried out on two public experiment platforms, i.e., MazeBase and MuJoCo, to verify the effectiveness of the proposed method. The results show that HGR significantly benefits the reinforcement learning (RL) area.",
        "type": "NarrativeText"
    },
    {
        "element_id": "6efadce36df26be455e8b9b40ad7af16",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        131.8,
                        1123.0
                    ],
                    [
                        131.8,
                        1175.6
                    ],
                    [
                        833.4,
                        1175.6
                    ],
                    [
                        833.4,
                        1123.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89279,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "3f883452e4c67a8a9a4c223582949b5d"
        },
        "text": "Index Terms\u2014 Curse of dimensionality, game theory, hierar- chical reinforcement learning (HRL), sampling efficiency.",
        "type": "NarrativeText"
    },
    {
        "element_id": "590d42a0eeff3c215565047009a20930",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        469.2
                    ],
                    [
                        866.6,
                        828.9
                    ],
                    [
                        1568.9,
                        828.9
                    ],
                    [
                        1568.9,
                        469.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95699,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "3f883452e4c67a8a9a4c223582949b5d"
        },
        "text": "One advantage of DRL for agents is that the agents do not obsess over the state of the environment itself but rather adjust their policies according to the reward feedback of the envi- ronment. Then, the goal is achieved by learning the policies. Therefore, an important issue of reinforcement learning (RL) is to design an appropriate reward function. In actual applica- tions, it is difficult for the agents to obtain enough effective rewards, or the rewards are sparse, leading to slow and even ineffective learning. Coupled with the large combination of state and action space, the curse of dimensionality has always been a problem in DRL.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9824a57c2e5c7ce7ff49875b8e5535c6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        865.3,
                        861.1
                    ],
                    [
                        865.3,
                        888.8
                    ],
                    [
                        1275.3,
                        888.8
                    ],
                    [
                        1275.3,
                        861.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.61508,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "3f883452e4c67a8a9a4c223582949b5d"
        },
        "text": "B. Related Work and the Challenge",
        "type": "NarrativeText"
    },
    {
        "element_id": "5a2c6f9753c8966f3a1a1d69de3522ff",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        898.1
                    ],
                    [
                        866.6,
                        1225.6
                    ],
                    [
                        1568.2,
                        1225.6
                    ],
                    [
                        1568.2,
                        898.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95499,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "3f883452e4c67a8a9a4c223582949b5d"
        },
        "text": "Since the 1990s, hierarchical reinforcement learning (HRL) [7], [8], [9] has gained increasing attention, driven by the advancements in deep learning and neural networks. HRL solves complex tasks using hierarchical decompositions, pro- viding a feasible solution for the curse of dimensionality and sparse rewards. HRL involves high-level policies that learn to select appropriate subtargets, and then low-level policies implement corresponding actions [10]. In general, HRL can be classified into two main categories based on training methods: hierarchical training and end-to-end training.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d0ed64ab2de75947467bf37c4b79cf18",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        372.0,
                        1233.0
                    ],
                    [
                        372.0,
                        1260.7
                    ],
                    [
                        597.3,
                        1260.7
                    ],
                    [
                        597.3,
                        1233.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.54556,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "0118932348ae6115b6d8bd2163ca94a9"
        },
        "text": "I. INTRODUCTION",
        "type": "Title"
    },
    {
        "element_id": "c765d9eee0d1316793e1974681a029cc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.0,
                        1278.4
                    ],
                    [
                        135.0,
                        1306.0
                    ],
                    [
                        307.7,
                        1306.0
                    ],
                    [
                        307.7,
                        1278.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.78716,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "d0ed64ab2de75947467bf37c4b79cf18"
        },
        "text": "A. Background",
        "type": "NarrativeText"
    },
    {
        "element_id": "0d0d0c08e76b5c8ea5a582ec6a27fd6c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1317.0
                    ],
                    [
                        136.0,
                        1518.5
                    ],
                    [
                        834.6,
                        1518.5
                    ],
                    [
                        834.6,
                        1317.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95012,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "d0ed64ab2de75947467bf37c4b79cf18"
        },
        "text": "T HE development of deep reinforcement learning (DRL) [1] has brought about a new era of artificial intelligence. Through DRL, agents can handle a variety of problems faster and better than humans, such as motion planning [2], obstacle avoidance [3], [4], game playing [5], and autonomous driving [6].",
        "type": "NarrativeText"
    },
    {
        "element_id": "46be703032aefda14855aa29563bcb93",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1552.7
                    ],
                    [
                        136.0,
                        1698.9
                    ],
                    [
                        833.4,
                        1698.9
                    ],
                    [
                        833.4,
                        1552.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93751,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "d0ed64ab2de75947467bf37c4b79cf18"
        },
        "text": "Manuscript received 10 October 2022; revised 13 September 2023 and 13 January 2024; accepted 30 March 2024. This work was supported in part by the National Key Research and Program of China under Grant 2021ZD0112400; and in part by the National Natural Science Founda- tion of China under Grant 62172072, Grant 62272115, and Grant U1908214. (Corresponding author: Enqiang Zhu.)",
        "type": "NarrativeText"
    },
    {
        "element_id": "4efd8e5158e07d8b8d4c1c966c585666",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1702.2
                    ],
                    [
                        136.0,
                        1774.2
                    ],
                    [
                        837.2,
                        1774.2
                    ],
                    [
                        837.2,
                        1702.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92515,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "d0ed64ab2de75947467bf37c4b79cf18"
        },
        "text": "Chanjuan Liu is with the Cancer Hospital of Dalian University of Tech- nology, School of Computer Science and Technology, Dalian University of Technology, Dalian 116024, China (e-mail: chanjuanliu@dlut.edu.cn).",
        "type": "NarrativeText"
    },
    {
        "element_id": "5d0a6d6a59cb4c3524c6bd0dac365145",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1776.9
                    ],
                    [
                        136.0,
                        1873.8
                    ],
                    [
                        838.2,
                        1873.8
                    ],
                    [
                        838.2,
                        1776.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93258,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "d0ed64ab2de75947467bf37c4b79cf18"
        },
        "text": "Jinmiao Cong, Guangyuan Liu, and Xirong Xu are with the School of Computer Science and Technology, Dalian University of Technology, Dalian 116024, China (e-mail: cjm111@mail.dlut.edu.cn; lgy_graduate@163.com; xirongxu@dlut.edu.cn).",
        "type": "NarrativeText"
    },
    {
        "element_id": "84709245700a03d29855ac94f8c76548",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1876.3
                    ],
                    [
                        136.0,
                        1923.6
                    ],
                    [
                        833.4,
                        1923.6
                    ],
                    [
                        833.4,
                        1876.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91058,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "d0ed64ab2de75947467bf37c4b79cf18"
        },
        "text": "Guifei Jiang is with the College of Software, Nankai University, Tianjin 300350, China (e-mail: G.Jiang@nankai.edu.cn).",
        "type": "NarrativeText"
    },
    {
        "element_id": "eb18c4de428d22cbcfbed5275d2a3d51",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1926.4
                    ],
                    [
                        136.0,
                        1998.3
                    ],
                    [
                        833.6,
                        1998.3
                    ],
                    [
                        833.6,
                        1926.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91035,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "d0ed64ab2de75947467bf37c4b79cf18"
        },
        "text": "Enqiang Zhu is with the Institute of Computing Science Technology, Guangzhou University, Guangzhou 510006, China (e-mail: zhuenqiang@gzhu.edu.cn). and",
        "type": "NarrativeText"
    },
    {
        "element_id": "9333038e593c872b9c0c4ddaba96980a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        152.5,
                        2000.9
                    ],
                    [
                        152.5,
                        2023.2
                    ],
                    [
                        664.8,
                        2023.2
                    ],
                    [
                        664.8,
                        2000.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.78877,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "d0ed64ab2de75947467bf37c4b79cf18"
        },
        "text": "Digital Object Identifier 10.1109/TNNLS.2024.3386717",
        "type": "NarrativeText"
    },
    {
        "element_id": "8a124364ebcc58e93919eb6dc2a340fc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1231.1
                    ],
                    [
                        866.6,
                        1857.9
                    ],
                    [
                        1567.7,
                        1857.9
                    ],
                    [
                        1567.7,
                        1231.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95074,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "d0ed64ab2de75947467bf37c4b79cf18"
        },
        "text": "Hierarchical training HRL trains the model in a hierarchical manner, which decomposes the learning tasks into multiple levels, with each level responsible for addressing different abstract levels of the task. Kulkarni et al. [11] proposed a two-layer hierarchical deep Q-learning (H-DQN) model that can solve the issue of sparse rewards in deep Q-networks (DQNs) [12]. On the other hand, Vezhnevets et al. [13] applied feUdal networks to HRL, which consists of a manager module and a worker module, to address the long-standing problems of credit distribution and sparse rewards. Both these methods are particularly effective for playing the Montezuma\u2019s revenge game on Atari. To improve its generalizability across similar tasks, Florensa et al. [14] proposed a skill-based stochastic neural network, namely, stochastic neural networks for HRL (SNN4HRL). This model combines two training processes: an unsupervised process for learning many skills using proxy rewards and a small amount of expert domain knowledge and a high-level training process that encapsulates the learned skills for reuse in future tasks.",
        "type": "NarrativeText"
    },
    {
        "element_id": "0951d573da90c069310f1956f078e637",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1863.5
                    ],
                    [
                        866.6,
                        2024.4
                    ],
                    [
                        1565.2,
                        2024.4
                    ],
                    [
                        1565.2,
                        1863.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93752,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "d0ed64ab2de75947467bf37c4b79cf18"
        },
        "text": "There are also some studies on end-to-end training HRL. In [15], [16], and [17], hindsight action and goal transitions were used to enable the agent to learn multiple policies simultaneously. This approach addressed the problems of sparse rewards and instability in parallel training of multilayer",
        "type": "NarrativeText"
    },
    {
        "element_id": "36bb5fe5909f93c2a217c9b79b3685bd",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        334.1,
                        2040.5
                    ],
                    [
                        334.1,
                        2088.6
                    ],
                    [
                        1367.0,
                        2088.6
                    ],
                    [
                        1367.0,
                        2040.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.54793,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "d0ed64ab2de75947467bf37c4b79cf18"
        },
        "text": "2162-237X \u00a9 2024 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c8a12667ec59c61e5d69060407c1ade3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.7
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82647,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1,
            "parent_id": "d0ed64ab2de75947467bf37c4b79cf18"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:23:24 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "fe49a4924aba88b8eaee9e7ca95d6a27",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1551.9,
                        83.7
                    ],
                    [
                        1551.9,
                        105.3
                    ],
                    [
                        1566.0,
                        105.3
                    ],
                    [
                        1566.0,
                        83.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72525,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 1
        },
        "text": "1",
        "type": "Header"
    },
    {
        "element_id": "08c69431e4dbfee363bf4d2dbc73b6c1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        318.0,
                        25.8
                    ],
                    [
                        318.0,
                        46.2
                    ],
                    [
                        1510.0,
                        46.2
                    ],
                    [
                        1510.0,
                        25.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81203,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2
        },
        "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "type": "Header"
    },
    {
        "element_id": "15fdc8efcec8e5cf3b85f401a0510b1d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.7,
                        84.4
                    ],
                    [
                        134.7,
                        105.4
                    ],
                    [
                        147.6,
                        105.4
                    ],
                    [
                        147.6,
                        84.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74401,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2
        },
        "text": "2",
        "type": "Header"
    },
    {
        "element_id": "89578c8015604e641741dfd9893cf9b9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        885.8,
                        85.0
                    ],
                    [
                        885.8,
                        104.6
                    ],
                    [
                        1565.1,
                        104.6
                    ],
                    [
                        1565.1,
                        85.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.62866,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2,
            "parent_id": "15fdc8efcec8e5cf3b85f401a0510b1d"
        },
        "text": "IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS",
        "type": "NarrativeText"
    },
    {
        "element_id": "eb36d1961c4e2875d6a92b4160ac9e55",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        161.7
                    ],
                    [
                        136.0,
                        521.9
                    ],
                    [
                        833.4,
                        521.9
                    ],
                    [
                        833.4,
                        161.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95573,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2,
            "parent_id": "15fdc8efcec8e5cf3b85f401a0510b1d"
        },
        "text": "policies. In [18] and [19], subgoal discovery was used to find appropriate subgoals. However, they often encountered train- ing inefficiency as the goal space was vast. Discovering useful goals in a large space poses challenges for both high-level subgoal generation and low-level policy learning. To alleviate the problem of a vast goal space, Zhang et al. [20] proposed restricting the high-level action space from the whole goal space to a k-step adjacent region of the current state using an adjacency constraint. By doing so, the agent can gradually learn suitable policies based on effective subgoals proposed by the high level.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9fe4145944b071b39c0ab905e203a750",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        527.5
                    ],
                    [
                        136.0,
                        1089.2
                    ],
                    [
                        837.3,
                        1089.2
                    ],
                    [
                        837.3,
                        527.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94749,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2,
            "parent_id": "15fdc8efcec8e5cf3b85f401a0510b1d"
        },
        "text": "Each of the current HRL algorithms has its advantages, yet most algorithms are limited to specific environments and have poor generalization capabilities. To this end, game theory [21], [22], [23] has been continuously applied to RL algorithms to improve their performance in different sce- narios [24]. One example is self-play, which has achieved excellent performances in checkers [25], TD-gammon [26], and Go [27], [28]. To address the issue of low sample efficiency in model-free RL, Sukhbaatar et al. [29] carried out unsupervised agent training with intrinsic motivation and automatic curriculum learning via self-play, which enabled the agent to explore the environment autonomously and make continuous improvements. Sukhbaatar et al. porated the unsupervised method of [29] into HRL and incor- proposed an asymmetrical self-play learning method, called hierarchical self-play (HSP) [30], to improve the algorithm\u2019s performance.",
        "type": "NarrativeText"
    },
    {
        "element_id": "57a4208c321a3f1be6a51eb979266f85",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        978.3,
                        150.2
                    ],
                    [
                        978.3,
                        358.3
                    ],
                    [
                        1452.3,
                        358.3
                    ],
                    [
                        1452.3,
                        150.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-2-1.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2
        },
        "text": "State Reward Agent Action NN",
        "type": "Image"
    },
    {
        "element_id": "e3a2b8e4854a4ca073bb6341454656ff",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        389.9
                    ],
                    [
                        866.6,
                        413.8
                    ],
                    [
                        1059.4,
                        413.8
                    ],
                    [
                        1059.4,
                        389.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.68056,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2
        },
        "text": "Fig. 1. RL process.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9205f78903e2653551b1880458193356",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        458.6
                    ],
                    [
                        866.6,
                        1050.8
                    ],
                    [
                        1566.7,
                        1050.8
                    ],
                    [
                        1566.7,
                        458.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94919,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2
        },
        "text": "long period of trial and error. This leads to a low sample utilization rate and a long training process. To overcome this, two game-playing agents, A and B, are introduced in low-level policy training. Agent A is responsible for proposing tasks, and agent B completes them. Rewards are given to either agent A or B. Through this competitive reward structure, agent A will continuously propose new tasks that have not been explored to ensure task diversity. Then, a maximum step length is set for the tasks such that it covers all the tasks of a given difficulty in the entire environment. However, if agent A continues proposing difficult tasks that agent B cannot complete, the training will be meaningless. To prevent this, we introduce an auxiliary penalty: agent A will be penalized in the above-mentioned case (e.g., if A proposes four tasks that B cannot complete continuously, it will be punished \u22122 or more. Details can be found in Section III-A). Through receiving this penalty feedback, A will be able to adjust the difficulty of the tasks it proposes actively.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9de6c27655142488231b81bc1dde102c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1094.7
                    ],
                    [
                        136.0,
                        1454.5
                    ],
                    [
                        837.3,
                        1454.5
                    ],
                    [
                        837.3,
                        1094.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95618,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2
        },
        "text": "However, in the current game-based HRL algorithms, when an agent works on a task during the game, regardless of task completion, the environment state in which the agent is situated will be reset afterward. As a result, much of the state information is lost, leading to a low sample utilization rate and hindering further explorations of the environment. Moreover, in the initial pretraining stage, the agent generally has a weak learning ability and can only complete simple tasks. As a result, if the agent responsible for task allocation assigns a difficult task, it may adversely affect the training efficiency and effectiveness.",
        "type": "NarrativeText"
    },
    {
        "element_id": "0832c2a6fc93d6cf93021f5080ed0105",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1056.4
                    ],
                    [
                        866.6,
                        1283.3
                    ],
                    [
                        1567.8,
                        1283.3
                    ],
                    [
                        1567.8,
                        1056.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95252,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2
        },
        "text": "To better explore the environment, a state relay mechanism is adopted. If agent B successfully completes the training task, the current state will temporarily be retained rather than reset. By doing so, the agent can continue exploring new tasks. Thus, the scope of environmental exploration is expanded, and the agent\u2019s ability to complete tasks is enhanced.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f9acacd7902ffdc4aabe0983230b17b3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1288.8
                    ],
                    [
                        866.6,
                        1449.3
                    ],
                    [
                        1565.4,
                        1449.3
                    ],
                    [
                        1565.4,
                        1288.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94753,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2
        },
        "text": "Our method was tested on two complex environments, including AntGather, to illustrate its effectiveness. The results indicate that our proposed algorithm can bolster the performance of the existing motion planning HRL algorithms.",
        "type": "NarrativeText"
    },
    {
        "element_id": "5c4f18f3cb65f4734d4c1c7d7716932d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1514.8
                    ],
                    [
                        136.0,
                        1542.5
                    ],
                    [
                        369.2,
                        1542.5
                    ],
                    [
                        369.2,
                        1514.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.69832,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2
        },
        "text": "C. Our Contribution",
        "type": "Title"
    },
    {
        "element_id": "07b6512be367e35a4b209bb00d414fbb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        865.8,
                        1497.6
                    ],
                    [
                        865.8,
                        1525.3
                    ],
                    [
                        1225.2,
                        1525.3
                    ],
                    [
                        1225.2,
                        1497.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.57754,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2
        },
        "text": "D. Organization of This Article",
        "type": "Title"
    },
    {
        "element_id": "60e7bbac07609316948304f01adb4922",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1561.3
                    ],
                    [
                        136.0,
                        1655.4
                    ],
                    [
                        834.8,
                        1655.4
                    ],
                    [
                        834.8,
                        1561.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93349,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2,
            "parent_id": "07b6512be367e35a4b209bb00d414fbb"
        },
        "text": "To solve the aforementioned problems in game-based HRL, an HRL algorithm based on game playing with the mechanism of state relay (HGR) is proposed in this work.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3cfe9eacaa8db5f892704ed3534794c0",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1660.9
                    ],
                    [
                        136.0,
                        1987.9
                    ],
                    [
                        836.3,
                        1987.9
                    ],
                    [
                        836.3,
                        1660.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95556,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2,
            "parent_id": "07b6512be367e35a4b209bb00d414fbb"
        },
        "text": "Our algorithm comprises two distinct stages of training: low-level training and high-level training. The low-level train- ing is a pretraining stage. During the pretraining stage, the policies are trained to explore and familiarize the environment through games. The second training is a fine-tuning stage, in which the high-level policies aim to propose subgoals for the low-level policies. We use a backpropagation (BP) [31] network to model the high-level policies and error BP is used during the training process to correct the model and speed up loss function convergence.",
        "type": "NarrativeText"
    },
    {
        "element_id": "eedac57bd69a3b976958233003ae7159",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1993.4
                    ],
                    [
                        136.0,
                        2087.5
                    ],
                    [
                        833.4,
                        2087.5
                    ],
                    [
                        833.4,
                        1993.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92998,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2,
            "parent_id": "07b6512be367e35a4b209bb00d414fbb"
        },
        "text": "In the pretraining stage, low-level policies are unfamiliar to the environment before the training of high-level policies. The agents need to understand the environment through a",
        "type": "NarrativeText"
    },
    {
        "element_id": "3b7bd540d8661a7b75f12aa9d708301c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1540.2
                    ],
                    [
                        866.6,
                        1733.9
                    ],
                    [
                        1565.2,
                        1733.9
                    ],
                    [
                        1565.2,
                        1540.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95265,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2,
            "parent_id": "07b6512be367e35a4b209bb00d414fbb"
        },
        "text": "The rest of this article is organized as follows. Section II presents the preliminaries of RL, followed by an introduction of the proposed method in Section III. Section IV describes the experimental environment and comparatively analyzes the experimental results. Finally, Section V concludes this article and presents future research directions.",
        "type": "NarrativeText"
    },
    {
        "element_id": "44f4a197527a572517ba412e645ff795",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1098.4,
                        1776.6
                    ],
                    [
                        1098.4,
                        1804.3
                    ],
                    [
                        1331.4,
                        1804.3
                    ],
                    [
                        1331.4,
                        1776.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80556,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2
        },
        "text": "II. PRELIMINARIES",
        "type": "Title"
    },
    {
        "element_id": "32cee28032d584538187b3fabb29cfc8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        862.6,
                        1817.9
                    ],
                    [
                        862.6,
                        1845.6
                    ],
                    [
                        1175.9,
                        1845.6
                    ],
                    [
                        1175.9,
                        1817.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80038,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2,
            "parent_id": "44f4a197527a572517ba412e645ff795"
        },
        "text": "A. Reinforcement Learning",
        "type": "NarrativeText"
    },
    {
        "element_id": "722e2f4ae8c2fadb445fa9c736eedfc4",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1860.6
                    ],
                    [
                        866.6,
                        1921.5
                    ],
                    [
                        1564.0,
                        1921.5
                    ],
                    [
                        1564.0,
                        1860.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87287,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2,
            "parent_id": "44f4a197527a572517ba412e645ff795"
        },
        "text": "As shown in Fig. 1, RL [32], [33], [34] refers to the continuous interaction between the agent and the environment.",
        "type": "NarrativeText"
    },
    {
        "element_id": "87754dc79aad8e404fbb87a3d2550b02",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.4,
                        1927.0
                    ],
                    [
                        866.4,
                        2087.5
                    ],
                    [
                        1564.0,
                        2087.5
                    ],
                    [
                        1564.0,
                        1927.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93009,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2,
            "parent_id": "44f4a197527a572517ba412e645ff795"
        },
        "text": "Through continuous trial and error, the agent adjusts its next action based on the reward for each interaction. The goal of RL is to learn a reward maximization policy \u03c0 for a given Markov decision process (MDP). Generally, a five- tuple \u27e8S, A, P, R, \u03b3 \u27e9 is used to describe the MDP process,",
        "type": "NarrativeText"
    },
    {
        "element_id": "1d015849279bccdb2dee2d029a74d6e1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.4
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79469,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 2,
            "parent_id": "44f4a197527a572517ba412e645ff795"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:23:24 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "51726cb927320add9835a67af074dec6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        320.7,
                        25.6
                    ],
                    [
                        320.7,
                        46.1
                    ],
                    [
                        1510.0,
                        46.1
                    ],
                    [
                        1510.0,
                        25.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82158,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3
        },
        "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "type": "Header"
    },
    {
        "element_id": "b586bb00ead1b3e683908f86304bdca6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.9,
                        84.8
                    ],
                    [
                        135.9,
                        104.6
                    ],
                    [
                        1136.6,
                        104.6
                    ],
                    [
                        1136.6,
                        84.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84492,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3,
            "parent_id": "51726cb927320add9835a67af074dec6"
        },
        "text": "LIU et al.: BOOSTING REINFORCEMENT LEARNING VIA HIERARCHICAL GAME PLAYING WITH STATE RELAY",
        "type": "NarrativeText"
    },
    {
        "element_id": "774dd95f160fde963ce667d93f9bf77c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        251.0,
                        144.9
                    ],
                    [
                        251.0,
                        662.3
                    ],
                    [
                        1432.9,
                        662.3
                    ],
                    [
                        1432.9,
                        144.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91403,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-3-2.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3
        },
        "text": "Environment a series of actions intrinsic rewards intrinsic rewards Agent Student a series of actions goal Environment Agent Teacher S1.g ST reas J \u201cAgent Agent Student Student task results rewards Environment () (a) \u00a9)",
        "type": "Image"
    },
    {
        "element_id": "f7d1c54062a824139c4bdf2edb4a9333",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        689.8
                    ],
                    [
                        136.0,
                        711.9
                    ],
                    [
                        901.5,
                        711.9
                    ],
                    [
                        901.5,
                        689.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87039,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3
        },
        "text": "Fig. 2. Algorithm framework diagram. (a) Pretraining stage. (b) Fine-tuning stage.",
        "type": "FigureCaption"
    },
    {
        "element_id": "274662c807880f84af2961266638c8e3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        757.1
                    ],
                    [
                        136.0,
                        918.7
                    ],
                    [
                        835.4,
                        918.7
                    ],
                    [
                        835.4,
                        757.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94965,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3
        },
        "text": "where S is a finite set of states, A represents a finite set of actions, P denotes the probability of a state transition, R is a reward function, and \u03b3 is a discount factor used to calculate accumulated rewards. Through repeated interactions with the environment, the agent will gradually learn an optimal policy.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9a0775e4b4318efc9af9ba620fa54a8e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        969.2
                    ],
                    [
                        136.0,
                        996.8
                    ],
                    [
                        594.5,
                        996.8
                    ],
                    [
                        594.5,
                        969.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.48903,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3
        },
        "text": "B. Hierarchical Reinforcement Learning",
        "type": "NarrativeText"
    },
    {
        "element_id": "d22f5609d1b0281d8be4a19139c666c8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        757.7
                    ],
                    [
                        866.6,
                        1017.9
                    ],
                    [
                        1566.1,
                        1017.9
                    ],
                    [
                        1566.1,
                        757.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95574,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3
        },
        "text": "the environment state is reset to its initial state, and student begins to perform actions. The environment state is eventually transitioned to state sStu after student acts. If sStu is very close to s\u2217, student will receive an appropriate reward, and monitor receives no reward. Otherwise, student receives no reward, and monitor receives an appropriate reward. Through games playing with the monitor, the student can gradually explore and familiarize itself with the environment.",
        "type": "NarrativeText"
    },
    {
        "element_id": "42f3026c3d114089602f3a4066f59a17",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1012.5
                    ],
                    [
                        136.0,
                        1239.9
                    ],
                    [
                        834.5,
                        1239.9
                    ],
                    [
                        834.5,
                        1012.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95543,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3
        },
        "text": "In classic RL, an agent\u2019s policy is optimized based on the reward obtained through continuous interaction. However, when the environment is complicated, the state space grows exponentially. This situation is the so-called curse of dimen- sionality. As a branch of RL, HRL [35], [36] divides a complex environment into several subtasks, and by solving each of the subproblems, the complex problem is finally solved.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a7450ded6a34c41fb02caa05ea406024",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1245.5
                    ],
                    [
                        136.0,
                        1439.6
                    ],
                    [
                        837.1,
                        1439.6
                    ],
                    [
                        837.1,
                        1245.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95554,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3
        },
        "text": "Therefore, HRL has a high learning efficiency, avoids the curse of dimensionality, and solves the problem of a large state-action space. Moreover, it has better generalization ability compared with standard RL. However, HRL faces some challenges [37], such as policy instability, additional hyperparameters, and low sampling efficiency.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c8479e371ac55bc88c58344dcdf9f433",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1023.4
                    ],
                    [
                        866.6,
                        1449.6
                    ],
                    [
                        1568.1,
                        1449.6
                    ],
                    [
                        1568.1,
                        1023.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95206,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3
        },
        "text": "In the high-level fine-tuning stage, an additional agent teacher is included alongside student. Teacher proposes sub- goals to guide student\u2019s learning. After the pretraining stage, student is already familiar with the environment and has the ability to complete some tasks. Therefore, student is more likely to achieve the subgoals proposed by teacher. As shown in Fig. 2(b), teacher proposes a new subgoal g every TTea time steps. When the environment state is at si , i \u2208 [1, 2, . . . , TTea], student attempts to complete the subgoal g. Based on the results of Student in achieving the subgoal, teacher contin- uously fine-tunes the subgoal tasks such that student learns toward the target. Details of the pretraining and fine-tuning stages are presented below.",
        "type": "NarrativeText"
    },
    {
        "element_id": "6faa54a1bdec9bf2290000fce0176ab9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        323.7,
                        1485.0
                    ],
                    [
                        323.7,
                        1512.6
                    ],
                    [
                        645.1,
                        1512.6
                    ],
                    [
                        645.1,
                        1485.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83629,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3
        },
        "text": "III. MODEL AND METHOD",
        "type": "Title"
    },
    {
        "element_id": "90fea127c0408f34cf37df3eb8aca739",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.8,
                        1528.5
                    ],
                    [
                        135.8,
                        1755.4
                    ],
                    [
                        835.9,
                        1755.4
                    ],
                    [
                        835.9,
                        1528.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95436,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3,
            "parent_id": "6faa54a1bdec9bf2290000fce0176ab9"
        },
        "text": "To solve the problem stated in Section I-B, an HGR is pro- posed in this work. In contrast to the traditional RL algorithms, the state relay mechanism is adopted in the game-playing process to temporarily retain the state information rather than resetting it after a task has been finished. Moreover, an auxiliary penalty is introduced to regulate the difficulty of tasks.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d8bc40a28917248606c79a0dd95cbdf3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1761.0
                    ],
                    [
                        136.0,
                        1921.5
                    ],
                    [
                        836.0,
                        1921.5
                    ],
                    [
                        836.0,
                        1761.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94014,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3,
            "parent_id": "6faa54a1bdec9bf2290000fce0176ab9"
        },
        "text": "As Fig. 2 shows, the HGR contains two stages: the pre- training stage and the fine-tuning stage. The pretraining stage trains agent Student to explore the environment at a low level. The fine-tuning stage proposes subgoals for guiding Student\u2019s learning at a high level.",
        "type": "NarrativeText"
    },
    {
        "element_id": "dc39ca788847f3831c42383d0307231c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1513.9
                    ],
                    [
                        866.6,
                        1541.6
                    ],
                    [
                        1101.9,
                        1541.6
                    ],
                    [
                        1101.9,
                        1513.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.70581,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3
        },
        "text": "A. Pretraining Stage",
        "type": "Title"
    },
    {
        "element_id": "3e23b8ea3c324199f5055e2496cd072b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1561.7
                    ],
                    [
                        866.6,
                        1954.7
                    ],
                    [
                        1568.4,
                        1954.7
                    ],
                    [
                        1568.4,
                        1561.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95309,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3,
            "parent_id": "dc39ca788847f3831c42383d0307231c"
        },
        "text": "Pretraining is performed via unsupervised training. Through the competitive game between monitor and student, the agent student can quickly become familiar with the environment. In the games, the monitor is responsible for proposing tasks; that is, the monitor first executes numerous actions, and then the final state of the environment after monitor acting is set as the target for the student to accomplish. If student completes the target, it will be rewarded 1, whereas monitor obtains a reward of 0. In contrast, if student cannot complete it, monitor will obtain a reward of 1. The monitor is allowed to propose tasks that are slightly higher than the student\u2019s ability to accelerate environment exploration.",
        "type": "NarrativeText"
    },
    {
        "element_id": "b7b57e3aeb456a26ebe0eeadd95460f9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1927.0
                    ],
                    [
                        136.0,
                        2087.5
                    ],
                    [
                        833.7,
                        2087.5
                    ],
                    [
                        833.7,
                        1927.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93564,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3,
            "parent_id": "dc39ca788847f3831c42383d0307231c"
        },
        "text": "As depicted in Fig. 2(a), in the pretraining stage, there are two agents, monitor and student. The pretraining is an unsupervised two-player game process between monitor and student. Monitor first performs a sequence of actions, and the environment is ultimately transitioned to state s\u2217. Then,",
        "type": "NarrativeText"
    },
    {
        "element_id": "1112b51f02118c46e75b5e41f820dd53",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1960.2
                    ],
                    [
                        866.6,
                        2087.5
                    ],
                    [
                        1565.8,
                        2087.5
                    ],
                    [
                        1565.8,
                        1960.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93265,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3,
            "parent_id": "dc39ca788847f3831c42383d0307231c"
        },
        "text": "The game starts with random initialization of monitor and student\u2019s policy: \u03c0M and \u03c0S. Both \u03c0M and \u03c0S take as input the current environmental state and output an action. The process of pretraining is described in Algorithm 1.",
        "type": "NarrativeText"
    },
    {
        "element_id": "652e147995f23cc552eceb683807de21",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.5
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79837,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3,
            "parent_id": "dc39ca788847f3831c42383d0307231c"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:23:24 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "8100d3a6e96db1201eec6149cf689a0e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1552.4,
                        84.3
                    ],
                    [
                        1552.4,
                        105.0
                    ],
                    [
                        1565.5,
                        105.0
                    ],
                    [
                        1565.5,
                        84.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72969,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 3
        },
        "text": "3",
        "type": "Header"
    },
    {
        "element_id": "eff2ba409953ec8ba7996beaec07ff07",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        321.9,
                        26.2
                    ],
                    [
                        321.9,
                        46.1
                    ],
                    [
                        1510.0,
                        46.1
                    ],
                    [
                        1510.0,
                        26.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82597,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "type": "Header"
    },
    {
        "element_id": "5de080efd58064d3fba1e705da0382f7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.8,
                        84.4
                    ],
                    [
                        134.8,
                        104.6
                    ],
                    [
                        147.2,
                        104.6
                    ],
                    [
                        147.2,
                        84.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72392,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "4",
        "type": "Header"
    },
    {
        "element_id": "52b14362955a7651829356fba8dfe0c5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        885.8,
                        85.2
                    ],
                    [
                        885.8,
                        104.6
                    ],
                    [
                        1566.6,
                        104.6
                    ],
                    [
                        1566.6,
                        85.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81551,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "5de080efd58064d3fba1e705da0382f7"
        },
        "text": "IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS",
        "type": "NarrativeText"
    },
    {
        "element_id": "e5eefec2a277e078d386d0a59b585e68",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        160.4
                    ],
                    [
                        136.0,
                        196.0
                    ],
                    [
                        594.4,
                        196.0
                    ],
                    [
                        594.4,
                        160.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "5de080efd58064d3fba1e705da0382f7"
        },
        "text": "Algorithm 1 Pretraining Stage (TM , TS)",
        "type": "Title"
    },
    {
        "element_id": "6576158997b147c5a9c98fe9013c0202",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        110.0,
                        203.6
                    ],
                    [
                        110.0,
                        1786.6
                    ],
                    [
                        665.5,
                        1786.6
                    ],
                    [
                        665.5,
                        203.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.50881,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "e5eefec2a277e078d386d0a59b585e68"
        },
        "text": "1: // Initialization 2: ty =0 3: 0 * Ni = env.obser ve() & while k < K do 7 count =0 8 while True do 9: // Monitor\u2019s turn 10: tu=tut+1 11: // Monitor\u2019s action 12: ad=Ty(s;) 13: ifa = STOP or ty > Ty then 14: /1 Student's target state 15: s*\u2014s env.reser) 18: end if 19: env.act (a) 20: s\u0131 = env.observe() > end while 23: while True do 24: HW Student\u2019s turn 25: set 5 to 5p 26: Si= So , or: 1 Student's action 28: a = T5(5;|81) 29: env.act(a) 30: 5; = env.observe() 31: si\" = si 32: if D(s\u2122, 5) Se and ts < Ts then x nue reward 35: break 36: end if 37: ts =ts +1 x. end woe 40: V\u0130 Monitor\u2019s reward 41: Ru \u2014 1 \u2014 Rs 42 if Ry =1 then 43: count = count + | 44: end if 45: if count > n then 46: // auxiliary penalty 47: Ry = Ru \u2014r 48: count =0 #9: else , a en di Ru 52: if Ry = 1 then 53: // Use the intermediate state 54: Skt = Sk 55: else 56: W Kemale",
        "type": "NarrativeText"
    },
    {
        "element_id": "17cd3182da1deafa21963088019766dd",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        161.1
                    ],
                    [
                        866.6,
                        355.4
                    ],
                    [
                        1566.9,
                        355.4
                    ],
                    [
                        1566.9,
                        161.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94819,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "e5eefec2a277e078d386d0a59b585e68"
        },
        "text": "In (1), si represents the state of the environment after monitor has taken ith steps. Monitor executes TM steps in each game, so i \u2208 [0, 1, 2, . . . , TM ]. a M i represents the action taken by monitor when the environment is at state si . After monitor completes TM steps, the state of the environment is denoted as s M , which will be the target of student.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f55e4de1473f1aab60d7e972a33b51f2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1007.4,
                        341.2
                    ],
                    [
                        1007.4,
                        360.6
                    ],
                    [
                        1012.8,
                        360.6
                    ],
                    [
                        1012.8,
                        341.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "5de080efd58064d3fba1e705da0382f7"
        },
        "text": "t",
        "type": "Title"
    },
    {
        "element_id": "d3727daec79587b9214f7c992507dd9e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        355.0
                    ],
                    [
                        866.6,
                        457.4
                    ],
                    [
                        1564.0,
                        457.4
                    ],
                    [
                        1564.0,
                        355.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92958,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "f55e4de1473f1aab60d7e972a33b51f2"
        },
        "text": "as s\u2217, which is the target of In student\u2019s turn, we use s M t student, and the environment state is then reset to its initial state s0",
        "type": "NarrativeText"
    },
    {
        "element_id": "5fa5ad30a0719997cf056345687f09e9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1116.6,
                        468.0
                    ],
                    [
                        1116.6,
                        509.2
                    ],
                    [
                        1564.6,
                        509.2
                    ],
                    [
                        1564.6,
                        468.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74324,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "= m5 (si|s\"). (2)",
        "type": "Formula"
    },
    {
        "element_id": "121b16b6646e82d2fbff20bd55c3452e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1131.8,
                        473.6
                    ],
                    [
                        1131.8,
                        512.5
                    ],
                    [
                        1210.3,
                        512.5
                    ],
                    [
                        1210.3,
                        473.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "i = \u03c0S",
        "type": "NarrativeText"
    },
    {
        "element_id": "d33d98202562ea11458f3d241b4459a2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        525.8
                    ],
                    [
                        894.3,
                        561.4
                    ],
                    [
                        1564.0,
                        561.4
                    ],
                    [
                        1564.0,
                        525.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "As shown in (2), given the target s\u2217, \u03c0S takes as input",
        "type": "NarrativeText"
    },
    {
        "element_id": "2508c1724e6edad9a0ba7dd8848abf3e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        864.7,
                        535.1
                    ],
                    [
                        864.7,
                        692.3
                    ],
                    [
                        1564.8,
                        692.3
                    ],
                    [
                        1564.8,
                        535.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9441,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "the environment state si and outputs an action a S student. Student can execute TS steps in each game, so i \u2208 i [0, 1, 2, . . . , TS]. After student completes TS steps, the state of the environment is denoted as sStu. for",
        "type": "NarrativeText"
    },
    {
        "element_id": "662aff4ae91f1231eb40125ae948c260",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        694.3
                    ],
                    [
                        866.6,
                        793.9
                    ],
                    [
                        1565.3,
                        793.9
                    ],
                    [
                        1565.3,
                        694.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93612,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "Within the specified TS steps, if student\u2019s final state sStu and the target state s\u2217 satisfy the following equation, we deem that student completes the task, and thus, RS is rewarded 1:",
        "type": "NarrativeText"
    },
    {
        "element_id": "04e2ae57aca9310f9ad3e2b64af49ff1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1118.3,
                        804.9
                    ],
                    [
                        1118.3,
                        843.5
                    ],
                    [
                        1295.5,
                        843.5
                    ],
                    [
                        1295.5,
                        804.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "D(ss\u2122, s*) <e.",
        "type": "UncategorizedText"
    },
    {
        "element_id": "dc2ed10ef200d92320a1ca642d9c404a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1122.5,
                        816.5
                    ],
                    [
                        1122.5,
                        844.2
                    ],
                    [
                        1565.1,
                        844.2
                    ],
                    [
                        1565.1,
                        816.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.69091,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "(3)",
        "type": "Formula"
    },
    {
        "element_id": "d0923820474841b671c17b9e150870d1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        862.7
                    ],
                    [
                        894.3,
                        896.4
                    ],
                    [
                        1564.0,
                        896.4
                    ],
                    [
                        1564.0,
                        862.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "In (3), D is a distance function and \u03b5 is a threshold, which",
        "type": "NarrativeText"
    },
    {
        "element_id": "2b732f5e3f6c9fff59401a1fdfc800e1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        872.5
                    ],
                    [
                        866.6,
                        1064.3
                    ],
                    [
                        1564.8,
                        1064.3
                    ],
                    [
                        1564.8,
                        872.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94748,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "is set according to the environment (see Section IV). If (3) is not satisfied within TS, student fails and RS is rewarded 0. Monitor\u2019s reward is RM = 1 \u2212 RS; that is, monitor and student compete for the reward. The reward is used to update monitor and student\u2019s policies \u03c0M and \u03c0S, respectively.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d2626a0a6828f57f6286034eb7a44f5f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        1062.0
                    ],
                    [
                        894.3,
                        1095.6
                    ],
                    [
                        1564.0,
                        1095.6
                    ],
                    [
                        1564.0,
                        1062.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "In this case, monitor will tend to seek a target state s\u2217 that",
        "type": "NarrativeText"
    },
    {
        "element_id": "7acb8e3564af0da1981df2c61c7e4684",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1071.2
                    ],
                    [
                        866.6,
                        1261.7
                    ],
                    [
                        1565.1,
                        1261.7
                    ],
                    [
                        1565.1,
                        1071.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94758,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "is difficult for student to complete. However, if the task is always too complicated, student will never be able to complete it, and thus, student cannot be trained effectively. To this end, an auxiliary penalty is introduced, where monitor is penalized if the proposed task is always too complicated",
        "type": "NarrativeText"
    },
    {
        "element_id": "026d71896e9250c313843c146d4a9488",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1124.0,
                        1278.9
                    ],
                    [
                        1124.0,
                        1313.3
                    ],
                    [
                        1147.5,
                        1313.3
                    ],
                    [
                        1147.5,
                        1278.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "R\u2032",
        "type": "UncategorizedText"
    },
    {
        "element_id": "6baafd9be8da5f0565effc929fec346f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1142.5,
                        1280.2
                    ],
                    [
                        1142.5,
                        1319.1
                    ],
                    [
                        1289.9,
                        1319.1
                    ],
                    [
                        1289.9,
                        1280.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "M = RM \u2212 r.",
        "type": "Title"
    },
    {
        "element_id": "a07f0c277a9bdad29e63dcc9c3e8775d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1123.0,
                        1286.2
                    ],
                    [
                        1123.0,
                        1313.9
                    ],
                    [
                        1565.5,
                        1313.9
                    ],
                    [
                        1565.5,
                        1286.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73067,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "(4)",
        "type": "Formula"
    },
    {
        "element_id": "fe2cea2cfff504e90764b6ec1493dfba",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1337.8
                    ],
                    [
                        866.6,
                        1731.4
                    ],
                    [
                        1566.6,
                        1731.4
                    ],
                    [
                        1566.6,
                        1337.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95252,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "As shown in (4), r is a constant greater than 1, which is the auxiliary penalty. The reason for this choice is to ensure that the reward monitor receives is negative so that monitor adjusts its strategy. For example, if monitor continuously proposes n (e.g., n = 4 or 5) tasks that student cannot complete, monitor will be rewarded an additional \u22122 or more. In this way, monitor will appropriately adjust task difficulty. If student can complete the tasks assigned by monitor, monitor will attempt to find new tasks that have not been proposed to challenge student. Through this auxiliary penalty, monitor can propose various moderately difficult tasks, and student can effectively explore the environment.",
        "type": "NarrativeText"
    },
    {
        "element_id": "6b697629434753988e21af9ecc0039b0",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.4,
                        1780.8
                    ],
                    [
                        134.4,
                        1805.7
                    ],
                    [
                        277.1,
                        1805.7
                    ],
                    [
                        277.1,
                        1780.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.53461,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "57: end if",
        "type": "ListItem"
    },
    {
        "element_id": "f325be5055377d8dad687e7b8d758cb1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        137.5,
                        1805.6
                    ],
                    [
                        137.5,
                        1833.6
                    ],
                    [
                        298.8,
                        1833.6
                    ],
                    [
                        298.8,
                        1805.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.53552,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "58: k + = 1",
        "type": "ListItem"
    },
    {
        "element_id": "128d1374ec7bbfec7305ce2bfddb08d3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        130.1,
                        1836.4
                    ],
                    [
                        130.1,
                        1861.3
                    ],
                    [
                        541.9,
                        1861.3
                    ],
                    [
                        541.9,
                        1836.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.584,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "// Update the policy individually",
        "type": "ListItem"
    },
    {
        "element_id": "ba513e87d57cc6b0d89596743694ecec",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        206.0,
                        1858.7
                    ],
                    [
                        206.0,
                        1890.5
                    ],
                    [
                        354.0,
                        1890.5
                    ],
                    [
                        354.0,
                        1858.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "\u03c0M .update(R\u2032",
        "type": "Title"
    },
    {
        "element_id": "70c7dc14dea0a6af6a893682c0d8e70a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        366.3,
                        1858.7
                    ],
                    [
                        366.3,
                        1883.6
                    ],
                    [
                        375.6,
                        1883.6
                    ],
                    [
                        375.6,
                        1858.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "ba513e87d57cc6b0d89596743694ecec"
        },
        "text": ")",
        "type": "UncategorizedText"
    },
    {
        "element_id": "946612fd65a5934345719856cdd73921",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        137.6,
                        1865.9
                    ],
                    [
                        137.6,
                        1888.3
                    ],
                    [
                        375.8,
                        1888.3
                    ],
                    [
                        375.8,
                        1865.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.49421,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "ba513e87d57cc6b0d89596743694ecec"
        },
        "text": "60:",
        "type": "ListItem"
    },
    {
        "element_id": "ebfe1852553afd0bd5846fbb467f0645",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        349.6,
                        1876.9
                    ],
                    [
                        349.6,
                        1893.5
                    ],
                    [
                        363.5,
                        1893.5
                    ],
                    [
                        363.5,
                        1876.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "M",
        "type": "Title"
    },
    {
        "element_id": "bcd59d6ea2093d0c073364d7ad0fe3be",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        206.0,
                        1886.3
                    ],
                    [
                        206.0,
                        1918.2
                    ],
                    [
                        362.6,
                        1918.2
                    ],
                    [
                        362.6,
                        1886.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "\u03c0S.update(RS)",
        "type": "Title"
    },
    {
        "element_id": "b3223a9ffd573374cbcfd8321bec97ca",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        137.6,
                        1893.9
                    ],
                    [
                        137.6,
                        1916.0
                    ],
                    [
                        363.9,
                        1916.0
                    ],
                    [
                        363.9,
                        1893.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.5022,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "bcd59d6ea2093d0c073364d7ad0fe3be"
        },
        "text": "61:",
        "type": "ListItem"
    },
    {
        "element_id": "30b0846bc4b86d31e72a847c0cfd2451",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1737.0
                    ],
                    [
                        866.6,
                        1930.7
                    ],
                    [
                        1565.9,
                        1930.7
                    ],
                    [
                        1565.9,
                        1737.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95309,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "bcd59d6ea2093d0c073364d7ad0fe3be"
        },
        "text": "In traditional RL training, regardless of whether the task is completed, the environment state in which the agent is situated will be reset after a game, which leads to the loss of useful information. Therefore, the state relay mechanism is proposed in this study to use the intermediate states of the training process fully",
        "type": "NarrativeText"
    },
    {
        "element_id": "b7ef47edbe14d47524b9ef85b399daf9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        137.6,
                        1919.2
                    ],
                    [
                        137.6,
                        1944.1
                    ],
                    [
                        286.1,
                        1944.1
                    ],
                    [
                        286.1,
                        1919.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.34318,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "bcd59d6ea2093d0c073364d7ad0fe3be"
        },
        "text": "62: end while",
        "type": "ListItem"
    },
    {
        "element_id": "7aecdc5812bb16e190406806b481fb0a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1010.9,
                        1939.9
                    ],
                    [
                        1010.9,
                        1967.6
                    ],
                    [
                        1030.0,
                        1967.6
                    ],
                    [
                        1030.0,
                        1939.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "bcd59d6ea2093d0c073364d7ad0fe3be"
        },
        "text": "(",
        "type": "UncategorizedText"
    },
    {
        "element_id": "a8d7dfafc03a0bd6a73e44bd11803209",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        137.6,
                        1946.5
                    ],
                    [
                        137.6,
                        1971.4
                    ],
                    [
                        248.6,
                        1971.4
                    ],
                    [
                        248.6,
                        1946.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "63: r etur n",
        "type": "Title"
    },
    {
        "element_id": "e655e1bf8f5b0727c8831efda1bdb4b9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        927.2,
                        1951.6
                    ],
                    [
                        927.2,
                        2027.4
                    ],
                    [
                        1576.6,
                        2027.4
                    ],
                    [
                        1576.6,
                        1951.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.7631,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "sk+1 = sk, reset as s0, if k < K if k > K , or task fails. (5)",
        "type": "Formula"
    },
    {
        "element_id": "1e08bc503ef6b763f299cd5e4223fc32",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1994.1
                    ],
                    [
                        136.0,
                        2060.9
                    ],
                    [
                        835.2,
                        2060.9
                    ],
                    [
                        835.2,
                        1994.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88127,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "First, monitor takes action according to its policy \u03c0M , as shown in the following equation:",
        "type": "NarrativeText"
    },
    {
        "element_id": "adb5b4e6f8fc5e1a580904eaf41daec3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        824.1,
                        2048.8
                    ],
                    [
                        824.1,
                        2143.4
                    ],
                    [
                        1564.0,
                        2143.4
                    ],
                    [
                        1564.0,
                        2048.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80595,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "In this mechanism, shown as (5), the condition for resetting the state is either: 1) it fails in one of the training tasks or",
        "type": "NarrativeText"
    },
    {
        "element_id": "79eb37ca01aea2cfbb9c8e4d55acfe86",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        410.4,
                        2073.6
                    ],
                    [
                        410.4,
                        2112.5
                    ],
                    [
                        553.8,
                        2112.5
                    ],
                    [
                        553.8,
                        2073.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "i = \u03c0M (si ).",
        "type": "NarrativeText"
    },
    {
        "element_id": "e13048f9b43d99212dec15c22a03ec19",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        396.6,
                        2074.3
                    ],
                    [
                        396.6,
                        2106.7
                    ],
                    [
                        429.2,
                        2106.7
                    ],
                    [
                        429.2,
                        2074.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4
        },
        "text": "a M",
        "type": "Title"
    },
    {
        "element_id": "02b47efb82c2544cee080e63ff16c49d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        801.1,
                        2079.6
                    ],
                    [
                        801.1,
                        2107.3
                    ],
                    [
                        833.4,
                        2107.3
                    ],
                    [
                        833.4,
                        2079.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "e13048f9b43d99212dec15c22a03ec19"
        },
        "text": "(1)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "53701dd4d8d34e7463e0205a4de37da9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2123.7
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2123.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 4,
            "parent_id": "e13048f9b43d99212dec15c22a03ec19"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:23:24 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "5bfd8e45e567593b198360e2828a6f10",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        320.3,
                        24.9
                    ],
                    [
                        320.3,
                        46.4
                    ],
                    [
                        1510.0,
                        46.4
                    ],
                    [
                        1510.0,
                        24.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80176,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "type": "Header"
    },
    {
        "element_id": "55867e6d49379ee31b3d2392925e2285",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        130.5,
                        82.7
                    ],
                    [
                        130.5,
                        104.7
                    ],
                    [
                        1140.0,
                        104.7
                    ],
                    [
                        1140.0,
                        82.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80442,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "5bfd8e45e567593b198360e2828a6f10"
        },
        "text": "LIU et al.: BOOSTING REINFORCEMENT LEARNING VIA HIERARCHICAL GAME PLAYING WITH STATE RELAY",
        "type": "NarrativeText"
    },
    {
        "element_id": "13f5b2462e56a9fccb01427b1a4f92b9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.4,
                        161.1
                    ],
                    [
                        135.4,
                        488.5
                    ],
                    [
                        834.3,
                        488.5
                    ],
                    [
                        834.3,
                        161.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95681,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "5bfd8e45e567593b198360e2828a6f10"
        },
        "text": "2) K tasks are all completed. Specifically, if student fails to complete a certain task, the algorithm remains the same; that is, the state is reset. However, if student accomplishes the task proposed by monitor, the current states in which monitor and student are situated will not be reset but rather used as the initial states in the next training game. When student successfully and consecutively completes multiple (e.g., K is three or four) tasks, the state is then reset to a random initial state. Through the relay mechanism, student can better explore the environment for a farther space that has not been visited.",
        "type": "NarrativeText"
    },
    {
        "element_id": "33e983ceaaf62c04cf9e6cb4df84d56e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        161.7
                    ],
                    [
                        866.6,
                        324.6
                    ],
                    [
                        1569.1,
                        324.6
                    ],
                    [
                        1569.1,
                        161.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95095,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "5bfd8e45e567593b198360e2828a6f10"
        },
        "text": "length of teacher). The time when teacher proposes a new subgoal is at t + TTea. An external reward is used to fine-tune teacher\u2019s policy \u03c0T and train student. After pretraining, student has been trained to complete the task with a total of TM steps; here, we set TTea = TM .",
        "type": "NarrativeText"
    },
    {
        "element_id": "b2ed03f97f6caa0381bee6257f7a5de4",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        360.5
                    ],
                    [
                        866.6,
                        396.5
                    ],
                    [
                        1349.9,
                        396.5
                    ],
                    [
                        1349.9,
                        360.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.54223,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "5bfd8e45e567593b198360e2828a6f10"
        },
        "text": "Algorithm 2 Fine-Tuning Stage (TTea, TS)",
        "type": "NarrativeText"
    },
    {
        "element_id": "b8f0943db2a2803a798319b11d3b2804",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        879.8,
                        403.4
                    ],
                    [
                        879.8,
                        433.2
                    ],
                    [
                        1084.4,
                        433.2
                    ],
                    [
                        1084.4,
                        403.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.41633,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "5bfd8e45e567593b198360e2828a6f10"
        },
        "text": "1: // Initialization",
        "type": "ListItem"
    },
    {
        "element_id": "f6bd2d768b4e1573dc6cf2d0db8a83b8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        882.6,
                        430.7
                    ],
                    [
                        882.6,
                        466.2
                    ],
                    [
                        1059.8,
                        466.2
                    ],
                    [
                        1059.8,
                        430.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "5bfd8e45e567593b198360e2828a6f10"
        },
        "text": "2: i = 0, tS = 0",
        "type": "UncategorizedText"
    },
    {
        "element_id": "2bd2b3d18e79db4d7e17cfba6a783f55",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        882.6,
                        463.9
                    ],
                    [
                        882.6,
                        499.4
                    ],
                    [
                        1096.3,
                        499.4
                    ],
                    [
                        1096.3,
                        463.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "5bfd8e45e567593b198360e2828a6f10"
        },
        "text": "3: RT = 0, RS = 0",
        "type": "UncategorizedText"
    },
    {
        "element_id": "cce8400ca68a00893e51e6885bf7bd1d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        882.6,
                        497.1
                    ],
                    [
                        882.6,
                        532.6
                    ],
                    [
                        1122.4,
                        532.6
                    ],
                    [
                        1122.4,
                        497.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "5bfd8e45e567593b198360e2828a6f10"
        },
        "text": "4: while i < TT ea do",
        "type": "NarrativeText"
    },
    {
        "element_id": "b085e4fb437d2bacf45f83779dfb61ea",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        537.6
                    ],
                    [
                        136.0,
                        565.3
                    ],
                    [
                        517.4,
                        565.3
                    ],
                    [
                        517.4,
                        537.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.54749,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "5bfd8e45e567593b198360e2828a6f10"
        },
        "text": "B. Structure of the Student Agent",
        "type": "Title"
    },
    {
        "element_id": "cb79b4d8f1629320e7ddb0810ebb5aee",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        883.0,
                        542.0
                    ],
                    [
                        883.0,
                        557.0
                    ],
                    [
                        892.0,
                        557.0
                    ],
                    [
                        892.0,
                        542.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "b085e4fb437d2bacf45f83779dfb61ea"
        },
        "text": "5",
        "type": "UncategorizedText"
    },
    {
        "element_id": "552ef2ade8429025dd0bc2b470dc1333",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        941.3,
                        530.3
                    ],
                    [
                        941.3,
                        563.3
                    ],
                    [
                        1155.6,
                        563.3
                    ],
                    [
                        1155.6,
                        530.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "5bfd8e45e567593b198360e2828a6f10"
        },
        "text": "s = env.obser ve()",
        "type": "Title"
    },
    {
        "element_id": "4c6ccba216417ca44e63b78b1c4b6ccf",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        580.5
                    ],
                    [
                        136.0,
                        709.7
                    ],
                    [
                        833.4,
                        709.7
                    ],
                    [
                        833.4,
                        580.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93826,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "552ef2ade8429025dd0bc2b470dc1333"
        },
        "text": "The student\u2019s policy is composed of two components. The first component is the target encoder E, which maps student\u2019s and target state s\u2217 to a low-dimensional target current state sStu t code gt \u2208 RN , as shown in the following equation:",
        "type": "NarrativeText"
    },
    {
        "element_id": "bd3115777d1fc685965ad402fe9108e8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.3,
                        569.5
                    ],
                    [
                        877.3,
                        597.5
                    ],
                    [
                        1269.0,
                        597.5
                    ],
                    [
                        1269.0,
                        569.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72188,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "552ef2ade8429025dd0bc2b470dc1333"
        },
        "text": "// Teacher proposes subgoals",
        "type": "ListItem"
    },
    {
        "element_id": "45c87686f7032b176b1473d0d6273324",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        941.9,
                        596.7
                    ],
                    [
                        941.9,
                        632.3
                    ],
                    [
                        1066.4,
                        632.3
                    ],
                    [
                        1066.4,
                        596.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "5bfd8e45e567593b198360e2828a6f10"
        },
        "text": "gt = \u03c0T (s)",
        "type": "Title"
    },
    {
        "element_id": "66277b9de597230683e92a884a714fbc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        882.6,
                        606.2
                    ],
                    [
                        882.6,
                        630.1
                    ],
                    [
                        1066.8,
                        630.1
                    ],
                    [
                        1066.8,
                        606.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.64284,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "45c87686f7032b176b1473d0d6273324"
        },
        "text": "7:",
        "type": "ListItem"
    },
    {
        "element_id": "e99369d452bce9026d4f9e0ce974fda8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        879.4,
                        635.7
                    ],
                    [
                        879.4,
                        663.6
                    ],
                    [
                        1104.8,
                        663.6
                    ],
                    [
                        1104.8,
                        635.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.66785,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "45c87686f7032b176b1473d0d6273324"
        },
        "text": "8: while True do",
        "type": "ListItem"
    },
    {
        "element_id": "c0f72b852ec178aa9ff8dcf526750175",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        969.0,
                        663.1
                    ],
                    [
                        969.0,
                        698.7
                    ],
                    [
                        1190.2,
                        698.7
                    ],
                    [
                        1190.2,
                        663.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "5bfd8e45e567593b198360e2828a6f10"
        },
        "text": "si = env.obser ve()",
        "type": "Title"
    },
    {
        "element_id": "8db22de368158b227b89af838d50d03c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        869.1,
                        670.7
                    ],
                    [
                        869.1,
                        695.9
                    ],
                    [
                        1189.9,
                        695.9
                    ],
                    [
                        1189.9,
                        670.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.6452,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "c0f72b852ec178aa9ff8dcf526750175"
        },
        "text": "9:",
        "type": "ListItem"
    },
    {
        "element_id": "0b28997e1def758346755b685cc481ed",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        381.6,
                        720.9
                    ],
                    [
                        381.6,
                        765.4
                    ],
                    [
                        825.0,
                        765.4
                    ],
                    [
                        825.0,
                        720.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.7259,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "& = E(s*, 57\"). 6)",
        "type": "Formula"
    },
    {
        "element_id": "6a2af2ea2efabf7ad131d6351c5600ca",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        801.1,
                        732.5
                    ],
                    [
                        801.1,
                        760.2
                    ],
                    [
                        833.4,
                        760.2
                    ],
                    [
                        833.4,
                        732.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "(6)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "709adba8867390bfe06b4a347c7b5428",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        882.0,
                        701.7
                    ],
                    [
                        882.0,
                        730.2
                    ],
                    [
                        1188.2,
                        730.2
                    ],
                    [
                        1188.2,
                        701.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.598,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "// Student\u2019s action",
        "type": "ListItem"
    },
    {
        "element_id": "f66de3c2b0e5f7891cebafb823cf343e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        871.5,
                        706.7
                    ],
                    [
                        871.5,
                        728.8
                    ],
                    [
                        899.8,
                        728.8
                    ],
                    [
                        899.8,
                        706.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "10:",
        "type": "UncategorizedText"
    },
    {
        "element_id": "b89e38d6a9529249ac47339285323a01",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        968.9,
                        729.5
                    ],
                    [
                        968.9,
                        765.1
                    ],
                    [
                        1128.6,
                        765.1
                    ],
                    [
                        1128.6,
                        729.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "ai = \u03c0S(si |gt )",
        "type": "Title"
    },
    {
        "element_id": "f05769c14ec499b7fb6968230dd60ee5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        858.2,
                        739.7
                    ],
                    [
                        858.2,
                        762.0
                    ],
                    [
                        1138.2,
                        762.0
                    ],
                    [
                        1138.2,
                        739.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.57406,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "b89e38d6a9529249ac47339285323a01"
        },
        "text": "11:",
        "type": "ListItem"
    },
    {
        "element_id": "4fe5a26422eb35bb8191d948bf92807b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        784.3
                    ],
                    [
                        136.0,
                        879.0
                    ],
                    [
                        833.4,
                        879.0
                    ],
                    [
                        833.4,
                        784.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93152,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "b89e38d6a9529249ac47339285323a01"
        },
        "text": "Because of the low spatial dimension, the target encoder E can compactly express the student\u2019s target and retain sufficient task information.",
        "type": "NarrativeText"
    },
    {
        "element_id": "93847ac76bc1629f789c0c6a9f15510a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        884.6
                    ],
                    [
                        136.0,
                        945.4
                    ],
                    [
                        833.4,
                        945.4
                    ],
                    [
                        833.4,
                        884.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91489,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "b89e38d6a9529249ac47339285323a01"
        },
        "text": "The target encoder has two forms, as shown in the following equations, where \u03c6 is the state embedding function.",
        "type": "NarrativeText"
    },
    {
        "element_id": "52dac3f170a22901c76fd5bdbd30e9de",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.2,
                        956.6
                    ],
                    [
                        163.2,
                        1017.5
                    ],
                    [
                        833.4,
                        1017.5
                    ],
                    [
                        833.4,
                        956.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.86217,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "b89e38d6a9529249ac47339285323a01"
        },
        "text": "1) The first form calculates the difference between the current state and the target state",
        "type": "ListItem"
    },
    {
        "element_id": "2f8f98af2ac8d761954f1d599653dc7e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        875.0,
                        775.0
                    ],
                    [
                        875.0,
                        790.0
                    ],
                    [
                        898.0,
                        790.0
                    ],
                    [
                        898.0,
                        775.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "b89e38d6a9529249ac47339285323a01"
        },
        "text": "12:",
        "type": "UncategorizedText"
    },
    {
        "element_id": "887b89437df09db287cedfcfba9e0f98",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        969.0,
                        762.8
                    ],
                    [
                        969.0,
                        798.3
                    ],
                    [
                        1317.5,
                        798.3
                    ],
                    [
                        1317.5,
                        762.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "if env.done() or tS \u2265 TS then",
        "type": "Title"
    },
    {
        "element_id": "8527ad00548cb2ed0d44d0c5ca4c2ee1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        996.7,
                        801.3
                    ],
                    [
                        996.7,
                        829.0
                    ],
                    [
                        1064.2,
                        829.0
                    ],
                    [
                        1064.2,
                        801.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "br eak",
        "type": "Title"
    },
    {
        "element_id": "d57649ad8f51a5b88512124ed7a9a875",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        871.5,
                        804.0
                    ],
                    [
                        871.5,
                        828.4
                    ],
                    [
                        1053.8,
                        828.4
                    ],
                    [
                        1053.8,
                        804.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.35528,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "8527ad00548cb2ed0d44d0c5ca4c2ee1"
        },
        "text": "13:",
        "type": "ListItem"
    },
    {
        "element_id": "2f7fb859166f6706da6a4aa6b0b3a1c3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        871.5,
                        835.0
                    ],
                    [
                        871.5,
                        862.6
                    ],
                    [
                        1053.6,
                        862.6
                    ],
                    [
                        1053.6,
                        835.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.54159,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "8527ad00548cb2ed0d44d0c5ca4c2ee1"
        },
        "text": "14: end if",
        "type": "ListItem"
    },
    {
        "element_id": "b22c152f5986575244c72b4d7da45434",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        969.0,
                        862.4
                    ],
                    [
                        969.0,
                        897.9
                    ],
                    [
                        1101.0,
                        897.9
                    ],
                    [
                        1101.0,
                        862.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "env.act (ai )",
        "type": "Title"
    },
    {
        "element_id": "17d6335fec7af61bd9619a986ba5e97c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        869.1,
                        872.7
                    ],
                    [
                        869.1,
                        894.9
                    ],
                    [
                        1106.6,
                        894.9
                    ],
                    [
                        1106.6,
                        872.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.4784,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "b22c152f5986575244c72b4d7da45434"
        },
        "text": "15:",
        "type": "ListItem"
    },
    {
        "element_id": "0b50c6ab736390a6875240f77a271f65",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        871.5,
                        900.9
                    ],
                    [
                        871.5,
                        929.2
                    ],
                    [
                        1205.8,
                        929.2
                    ],
                    [
                        1205.8,
                        900.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.49907,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "b22c152f5986575244c72b4d7da45434"
        },
        "text": "16: // Student\u2019s reward",
        "type": "ListItem"
    },
    {
        "element_id": "a9cb867b057d6f48ebdb97e72e150cfa",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        971.2,
                        928.8
                    ],
                    [
                        971.2,
                        964.4
                    ],
                    [
                        1266.2,
                        964.4
                    ],
                    [
                        1266.2,
                        928.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "b22c152f5986575244c72b4d7da45434"
        },
        "text": "RS = RS + env.r ewar d()",
        "type": "NarrativeText"
    },
    {
        "element_id": "40d528a91c2f397c2f66ff3d14fde2e6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        871.3,
                        936.7
                    ],
                    [
                        871.3,
                        961.3
                    ],
                    [
                        1266.2,
                        961.3
                    ],
                    [
                        1266.2,
                        936.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.45816,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "b22c152f5986575244c72b4d7da45434"
        },
        "text": "17:",
        "type": "ListItem"
    },
    {
        "element_id": "b51e6153554d815d92a3baa63b03d043",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        969.0,
                        964.5
                    ],
                    [
                        969.0,
                        997.6
                    ],
                    [
                        1094.9,
                        997.6
                    ],
                    [
                        1094.9,
                        964.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "b22c152f5986575244c72b4d7da45434"
        },
        "text": "tS = tS + 1",
        "type": "NarrativeText"
    },
    {
        "element_id": "c74bc812c1217c7fed216c3340ef491a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        871.5,
                        971.6
                    ],
                    [
                        871.5,
                        994.5
                    ],
                    [
                        1096.6,
                        994.5
                    ],
                    [
                        1096.6,
                        971.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.4064,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "b22c152f5986575244c72b4d7da45434"
        },
        "text": "18:",
        "type": "ListItem"
    },
    {
        "element_id": "9c6935aa7dc131976eba9a494f5abf4d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        871.5,
                        1001.0
                    ],
                    [
                        871.5,
                        1028.7
                    ],
                    [
                        1057.5,
                        1028.7
                    ],
                    [
                        1057.5,
                        1001.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.58723,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "b22c152f5986575244c72b4d7da45434"
        },
        "text": "19: end while",
        "type": "ListItem"
    },
    {
        "element_id": "240f55f360aa3b441704d2b67f8274a3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        339.3,
                        1030.6
                    ],
                    [
                        339.3,
                        1075.9
                    ],
                    [
                        833.4,
                        1075.9
                    ],
                    [
                        833.4,
                        1030.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.64467,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "E(s*, 55\u201c) = 6(s*) \u2014 o(se\"). (7)",
        "type": "Formula"
    },
    {
        "element_id": "75a884aa5db8fef1d4b6710f1d1377da",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        1088.7
                    ],
                    [
                        163.7,
                        1122.3
                    ],
                    [
                        707.0,
                        1122.3
                    ],
                    [
                        707.0,
                        1088.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "2) The second form considers only the s\u2217 state",
        "type": "ListItem"
    },
    {
        "element_id": "18f07eb7e5dc664ed35ae3023ab97c57",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        863.9,
                        1034.4
                    ],
                    [
                        863.9,
                        1062.1
                    ],
                    [
                        1164.8,
                        1062.1
                    ],
                    [
                        1164.8,
                        1034.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.42476,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "20: // Teacher\u2019s reward",
        "type": "ListItem"
    },
    {
        "element_id": "9df205c358dd65b519d3ddb0f02c2887",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        872.0,
                        1074.0
                    ],
                    [
                        872.0,
                        1089.0
                    ],
                    [
                        898.0,
                        1089.0
                    ],
                    [
                        898.0,
                        1074.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "21:",
        "type": "UncategorizedText"
    },
    {
        "element_id": "37122dfda5f5016fca8d3caf8068208d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        943.6,
                        1061.6
                    ],
                    [
                        943.6,
                        1097.2
                    ],
                    [
                        1243.7,
                        1097.2
                    ],
                    [
                        1243.7,
                        1061.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "RT = RT + env.r ewar d()",
        "type": "NarrativeText"
    },
    {
        "element_id": "7793329ff12c513eb92969a3aaa64ce6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        941.1,
                        1097.3
                    ],
                    [
                        941.1,
                        1128.5
                    ],
                    [
                        1046.4,
                        1128.5
                    ],
                    [
                        1046.4,
                        1097.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "i = i + 1",
        "type": "UncategorizedText"
    },
    {
        "element_id": "c2730ba293388d52590f9f778aa4ba1f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        876.4,
                        1102.8
                    ],
                    [
                        876.4,
                        1125.2
                    ],
                    [
                        1044.6,
                        1125.2
                    ],
                    [
                        1044.6,
                        1102.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.5348,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "2 i=it+l",
        "type": "ListItem"
    },
    {
        "element_id": "62763e696cdbe9afc355e1d70a201ec0",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        871.5,
                        1105.2
                    ],
                    [
                        871.5,
                        1127.3
                    ],
                    [
                        899.8,
                        1127.3
                    ],
                    [
                        899.8,
                        1105.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "22:",
        "type": "UncategorizedText"
    },
    {
        "element_id": "6ed4a44dfda50e7acb2ce77065d40bc5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        395.0,
                        1135.5
                    ],
                    [
                        395.0,
                        1180.0
                    ],
                    [
                        833.4,
                        1180.0
                    ],
                    [
                        833.4,
                        1135.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.66947,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "E(s*, sim) = $(s*). (8)",
        "type": "Formula"
    },
    {
        "element_id": "58ac01a6b6d2616bd48673a3526e39ff",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        870.4,
                        1133.8
                    ],
                    [
                        870.4,
                        1161.5
                    ],
                    [
                        1029.4,
                        1161.5
                    ],
                    [
                        1029.4,
                        1133.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.60297,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "23: end while",
        "type": "ListItem"
    },
    {
        "element_id": "55136dc1c3c379a2d15b39b526eda009",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        871.5,
                        1167.2
                    ],
                    [
                        871.5,
                        1194.9
                    ],
                    [
                        1287.6,
                        1194.9
                    ],
                    [
                        1287.6,
                        1167.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.51203,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "24: // Update the policy individually",
        "type": "ListItem"
    },
    {
        "element_id": "755859d6bcf09676c0f4385789bfa9bb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1198.8
                    ],
                    [
                        136.0,
                        1262.3
                    ],
                    [
                        833.4,
                        1262.3
                    ],
                    [
                        833.4,
                        1198.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91517,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "In the second part of student\u2019s policy, gt parameter in \u03c0S, as shown in the following equation: is used as a",
        "type": "NarrativeText"
    },
    {
        "element_id": "336e860e17f07d304d6afa7dd843f2c3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        871.5,
                        1194.5
                    ],
                    [
                        871.5,
                        1230.0
                    ],
                    [
                        1093.7,
                        1230.0
                    ],
                    [
                        1093.7,
                        1194.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "25: \u03c0T .update(RT )",
        "type": "Title"
    },
    {
        "element_id": "199f34c284d64dbb5d74ba2fc085df5b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        871.5,
                        1227.7
                    ],
                    [
                        871.5,
                        1263.2
                    ],
                    [
                        1088.5,
                        1263.2
                    ],
                    [
                        1088.5,
                        1227.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "26: \u03c0S.update(RS)",
        "type": "Title"
    },
    {
        "element_id": "a6ad8dbda364f50553a458e181e3b902",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        378.1,
                        1273.5
                    ],
                    [
                        378.1,
                        1314.7
                    ],
                    [
                        835.0,
                        1314.7
                    ],
                    [
                        835.0,
                        1273.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72154,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "as = 7s(s\u201cg\u0131). (9)",
        "type": "Formula"
    },
    {
        "element_id": "a3450b2dfd37c78645eab5bb656f8255",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        493.6,
                        1298.6
                    ],
                    [
                        493.6,
                        1318.0
                    ],
                    [
                        499.0,
                        1318.0
                    ],
                    [
                        499.0,
                        1298.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "t",
        "type": "Title"
    },
    {
        "element_id": "34df93f6aac9bd46e65af73ed7dbb25c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        871.5,
                        1266.2
                    ],
                    [
                        871.5,
                        1293.9
                    ],
                    [
                        992.1,
                        1293.9
                    ],
                    [
                        992.1,
                        1266.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.44447,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "a3450b2dfd37c78645eab5bb656f8255"
        },
        "text": "27: r etur n",
        "type": "ListItem"
    },
    {
        "element_id": "1c040f4e9aafa56e6438afa7c5fa1a94",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        133.9,
                        1337.5
                    ],
                    [
                        133.9,
                        1433.5
                    ],
                    [
                        833.4,
                        1433.5
                    ],
                    [
                        833.4,
                        1337.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92756,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "a3450b2dfd37c78645eab5bb656f8255"
        },
        "text": "Two components of Student\u2019s policy structure are then combined, where two parameters are used: the current state sStu and the target code gt , as shown in the following equation:",
        "type": "NarrativeText"
    },
    {
        "element_id": "33155000bce94138e5287582a7b056eb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        146.8,
                        1417.4
                    ],
                    [
                        146.8,
                        1436.8
                    ],
                    [
                        152.1,
                        1436.8
                    ],
                    [
                        152.1,
                        1417.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "t",
        "type": "Title"
    },
    {
        "element_id": "c5862bd57cbc24bfeaf6784566c3b13f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        169.6,
                        1444.7
                    ],
                    [
                        169.6,
                        1521.8
                    ],
                    [
                        815.9,
                        1521.8
                    ],
                    [
                        815.9,
                        1444.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81442,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "m5(sp\"|E(s*, 37\"). (10) 7s (ss Bn s*) as 7slsi lg)",
        "type": "Formula"
    },
    {
        "element_id": "df15f22b898689c2ebefc5f29315e062",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1574.9
                    ],
                    [
                        136.0,
                        1602.6
                    ],
                    [
                        382.5,
                        1602.6
                    ],
                    [
                        382.5,
                        1574.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.6984,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "C. Fine-Tuning Stage",
        "type": "NarrativeText"
    },
    {
        "element_id": "0740f4da15584aa147d260d77a3f1a37",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        787.3,
                        1497.9
                    ],
                    [
                        787.3,
                        1525.5
                    ],
                    [
                        833.4,
                        1525.5
                    ],
                    [
                        833.4,
                        1497.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "(10)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "df88acdad19a32697790db8eec4d320a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        865.1,
                        1321.4
                    ],
                    [
                        865.1,
                        1648.0
                    ],
                    [
                        1568.6,
                        1648.0
                    ],
                    [
                        1568.6,
                        1321.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95416,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "Note the difference between the two stages: in the pretrain- ing stage, monitor\u2019s job is to propose a variety of tasks for student to complete. The key idea is that the game between them should help student understand what the environment is like and how to transition from one state to another so that it can learn the target task faster. In the fine-tuning stage, teacher\u2019s job is to propose appropriate subgoals to student based on the current task. When presented with a subgoal task, student tries to accomplish it (monitor plays no role in the fine-tuning stage).",
        "type": "NarrativeText"
    },
    {
        "element_id": "6d14edfb3be50420d134e2a6f8862889",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1617.8
                    ],
                    [
                        136.0,
                        1711.8
                    ],
                    [
                        833.4,
                        1711.8
                    ],
                    [
                        833.4,
                        1617.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93528,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "After pretraining, student can be used as a low-level agent to complete more tasks. Then, the fine-tuning stage starts, the process of which is shown in Algorithm 2.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a39d5c38cb9034405ac63a3d672d81d9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        864.6,
                        1686.7
                    ],
                    [
                        864.6,
                        1714.4
                    ],
                    [
                        1202.4,
                        1714.4
                    ],
                    [
                        1202.4,
                        1686.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.57801,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "D. Neural Network Modeling",
        "type": "Title"
    },
    {
        "element_id": "ef28cdc740d2fc8adbbf45576cfabf69",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1717.4
                    ],
                    [
                        136.0,
                        1813.4
                    ],
                    [
                        833.4,
                        1813.4
                    ],
                    [
                        833.4,
                        1717.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93073,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5,
            "parent_id": "a39d5c38cb9034405ac63a3d672d81d9"
        },
        "text": "In this stage, an agent, named teacher with high-level policy \u03c0T , is introduced to propose subgoals and encode them to generate gt for student, as shown in the following equation:",
        "type": "NarrativeText"
    },
    {
        "element_id": "2680c79cf3419176acb832460a094902",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        406.1,
                        1830.2
                    ],
                    [
                        406.1,
                        1865.8
                    ],
                    [
                        545.0,
                        1865.8
                    ],
                    [
                        545.0,
                        1830.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "gt = \u03c0T (st ).",
        "type": "Title"
    },
    {
        "element_id": "8c20e7b9bbcfc7d6992cf0f00c6c1acf",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        401.8,
                        1836.2
                    ],
                    [
                        401.8,
                        1863.9
                    ],
                    [
                        833.4,
                        1863.9
                    ],
                    [
                        833.4,
                        1836.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73406,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "(11)",
        "type": "Formula"
    },
    {
        "element_id": "1febfdc2e5a71c3e0cf64abbe95a6d7c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1888.0
                    ],
                    [
                        136.0,
                        1951.4
                    ],
                    [
                        833.4,
                        1951.4
                    ],
                    [
                        833.4,
                        1888.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92029,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "Then, the target code gt is passed to the student\u2019s policy \u03c0S, where it is converted into actions",
        "type": "NarrativeText"
    },
    {
        "element_id": "b18b80826c5e281b88498cb3de60d9ec",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1729.4
                    ],
                    [
                        866.6,
                        1956.3
                    ],
                    [
                        1566.9,
                        1956.3
                    ],
                    [
                        1566.9,
                        1729.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95147,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "The nonlinear multilayer perceptron (MLP) [38] is used to model \u03c0M and \u03c0S. The state embedding function \u03c6 is also a perceptron. \u03c0M and \u03c6 have two layers, and the second layer of \u03c6 is set to be linear to avoid setting boundaries for the target. The policy \u03c0S of the student is a three-layer perceptron, including a hidden layer in the middle, as shown in the following equation:",
        "type": "NarrativeText"
    },
    {
        "element_id": "9dfd8c52dd219c8280cf317a2e05221e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        369.3,
                        1968.3
                    ],
                    [
                        369.3,
                        2003.8
                    ],
                    [
                        581.1,
                        2003.8
                    ],
                    [
                        581.1,
                        1968.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "at+i = \u03c0S(st+i |gt ).",
        "type": "Title"
    },
    {
        "element_id": "b891f325ef16435ffefe780839c00c2d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        365.4,
                        1974.2
                    ],
                    [
                        365.4,
                        2001.9
                    ],
                    [
                        833.4,
                        2001.9
                    ],
                    [
                        833.4,
                        1974.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.69618,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "(12)",
        "type": "Formula"
    },
    {
        "element_id": "28922fe4b8292f8a57899cfd11704a13",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1042.3,
                        1966.0
                    ],
                    [
                        1042.3,
                        2007.7
                    ],
                    [
                        1355.2,
                        2007.7
                    ],
                    [
                        1355.2,
                        1966.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "hy = f (Waf (Wis) + Weg)",
        "type": "Title"
    },
    {
        "element_id": "c866f90fa660e86bafbe0694c151dcfc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1041.1,
                        1976.5
                    ],
                    [
                        1041.1,
                        2005.3
                    ],
                    [
                        1564.0,
                        2005.3
                    ],
                    [
                        1564.0,
                        1976.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.68009,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "(13)",
        "type": "Formula"
    },
    {
        "element_id": "7b6789bc75a50983460e93b566f2b34d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        2026.0
                    ],
                    [
                        136.0,
                        2089.9
                    ],
                    [
                        833.4,
                        2089.9
                    ],
                    [
                        833.4,
                        2026.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91334,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "Student attempts to take actions to complete subgoal gt when i \u2208 [0, 1, 2, . . . , TTea \u2212 1] (TTea is the maximum step",
        "type": "NarrativeText"
    },
    {
        "element_id": "9e1a9d1bb7117da33e73b90457c0b379",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        2026.0
                    ],
                    [
                        866.6,
                        2087.5
                    ],
                    [
                        1564.0,
                        2087.5
                    ],
                    [
                        1564.0,
                        2026.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91199,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "where f is the tanh activation function. To facilitate the experimental design, the bias term is omitted. The hidden layer",
        "type": "NarrativeText"
    },
    {
        "element_id": "f2b130eda9c936752d5286e210bbd499",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        140.7,
                        2122.4
                    ],
                    [
                        140.7,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79815,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:23:24 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "1cb475e19ccb5a3ba6f2a4c3737986e6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1552.4,
                        84.2
                    ],
                    [
                        1552.4,
                        105.2
                    ],
                    [
                        1565.6,
                        105.2
                    ],
                    [
                        1565.6,
                        84.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74168,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 5
        },
        "text": "5",
        "type": "Header"
    },
    {
        "element_id": "8bfbe4c4ca59b31e05f0893fc7a1fe24",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        317.0,
                        26.2
                    ],
                    [
                        317.0,
                        46.2
                    ],
                    [
                        1510.0,
                        46.2
                    ],
                    [
                        1510.0,
                        26.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81105,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6
        },
        "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "type": "Header"
    },
    {
        "element_id": "95fe88ff3f43abb1262f88067a0fcc49",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.6,
                        85.1
                    ],
                    [
                        134.6,
                        105.6
                    ],
                    [
                        147.2,
                        105.6
                    ],
                    [
                        147.2,
                        85.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.75088,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6
        },
        "text": "6",
        "type": "Header"
    },
    {
        "element_id": "689d8f1a96cf78e9b50329d1e64b7d3b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        885.8,
                        85.2
                    ],
                    [
                        885.8,
                        104.6
                    ],
                    [
                        1566.0,
                        104.6
                    ],
                    [
                        1566.0,
                        85.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.78252,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "95fe88ff3f43abb1262f88067a0fcc49"
        },
        "text": "IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS",
        "type": "NarrativeText"
    },
    {
        "element_id": "6d65144033f85be36e7434073508b49e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.9,
                        158.2
                    ],
                    [
                        134.9,
                        222.6
                    ],
                    [
                        833.4,
                        222.6
                    ],
                    [
                        833.4,
                        158.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93109,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "95fe88ff3f43abb1262f88067a0fcc49"
        },
        "text": "includes 64 cells. All the policy nets have D + 1 output heads, where D is the dimension of the action space.",
        "type": "NarrativeText"
    },
    {
        "element_id": "5859cb0ec01e0d7243ef9fe286b67361",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        222.1
                    ],
                    [
                        163.7,
                        257.7
                    ],
                    [
                        833.4,
                        257.7
                    ],
                    [
                        833.4,
                        222.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "95fe88ff3f43abb1262f88067a0fcc49"
        },
        "text": "The high-level policy \u03c0T is modeled using the BP net-",
        "type": "NarrativeText"
    },
    {
        "element_id": "77e71f9609aef54198e99a6622f1b2fd",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        231.6
                    ],
                    [
                        136.0,
                        455.0
                    ],
                    [
                        834.3,
                        455.0
                    ],
                    [
                        834.3,
                        231.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95392,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "95fe88ff3f43abb1262f88067a0fcc49"
        },
        "text": "work. During training, error BP is used to make continuous corrections, thereby accelerating the convergence of the loss function. Moreover, the activation function is the rectified lin- ear unit (ReLU) function, which reduces the interdependence between parameters, avoiding the occurrence of overfitting and effectively improving the training result.",
        "type": "NarrativeText"
    },
    {
        "element_id": "83e29ab5b7369dcfbb8cca837a0e219b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        378.8,
                        499.5
                    ],
                    [
                        378.8,
                        527.2
                    ],
                    [
                        592.8,
                        527.2
                    ],
                    [
                        592.8,
                        499.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.8415,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "95fe88ff3f43abb1262f88067a0fcc49"
        },
        "text": "IV. EXPERIMENT",
        "type": "Title"
    },
    {
        "element_id": "8fdebca14e164ab6021ca9b7720bab63",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        161.7
                    ],
                    [
                        866.6,
                        421.8
                    ],
                    [
                        1568.2,
                        421.8
                    ],
                    [
                        1568.2,
                        161.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95645,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "83e29ab5b7369dcfbb8cca837a0e219b"
        },
        "text": "second task [see Fig. 3 (middle)], two rooms are separated by a door. The agent has to learn to find the key in the room, and then find the door and open it. Compared with Task 1, Task 2 adds the task of picking up the key and needs to find the locations of the key and door. In the last task [see Fig. 3 (right)], the agent must first find the key in its room, open the door, and then go to the other room to reach the target location. This task is the most difficult.",
        "type": "NarrativeText"
    },
    {
        "element_id": "20016ad574552d020cb4c0eec7084cf1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        427.4
                    ],
                    [
                        866.6,
                        554.7
                    ],
                    [
                        1568.8,
                        554.7
                    ],
                    [
                        1568.8,
                        427.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93866,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "83e29ab5b7369dcfbb8cca837a0e219b"
        },
        "text": "If the agent completes the task, a reward of 1 is given; otherwise, the reward is 0. The randomness of the target location and the sparsity of the reward structure make the task challenging.",
        "type": "NarrativeText"
    },
    {
        "element_id": "764fafd03335d49a3c339f05f462763f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.2,
                        542.5
                    ],
                    [
                        135.2,
                        836.3
                    ],
                    [
                        834.9,
                        836.3
                    ],
                    [
                        834.9,
                        542.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95598,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "83e29ab5b7369dcfbb8cca837a0e219b"
        },
        "text": "The proposed HGR algorithm is expected to improve the performance compared with the state-of-the-art related HRL algorithms. Therefore, we use the SNN4HRL [14] algorithm, the HSP [30] algorithm, and the HRL with k-step adjacency constraint (HRAC) [20] algorithm as baselines. In our compar- ative experiments, the number of timesteps per iteration when training SNN4HRL is different from that in the original paper. We use the parameter setting of [39] to speed up SNN4HRL convergence.",
        "type": "NarrativeText"
    },
    {
        "element_id": "72cfee853d92e2c0aef01a29e32be70c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        865.7,
                        556.7
                    ],
                    [
                        865.7,
                        853.6
                    ],
                    [
                        1569.2,
                        853.6
                    ],
                    [
                        1569.2,
                        556.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95599,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "83e29ab5b7369dcfbb8cca837a0e219b"
        },
        "text": "The observable value is a binary vector: map width \u00d7 map height \u00d7 word size. The vocabulary includes a description of objects, such as \u201cagent,\u201d \u201cdoor,\u201d \u201cblock,\u201d \u201ckey,\u201d and \u201cgoal.\u201d The possible actions include four single-step movements (up, down, right, left), pick up action, and stop action. The agent must choose the next action after the previous action. In the pretraining process, the L2 paradigm is used as the distance function D, and \u03b5 is set to 0; that is, the final state of student in the task must match the final state of monitor.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d02727a39a0bac07f65e0d1ee3299be3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        841.8
                    ],
                    [
                        136.0,
                        1136.1
                    ],
                    [
                        835.8,
                        1136.1
                    ],
                    [
                        835.8,
                        841.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95642,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "83e29ab5b7369dcfbb8cca837a0e219b"
        },
        "text": "These algorithms are tested in two public environments. The first test is in the \u201cKey-Door\u201d environment of the MazeBase platform [40]. Specifically, in the \u201cKey-Door\u201d environment, the agent finds the key to a door and then opens it enter the other room for treasure hunting. The second test is in the AntGather environment of MuJoCo [41]. For AntGather, an ant-like robot collects targets of specific colors to obtain more rewards in an environment where objects are randomly placed. to",
        "type": "NarrativeText"
    },
    {
        "element_id": "ca6a12ce4452b4bb99e9c6ad723a2574",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        865.7,
                        859.1
                    ],
                    [
                        865.7,
                        1121.1
                    ],
                    [
                        1568.4,
                        1121.1
                    ],
                    [
                        1568.4,
                        859.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95745,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "83e29ab5b7369dcfbb8cca837a0e219b"
        },
        "text": "During pretraining, each game contains four rounds. In each round, monitor takes TM = 5 steps one time, while student takes TS = 7 steps to reach the target state. A discount ratio of 0.7 is used between training rounds, which is enough for monitor and student to pick up the key and enter the other room. Here, the target encoder only considers the target state. TTea is equal to TM when training teacher. In pretraining, student is trained to accomplish the task with TM steps.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9cbce8a1ffaf70e3d5062accd8c9931e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.4,
                        1141.6
                    ],
                    [
                        135.4,
                        1435.4
                    ],
                    [
                        835.8,
                        1435.4
                    ],
                    [
                        835.8,
                        1141.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95803,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "83e29ab5b7369dcfbb8cca837a0e219b"
        },
        "text": "In both the experiments, monitor\u2019s entropy regularization coefficient \u03b2 is set to 0.01, and student\u2019s imitation coefficient \u03b11 is 0.03. We use the proximal policy optimization (PPO) algorithm [42] for training all the policies. For optimization using root mean square propagation (RMSProp), the learning rate lr is 0.001, \u03b12 is 0.98, and \u03f5 is 1e\u22128. Each experiment is run three times with different random seeds, and the mean value and standard deviation of the experimental results are reported.",
        "type": "NarrativeText"
    },
    {
        "element_id": "bd62f4a6b8928205ea349ab7e5867d36",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1485.4
                    ],
                    [
                        136.0,
                        1513.1
                    ],
                    [
                        286.1,
                        1513.1
                    ],
                    [
                        286.1,
                        1485.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.70603,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "95fe88ff3f43abb1262f88067a0fcc49"
        },
        "text": "A. MazeBase",
        "type": "Title"
    },
    {
        "element_id": "c7a2e097e16509e4fd092cb715883cb2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1124.1
                    ],
                    [
                        866.6,
                        1550.9
                    ],
                    [
                        1567.2,
                        1550.9
                    ],
                    [
                        1567.2,
                        1124.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95165,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "bd62f4a6b8928205ea349ab7e5867d36"
        },
        "text": "Due to the critical importance of parameters TM and TS to the algorithm, their values are determined through exper- iments. We conducted an experiment to show the results of their sensitivity. Then, we selected appropriate values of TM and TS. The results are illustrated in Fig. 4 and Tables I\u2013III. In the figures of all the experimental results, the X -axis is the number of training epochs; the Y -axis denotes the success rate, i.e., the ratio of the number of successfully completed tasks to the total tasks in each epoch. In the tables of all the experimental results, the maximum reward is the highest reward obtained during the completion of each task, and the average reward is calculated by dividing the total reward by the number of epochs.",
        "type": "NarrativeText"
    },
    {
        "element_id": "396af22fb3979c92d3809abe3b31c17c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        133.3,
                        1528.3
                    ],
                    [
                        133.3,
                        1755.4
                    ],
                    [
                        836.3,
                        1755.4
                    ],
                    [
                        836.3,
                        1528.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95622,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "bd62f4a6b8928205ea349ab7e5867d36"
        },
        "text": "In the \u201cKey-Door\u201d task of MazeBase [40], the environment is two rooms with a door, as shown in Fig. 3. The eventual goal for the agent is to reach the location of the treasure. To achieve this goal, the agent needs to first determine the location of the key, move to the location of the key, and pick it up. Then, the agent needs to search where the door is, move there to open the door, and finally enter the other room to find the treasure.",
        "type": "NarrativeText"
    },
    {
        "element_id": "06f2c5de5eed840e198fe4cf8c1b2d36",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.8,
                        1761.0
                    ],
                    [
                        134.8,
                        2087.5
                    ],
                    [
                        834.8,
                        2087.5
                    ],
                    [
                        834.8,
                        1761.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95147,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "bd62f4a6b8928205ea349ab7e5867d36"
        },
        "text": "As shown in Fig. 3, the experiment involves three tasks, and the position of every element in the tasks is randomly generated in each game. We consider the different sizes of the three task environments, which are 7 \u00d7 7 and 9 \u00d7 9. Each task is tested three times independently for each map size. The mean and standard deviation of the test results are calculated. In the first task, the agent searches for the target [see Fig. 3 (left)]. A target is randomly placed in the room. If the agent finds the target and moves to the location, the task is completed. Task 1 is the simplest of the search tasks. In the",
        "type": "NarrativeText"
    },
    {
        "element_id": "fc61a0e8aa11ba07f1aaa5793eb97171",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1556.5
                    ],
                    [
                        866.6,
                        1883.0
                    ],
                    [
                        1569.0,
                        1883.0
                    ],
                    [
                        1569.0,
                        1556.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95743,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "bd62f4a6b8928205ea349ab7e5867d36"
        },
        "text": "According to Fig. 4 and Tables I\u2013III, it can be observed that as TM and TS increase, the success rate of HGR improves more rapidly, and HGR also attains higher average and maximum rewards. The experimental results align with our expectations. Theoretically, a larger TS allows student to explore a wider range of the environment and enhance its ability to accomplish tasks. As TM and TS increase, the performance of HGR will improve, but the time cost will also increase. To balance algorithm performance and time cost, we set TM = 5, TS = 7 in three tasks of MazeBase.",
        "type": "NarrativeText"
    },
    {
        "element_id": "7328c0cf350352b1eca11733f86eeae3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1887.9
                    ],
                    [
                        866.6,
                        2082.3
                    ],
                    [
                        1566.4,
                        2082.3
                    ],
                    [
                        1566.4,
                        1887.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95337,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "bd62f4a6b8928205ea349ab7e5867d36"
        },
        "text": "After determining the values of parameters TM and TS of HGR, we conducted experiments for the performance compar- ison of four algorithms. The experimental results are shown in Fig. 5. The green line is the result of our HGR algorithm. The results of SNN4HRL, HSP, and HRAC are marked in yellow, magenta, and spring-green, respectively.",
        "type": "NarrativeText"
    },
    {
        "element_id": "0a2d96940ab13e8925ebeaeaabfc8cfa",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.6
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79221,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 6,
            "parent_id": "bd62f4a6b8928205ea349ab7e5867d36"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:23:24 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ccb1d49d5ce5da3ad24f760d54084d41",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        320.4,
                        25.2
                    ],
                    [
                        320.4,
                        46.1
                    ],
                    [
                        1510.0,
                        46.1
                    ],
                    [
                        1510.0,
                        25.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82037,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "type": "Header"
    },
    {
        "element_id": "b90d1c8568cc31b5ccd4288930b4acea",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        83.4
                    ],
                    [
                        136.0,
                        104.6
                    ],
                    [
                        1135.3,
                        104.6
                    ],
                    [
                        1135.3,
                        83.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82795,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7,
            "parent_id": "ccb1d49d5ce5da3ad24f760d54084d41"
        },
        "text": "LIU et al.: BOOSTING REINFORCEMENT LEARNING VIA HIERARCHICAL GAME PLAYING WITH STATE RELAY",
        "type": "NarrativeText"
    },
    {
        "element_id": "75cc086e3d1377ba9f28a059b89af63f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        141.6,
                        151.1
                    ],
                    [
                        141.6,
                        460.6
                    ],
                    [
                        575.0,
                        460.6
                    ],
                    [
                        575.0,
                        151.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82336,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-7-3.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "41bfa72df63c3fb475d3fb41003ffee1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        646.0,
                        154.2
                    ],
                    [
                        646.0,
                        461.4
                    ],
                    [
                        1061.1,
                        461.4
                    ],
                    [
                        1061.1,
                        154.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.7999,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-7-4.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "e05a8c97fd26c7133d6a82753080e7c3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        645.0,
                        161.2
                    ],
                    [
                        645.0,
                        213.1
                    ],
                    [
                        692.9,
                        213.1
                    ],
                    [
                        692.9,
                        161.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-7-5.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "3b5469846b52c15e830cc6bf35c7cf0b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1124.6,
                        152.0
                    ],
                    [
                        1124.6,
                        463.3
                    ],
                    [
                        1562.7,
                        463.3
                    ],
                    [
                        1562.7,
                        152.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84614,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-7-6.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "P",
        "type": "Image"
    },
    {
        "element_id": "23c313c43270c7101bf778844d724f78",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.9,
                        493.3
                    ],
                    [
                        135.9,
                        516.7
                    ],
                    [
                        562.6,
                        516.7
                    ],
                    [
                        562.6,
                        493.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.63092,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "Fig. 3. MazeBase experimental environment.",
        "type": "FigureCaption"
    },
    {
        "element_id": "568c4c413b79dc773a31ca3e69d19b20",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        137.6,
                        542.2
                    ],
                    [
                        137.6,
                        959.9
                    ],
                    [
                        1569.2,
                        959.9
                    ],
                    [
                        1569.2,
                        542.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92895,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-7-7.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "Search_goal Experiment Search_key Experiment Search_treasure Experiment Success rate 02 \u2014 T=3,Ts=5 \u2014 T=5,Ts=7 \u2014 \u2122T=7,Ts=9 \u2014 Tw =9,Ts=11 06 Success rate os Success rate \u201c0 75 100 125 150 17.5 20.0 15 5 \u00bb 3 4 0 20 40 oo 80 100 Epochs (a) % Epochs (b) Epochs \u00a9)",
        "type": "Image"
    },
    {
        "element_id": "a724c2f5613683ffce82f9acadea2096",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        123.6,
                        982.6
                    ],
                    [
                        123.6,
                        1030.4
                    ],
                    [
                        1572.0,
                        1030.4
                    ],
                    [
                        1572.0,
                        982.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.85721,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "Fig. 4. Result comparison with different TM and TS under the MazeBase experiment. (a) Test results of Task 1. (b) Test results of Task 2. (c) Test results of Task 3.",
        "type": "FigureCaption"
    },
    {
        "element_id": "993a7355d5eb969e1e681a9b01f9a8e2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        441.0,
                        1093.2
                    ],
                    [
                        441.0,
                        1115.3
                    ],
                    [
                        533.2,
                        1115.3
                    ],
                    [
                        533.2,
                        1093.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.5054,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "TABLE I",
        "type": "FigureCaption"
    },
    {
        "element_id": "6143d22c2861999c813640ff0f058fe0",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1165.7,
                        1093.2
                    ],
                    [
                        1165.7,
                        1115.3
                    ],
                    [
                        1266.9,
                        1115.3
                    ],
                    [
                        1266.9,
                        1093.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.50951,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "TABLE III",
        "type": "FigureCaption"
    },
    {
        "element_id": "ecbd8e0772cc06c9ee1b30024fe164d7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        234.0,
                        1125.9
                    ],
                    [
                        234.0,
                        1173.4
                    ],
                    [
                        733.8,
                        1173.4
                    ],
                    [
                        733.8,
                        1125.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.39588,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "REWARD COMPARISON WITH DIFFERENT TM AND TS IN TASK 1 OF MAZEBASE",
        "type": "FigureCaption"
    },
    {
        "element_id": "584e801d2905b645455b5fed21a590f2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        964.1,
                        1125.9
                    ],
                    [
                        964.1,
                        1173.4
                    ],
                    [
                        1466.3,
                        1173.4
                    ],
                    [
                        1466.3,
                        1125.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.38506,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "REWARD COMPARISON WITH DIFFERENT TM AND TS IN TASK 3 OF MAZEBASE",
        "type": "FigureCaption"
    },
    {
        "element_id": "81265ca67b7a3c9743108e9c9cc5f9f6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        146.4,
                        1187.6
                    ],
                    [
                        146.4,
                        1351.5
                    ],
                    [
                        819.6,
                        1351.5
                    ],
                    [
                        819.6,
                        1187.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90457,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-7-1.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7,
            "text_as_html": "<table><thead><tr><th>Parameter value</th><th>Maximum reward</th><th>Average reward</th></tr></thead><tbody><tr><td>HGR(Ty = 3,Ts = 5)</td><td>5,538</td><td>2,645</td></tr><tr><td>HGR(Ty = 5,Ts = 7)</td><td>5,671</td><td>2,784</td></tr><tr><td>HGR(Tu = 7,Ts = 9)</td><td>5,697</td><td>2,848</td></tr><tr><td>HGR(Ty = 9,Ts = 11)</td><td>5,706</td><td>2,872</td></tr></tbody></table>"
        },
        "text": "Parameter value Maximum reward Average reward HGR(Ty = 3,Ts = 5) 5,538 2,645 HGR(Ty = 5,Ts = 7) 5,671 2,784 HGR(Ty = 7,Ts = 9) 5,697 2,848 HGR(Ty = 9,Ts = 11) 5,706 2,872",
        "type": "Table"
    },
    {
        "element_id": "3e60959c12ce48b9bdcaf47acccccbbb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.1,
                        1172.8
                    ],
                    [
                        877.1,
                        1340.2
                    ],
                    [
                        1552.3,
                        1340.2
                    ],
                    [
                        1552.3,
                        1172.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88355,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-7-2.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7,
            "text_as_html": "<table><thead><tr><th>Parameter value</th><th>Maximum reward</th><th>Average reward</th></tr></thead><tbody><tr><td>HGR(T'y =</td><td>20,528</td><td>9,131</td></tr><tr><td>HGR(Ty</td><td>29,168</td><td>15,973</td></tr><tr><td>HGR =</td><td>29,194</td><td>16,224</td></tr><tr><td>HGR(Ty, = 9, Ts = 11)</td><td>29,244</td><td>16,268</td></tr></tbody></table>"
        },
        "text": "Parameter value Maximum reward Average reward HGR(Ty = 3, Ts = 5) 20,528 9,131 HGRTw = 5, Ts = 7) 29,168 15,973 HGR(Ty = 7,Ts = 9) 29,194 16,224 HGR(T'y = 9, Ts = 11) 29,244 16,268",
        "type": "Table"
    },
    {
        "element_id": "40b744de281cbb0c36c458acec001f2a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        437.7,
                        1387.6
                    ],
                    [
                        437.7,
                        1409.7
                    ],
                    [
                        532.5,
                        1409.7
                    ],
                    [
                        532.5,
                        1387.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.46746,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "TABLE II",
        "type": "Title"
    },
    {
        "element_id": "3551b7fc74b63c9e89705f50a8220e95",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        233.7,
                        1420.3
                    ],
                    [
                        233.7,
                        1467.8
                    ],
                    [
                        735.9,
                        1467.8
                    ],
                    [
                        735.9,
                        1420.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.30271,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "REWARD COMPARISON WITH DIFFERENT TM AND TS IN TASK 2 OF MAZEBASE",
        "type": "Title"
    },
    {
        "element_id": "03e135a7dc7ebd45c09b261c7af2faed",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        148.1,
                        1487.1
                    ],
                    [
                        148.1,
                        1645.8
                    ],
                    [
                        813.0,
                        1645.8
                    ],
                    [
                        813.0,
                        1487.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91693,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-7-3.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7,
            "parent_id": "3551b7fc74b63c9e89705f50a8220e95",
            "text_as_html": "<table><thead><tr><th>HGR(Ty =</th><th>3,Ts = 5)</th><th>10,184</th><th>Average 4,534</th></tr></thead><tbody><tr><td>HGR(Tu =</td><td>5,Ts = 7)</td><td>10,367</td><td>4,933</td></tr><tr><td>HGR(Tu =</td><td>7,Ts = 9)</td><td>10,322</td><td>4,993</td></tr><tr><td>HGR(Ty =</td><td>9,Ts = 11)</td><td>10,477</td><td>5,079</td></tr></tbody></table>"
        },
        "text": "Parameter value Maximum reward O Average reward HGR(Ty = 3,Ts = 5) 10,184 4,534 HGR(T = 5, Ts = 7) 10,367 4,933 HGR(Ty = 7,Ts = 9) 10,322 4,993 HGRTy = 9,Ts = 11) 10,477 5,079",
        "type": "Table"
    },
    {
        "element_id": "3fcff30e2bc0d0287772e6a03c3b378f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1694.6
                    ],
                    [
                        136.0,
                        2087.5
                    ],
                    [
                        833.4,
                        2087.5
                    ],
                    [
                        833.4,
                        1694.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95588,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7,
            "parent_id": "3551b7fc74b63c9e89705f50a8220e95"
        },
        "text": "Due to the simplicity of Task 1, all these algorithms can train the agents to gain a high success rate. However, the SNN4HRL [14] algorithm is much lower than HSP [30], HRAC [20], and our HGR. During training, HRAC\u2019s initial success rate is lower than that of HSP but later exceeds that of HSP and eventually approaches that of HGR. Similarly, in Tasks 2 and 3, HRAC\u2019s initial success rate is lowest but later exceeds SNN4HRL and HSP, eventually approaching HGR. For the second task, the convergence speed and success rate of the SNN4HRL algorithm are lower than those of HSP. For the most difficult task, Task 3, the initial convergence of SNN4HRL is lower than that of HSP but eventually slightly",
        "type": "NarrativeText"
    },
    {
        "element_id": "6340ee073a2efa2c9e7807bba6cf1f92",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1395.7
                    ],
                    [
                        866.6,
                        1556.2
                    ],
                    [
                        1564.5,
                        1556.2
                    ],
                    [
                        1564.5,
                        1395.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94761,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7,
            "parent_id": "3551b7fc74b63c9e89705f50a8220e95"
        },
        "text": "exceeds that of HSP. Moreover, the convergence speed and success rate of SNN4HRL, HSP, and HRAC are significantly lower than those of HGR, indicating that our proposed method can be used to improve the performance of the state-of-the-art HRL algorithm even in complex tasks.",
        "type": "NarrativeText"
    },
    {
        "element_id": "acae7d30ad7dbf4006fc279c6b349a6e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1561.7
                    ],
                    [
                        866.6,
                        1821.9
                    ],
                    [
                        1566.8,
                        1821.9
                    ],
                    [
                        1566.8,
                        1561.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95613,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7,
            "parent_id": "3551b7fc74b63c9e89705f50a8220e95"
        },
        "text": "Relative experiments are conducted separately to show the effects of the relay mechanism and the auxiliary penalty mechanism. The results are shown in Fig. 6. The magenta line is the result of the baseline algorithm HSP [30]. The red line is the result of the auxiliary penalty mechanism (Only + Auxiliary Penalty), and the black line is that of the relay mechanism (Only + Relay). The dodger blue line is the joint effect of the two mechanisms (Auxiliary Penalty + Relay).",
        "type": "NarrativeText"
    },
    {
        "element_id": "f382480673ab90723148cd4ed9a5e3eb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1827.4
                    ],
                    [
                        866.6,
                        2087.5
                    ],
                    [
                        1564.0,
                        2087.5
                    ],
                    [
                        1564.0,
                        1827.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.951,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7,
            "parent_id": "3551b7fc74b63c9e89705f50a8220e95"
        },
        "text": "For Task 1, the convergence speed of the auxiliary penalty mechanism is slightly superior to that of the relay mechanism. For Task 2, the effects of the two mechanisms are similar. For Task 3, the incipient training is faster for the auxiliary penalty mechanism; however, after 20 epochs, the effect of the relay mechanism is improved. In addition, the best overall result can be seen after using both the mechanisms rather than each mechanism alone, and the success rate is also the highest,",
        "type": "NarrativeText"
    },
    {
        "element_id": "8bd8da27c264096697a9955931a9441c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.4
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.75668,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7,
            "parent_id": "3551b7fc74b63c9e89705f50a8220e95"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:23:24 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3c59ae1c80fa968f2763e60139cb06d0",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1552.7,
                        84.0
                    ],
                    [
                        1552.7,
                        104.6
                    ],
                    [
                        1565.2,
                        104.6
                    ],
                    [
                        1565.2,
                        84.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.71496,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 7
        },
        "text": "7",
        "type": "Header"
    },
    {
        "element_id": "accf9e31698623bc4d49f76a7f3573b8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        320.5,
                        25.2
                    ],
                    [
                        320.5,
                        46.1
                    ],
                    [
                        1510.5,
                        46.1
                    ],
                    [
                        1510.5,
                        25.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79921,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8
        },
        "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "type": "Header"
    },
    {
        "element_id": "67d2421bcfb5445ba70d241c8ada3d6d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.9,
                        84.9
                    ],
                    [
                        134.9,
                        105.2
                    ],
                    [
                        147.4,
                        105.2
                    ],
                    [
                        147.4,
                        84.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73307,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8
        },
        "text": "8",
        "type": "Header"
    },
    {
        "element_id": "d085f0233b34a3009fa464433de17ee5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        885.8,
                        84.7
                    ],
                    [
                        885.8,
                        104.6
                    ],
                    [
                        1566.7,
                        104.6
                    ],
                    [
                        1566.7,
                        84.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.68436,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "67d2421bcfb5445ba70d241c8ada3d6d"
        },
        "text": "IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS",
        "type": "NarrativeText"
    },
    {
        "element_id": "24b2d07c6ac1243bace55d7d2f78d928",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.9,
                        142.0
                    ],
                    [
                        136.9,
                        563.8
                    ],
                    [
                        1562.6,
                        563.8
                    ],
                    [
                        1562.6,
                        142.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93743,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-8-8.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8
        },
        "text": "Search_goal Experiment Search_key Experiment Search_treasure Experiment 1.0 1.0 o as 08 08 2 2 \u00a3 3 B06 #06 10.6 al a 3 3 3 8 8 8 g goa Sos a a a \u00b0. \u2018 \u2014\u2014 SNN4HRL \u2014\u2014 SNN4HRL \u2014 SNN4HRL \u2014 HRAC 02 \u2014 HSP oe \u2014 HRAC \u2014 ASP \u2014 HRAC \u2014 ASP 0.2 \u2014 HGR a \u2014 HGR oo \u2014 HGR 25 so 75 100 125 150 17.5 20.0 5 5 0 6 20 2 oo 3 40 0 20 0 6 80 100 Epochs Epochs Epochs (a) (b) ()",
        "type": "Image"
    },
    {
        "element_id": "2da7c9765e8f27a6ffc3b40f381dbbfc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        592.6
                    ],
                    [
                        136.0,
                        614.7
                    ],
                    [
                        1474.9,
                        614.7
                    ],
                    [
                        1474.9,
                        592.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79052,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8
        },
        "text": "Fig. 5. Algorithm comparison under the MazeBase experiment. (a) Test results of Task 1. (b) Test results of Task 2. (c) Test results of Task 3.",
        "type": "FigureCaption"
    },
    {
        "element_id": "9b7217b096e752a84e39ab40c9b88ce3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        141.5,
                        642.3
                    ],
                    [
                        141.5,
                        1059.9
                    ],
                    [
                        1564.6,
                        1059.9
                    ],
                    [
                        1564.6,
                        642.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93815,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-8-9.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8
        },
        "text": "Search_goal Experiment Search_key Experiment Search_treasure Experiment 1.0 1.0 o 0.8 08 os 2 2 \u00a3 \u00e9 Eos Eos glo al a! 3 3 g z z bi a Aus Gos 04 7 \u2014 asp \u2014 asp yi \u2014 Oniy+Ausiliary Penalty a2 \u2014 Only+Ausiliary Penalty ae \u2014 Only+Auxiliary Penalty \u2014 Only+Relay \u2014 Only+Relay \u2014 OnlytRelay 02 \u2014 HGR(Auxiliary Penalty+Relay) \u2014 HGR(Auxiliary Penalty+Relay) \u2014 HGR(Auxiliary Penalty+Relay) 25 so 75 100 125 150 17.5 20.0 5 5 0 6 20 2 oo 3 40 0 20 0 6 80 100 Epochs Epochs Epochs (a) (b) \u00a9)",
        "type": "Image"
    },
    {
        "element_id": "381a7ab1433bf7ce7669b89c46c3ae6e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.1,
                        648.4
                    ],
                    [
                        136.1,
                        1020.9
                    ],
                    [
                        605.6,
                        1020.9
                    ],
                    [
                        605.6,
                        648.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-8-10.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8
        },
        "text": "Search_goal Experiment 1.0 0.8 2 \u00e9 glo 3 z a 04 \u2014 asp \u2014 Oniy+Ausiliary Penalty \u2014 Only+Relay 02 \u2014 HGR(Auxiliary Penalty+Relay) 25 so 75 100 125 150 17.5 20.0 Epochs",
        "type": "Image"
    },
    {
        "element_id": "1baec5d4632fb68f83834fa25b356858",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.3,
                        1082.0
                    ],
                    [
                        135.3,
                        1129.0
                    ],
                    [
                        1565.6,
                        1129.0
                    ],
                    [
                        1565.6,
                        1082.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.8767,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8
        },
        "text": "Fig. 6. Comparison of different mechanisms of the HGR algorithm under the MazeBase experiment. (a) Test results of Task 1. (b) Test results of Task 2. (c) Test results of Task 3.",
        "type": "FigureCaption"
    },
    {
        "element_id": "c2dfcf2ad9ec57a06b20e1b1fb4f9793",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        434.5,
                        1195.8
                    ],
                    [
                        434.5,
                        1218.0
                    ],
                    [
                        534.9,
                        1218.0
                    ],
                    [
                        534.9,
                        1195.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8
        },
        "text": "TABLE IV",
        "type": "Title"
    },
    {
        "element_id": "b3870909bb6c508737e69e49e248fed9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        243.4,
                        1216.1
                    ],
                    [
                        243.4,
                        1251.2
                    ],
                    [
                        730.2,
                        1251.2
                    ],
                    [
                        730.2,
                        1216.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.28203,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "c2dfcf2ad9ec57a06b20e1b1fb4f9793"
        },
        "text": "REWARD COMPARISON IN TASK 1 OF MAZEBASE",
        "type": "FigureCaption"
    },
    {
        "element_id": "0cab2e323f0403f5a85ad2dd20c1f78e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        983.1,
                        1195.5
                    ],
                    [
                        983.1,
                        1251.2
                    ],
                    [
                        1450.9,
                        1251.2
                    ],
                    [
                        1450.9,
                        1195.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.40011,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "c2dfcf2ad9ec57a06b20e1b1fb4f9793"
        },
        "text": "TABLE VI REWARD COMPARISON IN TASK 3 OF MAZEBASE",
        "type": "FigureCaption"
    },
    {
        "element_id": "25abe8739d25f42a5ea790d6623c27c2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        137.6,
                        1262.5
                    ],
                    [
                        137.6,
                        1430.1
                    ],
                    [
                        809.3,
                        1430.1
                    ],
                    [
                        809.3,
                        1262.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84186,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-8-4.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "c2dfcf2ad9ec57a06b20e1b1fb4f9793",
            "text_as_html": "<table><thead><tr><th>Algorithm</th><th>Maximum reward</th><th>Average reward</th></tr></thead><tbody><tr><td>SNN4HRL</td><td>5,618</td><td>2,597</td></tr><tr><td>HSP</td><td>5,640</td><td>2,686</td></tr><tr><td>HRAC</td><td>5,657</td><td>2711</td></tr><tr><td>HGR</td><td>5,671</td><td>2,784</td></tr></tbody></table>"
        },
        "text": "Algorithm Maximum reward Average reward SNN4HRL 5,618 2,597 HSP 5,640 2,686 HRAC 5,657 2,711 HGR 5,671 2,784",
        "type": "Table"
    },
    {
        "element_id": "46f03ee276106b3e03b5571385e65894",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        909.0,
                        1271.0
                    ],
                    [
                        909.0,
                        1357.0
                    ],
                    [
                        1022.0,
                        1357.0
                    ],
                    [
                        1022.0,
                        1271.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8
        },
        "text": "Algorithm SNN4HRL HSP",
        "type": "Title"
    },
    {
        "element_id": "efeda57c83484a8b16594031c4a996a6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        931.0,
                        1370.0
                    ],
                    [
                        931.0,
                        1388.0
                    ],
                    [
                        999.0,
                        1388.0
                    ],
                    [
                        999.0,
                        1370.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8
        },
        "text": "HRAC",
        "type": "Title"
    },
    {
        "element_id": "99b13be037d3798afc571dbc9b62df13",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        939.0,
                        1401.0
                    ],
                    [
                        939.0,
                        1419.0
                    ],
                    [
                        992.0,
                        1419.0
                    ],
                    [
                        992.0,
                        1401.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8
        },
        "text": "HGR",
        "type": "Title"
    },
    {
        "element_id": "45ee1b9fa5261c003743485d70311759",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1095.0,
                        1275.0
                    ],
                    [
                        1095.0,
                        1293.0
                    ],
                    [
                        1280.0,
                        1293.0
                    ],
                    [
                        1280.0,
                        1275.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8
        },
        "text": "Maximum reward",
        "type": "Title"
    },
    {
        "element_id": "181ee27f2c20c6ebf2608b3db0da1cbb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1153.0,
                        1308.0
                    ],
                    [
                        1153.0,
                        1421.0
                    ],
                    [
                        1222.0,
                        1421.0
                    ],
                    [
                        1222.0,
                        1308.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "45ee1b9fa5261c003743485d70311759"
        },
        "text": "28,912 27,265 29,001 29,168",
        "type": "UncategorizedText"
    },
    {
        "element_id": "19c6ae2b860a075a1e0d4b20a35bc6d3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1353.0,
                        1275.0
                    ],
                    [
                        1353.0,
                        1422.0
                    ],
                    [
                        1515.0,
                        1422.0
                    ],
                    [
                        1515.0,
                        1275.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "45ee1b9fa5261c003743485d70311759"
        },
        "text": "Average reward 12,798 14,539 14,295 15,973",
        "type": "UncategorizedText"
    },
    {
        "element_id": "e51ce3b2291dc0f297e0d45bbb29bf35",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        436.5,
                        1483.2
                    ],
                    [
                        436.5,
                        1505.3
                    ],
                    [
                        532.9,
                        1505.3
                    ],
                    [
                        532.9,
                        1483.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.41344,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8
        },
        "text": "TABLE V",
        "type": "Title"
    },
    {
        "element_id": "e4e79c366663e3b61ed673ca889cce44",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        252.5,
                        1516.4
                    ],
                    [
                        252.5,
                        1538.5
                    ],
                    [
                        716.9,
                        1538.5
                    ],
                    [
                        716.9,
                        1516.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.50685,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "e51ce3b2291dc0f297e0d45bbb29bf35"
        },
        "text": "REWARD COMPARISON IN TASK 2 OF MAZEBASE",
        "type": "FigureCaption"
    },
    {
        "element_id": "083beedb1812d092fb8ac956fa2a01d5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        140.3,
                        1548.6
                    ],
                    [
                        140.3,
                        1716.9
                    ],
                    [
                        809.4,
                        1716.9
                    ],
                    [
                        809.4,
                        1548.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9128,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-8-5.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "e51ce3b2291dc0f297e0d45bbb29bf35",
            "text_as_html": "<table><thead><tr><th>Algorithm</th><th>Maximum reward</th><th>Average reward</th></tr></thead><tbody><tr><td>SNN4HRL</td><td>9,996</td><td>4,290</td></tr><tr><td>HSP</td><td>10,258</td><td>4,689</td></tr><tr><td>HRAC</td><td>10,482</td><td>4,465</td></tr><tr><td>HGR</td><td>10,503</td><td>4,933</td></tr></tbody></table>"
        },
        "text": "Algorithm Maximum reward Average reward SNN4HRL 9,996 4,290 HSP 10,258 4,689 HRAC 10,482 4,465 HGR 10,503 4,933",
        "type": "Table"
    },
    {
        "element_id": "e92ecc697c47c260b20e67ef55fe93c7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1495.3
                    ],
                    [
                        866.6,
                        1722.2
                    ],
                    [
                        1568.5,
                        1722.2
                    ],
                    [
                        1568.5,
                        1495.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95446,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "e51ce3b2291dc0f297e0d45bbb29bf35"
        },
        "text": "three tasks, HRAC\u2019s maximum reward is higher than that of HSP and SNN4HRL. HSP\u2019s average reward is slightly lower than that of HRAC only in Task 1. In other tasks, HSP\u2019s average reward is higher than HRAC and SNN4HRL. In all the tasks, HGR has the highest value in maximum and average reward, which demonstrates the excellent ability of HGR to complete tasks.",
        "type": "NarrativeText"
    },
    {
        "element_id": "cc0848f94a018e0208695265275bf509",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.9,
                        1794.2
                    ],
                    [
                        135.9,
                        1855.1
                    ],
                    [
                        833.4,
                        1855.1
                    ],
                    [
                        833.4,
                        1794.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91851,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "e51ce3b2291dc0f297e0d45bbb29bf35"
        },
        "text": "indicating the joint effect of these two mechanisms on the overall performance.",
        "type": "NarrativeText"
    },
    {
        "element_id": "7b19376afa3f211da2d14a3c24d2ce5a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1860.6
                    ],
                    [
                        136.0,
                        1987.9
                    ],
                    [
                        837.5,
                        1987.9
                    ],
                    [
                        837.5,
                        1860.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93815,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "e51ce3b2291dc0f297e0d45bbb29bf35"
        },
        "text": "To further show the performance of the proposed algorithm, we report the maximum reward and average reward that the training agent receives in Tasks 1\u20133 of MazeBase in Tables IV\u2013IX.",
        "type": "NarrativeText"
    },
    {
        "element_id": "0185b59bbdb730123a7b17fa83a9ec96",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1993.1
                    ],
                    [
                        136.0,
                        2087.5
                    ],
                    [
                        836.2,
                        2087.5
                    ],
                    [
                        836.2,
                        1993.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93077,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "e51ce3b2291dc0f297e0d45bbb29bf35"
        },
        "text": "Based on Tables IV\u2013VI, SNN4HRL\u2019s maximum reward exceeds that of HSP only in Task 3. In other tasks, SNN4HRL has the lowest average reward and maximum reward. In the",
        "type": "NarrativeText"
    },
    {
        "element_id": "6d8d35146dfe5e43d69e5a25eca17c35",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1727.2
                    ],
                    [
                        866.6,
                        2087.5
                    ],
                    [
                        1567.7,
                        2087.5
                    ],
                    [
                        1567.7,
                        1727.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95297,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "e51ce3b2291dc0f297e0d45bbb29bf35"
        },
        "text": "According to Tables VII\u2013IX, overall, the average and max- imum rewards of the relay mechanism are higher than those of the auxiliary penalty mechanism and most baselines. This proves that the relay mechanism can make full use of environ- mental information and play an important role in improving the performance of HGR. The average reward and maximum reward of the auxiliary penalty mechanism are higher than those of HSP and SNN4HRL. This shows that the auxiliary penalty mechanism is also a useful part of our algorithm. HGR endowed with these two mechanisms achieves the highest maximum reward and the highest average reward.",
        "type": "NarrativeText"
    },
    {
        "element_id": "2c66eec7522e3d9e0d2df63c99c6e649",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.1
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79083,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 8,
            "parent_id": "e51ce3b2291dc0f297e0d45bbb29bf35"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:23:24 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "fdaa654f0219d19fec40905a4d581aba",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        315.1,
                        26.2
                    ],
                    [
                        315.1,
                        46.1
                    ],
                    [
                        1510.0,
                        46.1
                    ],
                    [
                        1510.0,
                        26.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79714,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9
        },
        "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "type": "Header"
    },
    {
        "element_id": "58f5fb0adbc587d1f1bbe76f8ef5ccd1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        85.2
                    ],
                    [
                        136.0,
                        104.6
                    ],
                    [
                        1135.3,
                        104.6
                    ],
                    [
                        1135.3,
                        85.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.75465,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "fdaa654f0219d19fec40905a4d581aba"
        },
        "text": "LIU et al.: BOOSTING REINFORCEMENT LEARNING VIA HIERARCHICAL GAME PLAYING WITH STATE RELAY",
        "type": "NarrativeText"
    },
    {
        "element_id": "0add35e1a7104e301038740a98aff588",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        429.3,
                        161.3
                    ],
                    [
                        429.3,
                        183.5
                    ],
                    [
                        542.3,
                        183.5
                    ],
                    [
                        542.3,
                        161.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.6781,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "fdaa654f0219d19fec40905a4d581aba"
        },
        "text": "TABLE VII",
        "type": "Title"
    },
    {
        "element_id": "4fda02d51720a1af3394bd7927730700",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.6,
                        194.5
                    ],
                    [
                        136.6,
                        241.6
                    ],
                    [
                        832.8,
                        241.6
                    ],
                    [
                        832.8,
                        194.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.50771,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "0add35e1a7104e301038740a98aff588"
        },
        "text": "REWARD COMPARISON OF ABLATION EXPERIMENT IN TASK 1 OF MAZE- BASE",
        "type": "FigureCaption"
    },
    {
        "element_id": "db6db5cecd89b639d94b88d4d15a06b1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        137.9,
                        256.0
                    ],
                    [
                        137.9,
                        435.1
                    ],
                    [
                        829.1,
                        435.1
                    ],
                    [
                        829.1,
                        256.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92263,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-9-6.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "0add35e1a7104e301038740a98aff588",
            "text_as_html": "<table><thead><tr><th>Algorithm</th><th>Maximum reward</th><th>o Average reward</th></tr></thead><tbody><tr><td>Only+Auxiliary Penalty</td><td>5,643</td><td>2,746</td></tr><tr><td>Only+Relay</td><td>5,648</td><td>2,744</td></tr><tr><td>HGR(without fine-tuning stage)</td><td>1,765</td><td>820</td></tr><tr><td>HGR(without pretraining stage)</td><td>3,166</td><td>1,551</td></tr><tr><td>HGR</td><td>5,671</td><td>2,784</td></tr></tbody></table>"
        },
        "text": "Algorithm Maximum reward O Average reward Only+Auxiliary Penalty 5,643 2,746 _ Only+Relay 5,648 2,744 HGR(without fine-tuning stage) 1,765 820 HGR(without pretraining stage) 3,166 1,551 HGR 5,671 2184",
        "type": "Table"
    },
    {
        "element_id": "9cc0e442a876be2e2d026af2e49fd385",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        423.2,
                        483.9
                    ],
                    [
                        423.2,
                        506.0
                    ],
                    [
                        545.1,
                        506.0
                    ],
                    [
                        545.1,
                        483.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81107,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "fdaa654f0219d19fec40905a4d581aba"
        },
        "text": "TABLE VIII",
        "type": "Title"
    },
    {
        "element_id": "9b3eaa812cdfe9d8dc673c6084648718",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        238.9,
                        517.1
                    ],
                    [
                        238.9,
                        564.1
                    ],
                    [
                        727.1,
                        564.1
                    ],
                    [
                        727.1,
                        517.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.47645,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "fdaa654f0219d19fec40905a4d581aba"
        },
        "text": "REWARD COMPARISON OF ABLATION EXPERIMENT IN TASK 2 OF MAZEBASE",
        "type": "Title"
    },
    {
        "element_id": "c08a167c12dacde1c1221c671e70a0dc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        137.8,
                        581.1
                    ],
                    [
                        137.8,
                        759.2
                    ],
                    [
                        828.8,
                        759.2
                    ],
                    [
                        828.8,
                        581.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93729,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-9-7.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "9b3eaa812cdfe9d8dc673c6084648718",
            "text_as_html": "<table><thead><tr><th>Algorithm</th><th>Maximum reward</th><th>o Average reward</th></tr></thead><tbody><tr><td>Only+Auxiliary Penalty</td><td>10,264</td><td>4,804</td></tr><tr><td>Only+Relay</td><td>10,312</td><td>4,891</td></tr><tr><td>HGR(without fine-tuning stage)</td><td>3,432</td><td>1,660</td></tr><tr><td>HGR(without pretraining stage)</td><td>8,611</td><td>3,142</td></tr><tr><td>HGR</td><td>10,367</td><td>4,933</td></tr></tbody></table>"
        },
        "text": "Algorithm Maximum reward o Average reward Only+Auxiliary Penalty 10,264 4,804 Only+Relay 10,312 4,891 HGR(without fine-tuning stage) 3,432 1,660 HGR(without pretraining stage) 8,611 3,142 HGR 10,367 4,933",
        "type": "Table"
    },
    {
        "element_id": "019acd9a501344192ed522cc44bbbd1d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        434.5,
                        806.4
                    ],
                    [
                        434.5,
                        828.5
                    ],
                    [
                        534.9,
                        828.5
                    ],
                    [
                        534.9,
                        806.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.62168,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "fdaa654f0219d19fec40905a4d581aba"
        },
        "text": "TABLE IX",
        "type": "Title"
    },
    {
        "element_id": "ff44ca53e49e04f4fec5b3e9117043ff",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        236.8,
                        839.6
                    ],
                    [
                        236.8,
                        886.6
                    ],
                    [
                        728.4,
                        886.6
                    ],
                    [
                        728.4,
                        839.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.53621,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "019acd9a501344192ed522cc44bbbd1d"
        },
        "text": "REWARD COMPARISON OF ABLATION EXPERIMENT IN TASK 3 OF MAZEBASE",
        "type": "FigureCaption"
    },
    {
        "element_id": "041bb1fe5454ea2b8dc0cd336d28d4d9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.9,
                        900.4
                    ],
                    [
                        144.9,
                        1081.1
                    ],
                    [
                        821.2,
                        1081.1
                    ],
                    [
                        821.2,
                        900.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92317,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-9-8.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "019acd9a501344192ed522cc44bbbd1d",
            "text_as_html": "<table><thead><tr><th>Algorithm</th><th>Maximum reward</th><th>Average reward</th></tr></thead><tbody><tr><td>Only+Auxiliary Penalty</td><td>27,876</td><td>15,059</td></tr><tr><td>Only+Relay</td><td>28,607</td><td>15,589</td></tr><tr><td>HGR(without fine-tuning stage)</td><td>6,153</td><td>3,534</td></tr><tr><td>HGR(without pretraining stage)</td><td>19,398</td><td>8,586</td></tr><tr><td>HGR</td><td>29,168</td><td>15,973</td></tr></tbody></table>"
        },
        "text": "Algorithm Maximum reward O Average reward Only+Auxiliary Penalty 27,876 15,059 Only+Relay 28,607 15,589 HGR(without fine-tuning stage) 6,153 3,534 HGR(without pretraining stage) 19,398 8,586 HGR 29,168 15,973",
        "type": "Table"
    },
    {
        "element_id": "80a7712299823493ec021aefee2da283",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.1,
                        1130.4
                    ],
                    [
                        135.1,
                        1257.7
                    ],
                    [
                        833.4,
                        1257.7
                    ],
                    [
                        833.4,
                        1130.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93647,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "019acd9a501344192ed522cc44bbbd1d"
        },
        "text": "To demonstrate the impact of HGR\u2019s different stages on the experimental results, we conducted one additional abla- tion experiment. The results are illustrated in Fig. 7 and Tables VII\u2013IX.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3ca7d5618b4cda02ebfe5bebd97b888c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1263.2
                    ],
                    [
                        136.0,
                        1556.6
                    ],
                    [
                        834.9,
                        1556.6
                    ],
                    [
                        834.9,
                        1263.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95687,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "019acd9a501344192ed522cc44bbbd1d"
        },
        "text": "Fig. 7 and Tables VII\u2013IX show that HGR (without fine- tuning stage) has the worst performance, which shows that the high-level strategy of the hierarchical structure plays an important role in HGR. In addition, the HGR (without the pretraining stage) success rate is also slower than that of HGR. This shows that the game process truly helps student explore the environment. This ablation experiment proves that hierarchical structure and playing games between agents are important and take a key role in the effectiveness of HGR.",
        "type": "NarrativeText"
    },
    {
        "element_id": "542da5080ecbb144e65fa3151da43f6b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.6,
                        1615.4
                    ],
                    [
                        134.6,
                        1643.0
                    ],
                    [
                        266.0,
                        1643.0
                    ],
                    [
                        266.0,
                        1615.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72561,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "fdaa654f0219d19fec40905a4d581aba"
        },
        "text": "B. MuJoCo",
        "type": "Title"
    },
    {
        "element_id": "eec1fe4af6ce0c8037d372314e5c633a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1661.4
                    ],
                    [
                        136.0,
                        1755.4
                    ],
                    [
                        833.4,
                        1755.4
                    ],
                    [
                        833.4,
                        1661.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93184,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "542da5080ecbb144e65fa3151da43f6b"
        },
        "text": "The algorithms are then evaluated on the MuJoCo [41] platform. The environment of the AntGather in MuJoCo is shown in Fig. 8.",
        "type": "NarrativeText"
    },
    {
        "element_id": "229c4929013d6cffd6a838cc29de584d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1761.0
                    ],
                    [
                        136.0,
                        2087.5
                    ],
                    [
                        834.8,
                        2087.5
                    ],
                    [
                        834.8,
                        1761.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95535,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "542da5080ecbb144e65fa3151da43f6b"
        },
        "text": "The agent is an ant-like robot with four legs, which is placed in a coliseum with green and red objects. All the object positions are random in each round. If the ant robot touches a green object, the reward value is +1; if it is red, the reward is \u22121. If the agent jumps up in the Z -axis direction, it will be penalized by \u221210, and the round will terminate immediately. This setting increases the difficulty of the task because it inhibits the search and possibly introduces a local minimum. The ant agent must learn to stay still to avoid the penalty. Each round ends after a thousand steps.",
        "type": "NarrativeText"
    },
    {
        "element_id": "2bbad19370b808dd769e6d41c077fc33",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        161.7
                    ],
                    [
                        866.6,
                        654.4
                    ],
                    [
                        1567.2,
                        654.4
                    ],
                    [
                        1567.2,
                        161.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95149,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "542da5080ecbb144e65fa3151da43f6b"
        },
        "text": "A 125-D vector, including position, velocity, and joint angles, is taken as the observation value. The action of the agent is an 8-D vector, i.e., the movements of the eight joints of the ant. Although the actions are continuous, they are discretized into five 2-D vectors. Here, we use the difference version of the target encoder, as shown in (7). The distance function D is defined as the physical distance on the X \u2013Y -axis, and \u03f5 = 0.25. This means that the task is considered completed if student\u2019s final location is less than 0.25 from monitor\u2019s last location. During pretraining, each game contains four rounds. In each round, monitor takes TM = 50 steps as a series of actions, and student takes TS = 70 steps. In the fine-tuning stage, when training teacher, we also set TTea = TM . An entire action of the teacher also consists of 50 steps, and it can take 20 actions in a round.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f859d894d670b99e1e93d08f4c97d9ca",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        659.2
                    ],
                    [
                        866.6,
                        1052.8
                    ],
                    [
                        1568.4,
                        1052.8
                    ],
                    [
                        1568.4,
                        659.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95446,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "542da5080ecbb144e65fa3151da43f6b"
        },
        "text": "The values of TM and TS are also determined through experiments. We conducted an experiment to show the results of their sensitivity in AntGather. Then, we selected appropriate values of TM and TS. Each experiment is also run three times independently, and the mean of the experimental results is calculated, as illustrated in Fig. 9 and Table X. In the figures of all the experimental results, the X -axis is the number of training epochs; the Y -axis is the reward the agent obtains during training. In the tables of all the experimental results, the maximum reward is the highest reward obtained during the completion of each task, and the average reward is calculated by dividing the total reward by the number of epochs.",
        "type": "NarrativeText"
    },
    {
        "element_id": "1895dfb4e3b01215dd0e3a1def9f6013",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1058.3
                    ],
                    [
                        866.6,
                        1451.3
                    ],
                    [
                        1567.8,
                        1451.3
                    ],
                    [
                        1567.8,
                        1058.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95327,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "542da5080ecbb144e65fa3151da43f6b"
        },
        "text": "According to Fig. 9 and Table X, it can be observed that the general trend is still that as TM and TS increase, the reward of HGR improves more rapidly and attains higher average and maximum rewards. Although the maximum reward of HGR (TM = 70, TS = 90) is very close to that of HGR (TM = 90, TS = 110), the average reward of HGR (TM = 70, TS = 90) is 0.34 lower than that of HGR (TM = 90, TS = 110). Overall, student performs more steps, which is helpful for exploring the environment and learning policies. As TM and TS increase, the time cost will also increase. To balance algorithm performance and time cost, we set TM = 50, TS = 70 in the AntGather task of MuJoCo.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d72891c7e1235009382bf0571adc415b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1456.2
                    ],
                    [
                        866.6,
                        1916.2
                    ],
                    [
                        1569.7,
                        1916.2
                    ],
                    [
                        1569.7,
                        1456.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94829,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "542da5080ecbb144e65fa3151da43f6b"
        },
        "text": "After determining the values of parameters TM and TS of HGR in AntGather, we conducted experiments for the performance comparison of four algorithms. The experimental results are shown in Fig. 10. The green line is the result of the HGR algorithm proposed in this work. The magenta line is the result of the HSP algorithm [30]. The yellow line is the SNN4HRL algorithm [14]. The spring-green line is the HRAC algorithm [20]. Since AntGather is a challenging task, it can be seen from Fig. 10 that for the SNN4HRL algorithm, the reward converges to 0 after training for a long time, indicating that the agent cannot learn the correct policy. For the HSP algorithm [30], the reward value reaches more than 1.0, which indicates the effectiveness of the combination of hierarchical learning and self-play.",
        "type": "NarrativeText"
    },
    {
        "element_id": "e25e133b311e2a0862c2429ed3840d18",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1921.8
                    ],
                    [
                        866.6,
                        2082.3
                    ],
                    [
                        1568.5,
                        2082.3
                    ],
                    [
                        1568.5,
                        1921.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94041,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "542da5080ecbb144e65fa3151da43f6b"
        },
        "text": "The HRAC alleviates the goal space by restricting the high-level action space from the whole goal space to a k-step adjacent region of the current state using an adjacency constraint. The agent can gradually learn useful policies by effective subgoals proposed by the high level and obtain more",
        "type": "NarrativeText"
    },
    {
        "element_id": "f163956c008758ec4d3b80400d45c0c5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.4
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79491,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9,
            "parent_id": "542da5080ecbb144e65fa3151da43f6b"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:23:24 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "fb56956b76d2d624ad4daa218ee69976",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1552.5,
                        84.7
                    ],
                    [
                        1552.5,
                        104.9
                    ],
                    [
                        1565.1,
                        104.9
                    ],
                    [
                        1565.1,
                        84.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.71882,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 9
        },
        "text": "9",
        "type": "Header"
    },
    {
        "element_id": "5e22d3d306ed4727b3b7f2435734c843",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        321.9,
                        25.6
                    ],
                    [
                        321.9,
                        46.1
                    ],
                    [
                        1510.0,
                        46.1
                    ],
                    [
                        1510.0,
                        25.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79831,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10
        },
        "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "type": "Header"
    },
    {
        "element_id": "6fd426cdef6c22fc10e59f11fef13d64",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.5,
                        85.2
                    ],
                    [
                        134.5,
                        105.4
                    ],
                    [
                        156.1,
                        105.4
                    ],
                    [
                        156.1,
                        85.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.75059,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10
        },
        "text": "10",
        "type": "Header"
    },
    {
        "element_id": "7fd7d1299b91fe083c8a97f9cce235a3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        885.8,
                        84.9
                    ],
                    [
                        885.8,
                        104.6
                    ],
                    [
                        1566.8,
                        104.6
                    ],
                    [
                        1566.8,
                        84.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.6858,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10,
            "parent_id": "6fd426cdef6c22fc10e59f11fef13d64"
        },
        "text": "IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS",
        "type": "NarrativeText"
    },
    {
        "element_id": "9274ffda0a70664286e908c6838751f7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        138.1,
                        141.5
                    ],
                    [
                        138.1,
                        563.0
                    ],
                    [
                        1561.9,
                        563.0
                    ],
                    [
                        1561.9,
                        141.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93905,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-10-11.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10
        },
        "text": "Search_goal Experiment Search_key Experiment Search_treasure Experiment 1.0 10 1.0 09 -\u2014 L \u2014 HGR(without fine-tuning stage) \u2014\u2014 HGR(without fine-tuning stage) rel 08 \u2014 _HGR(without pretraining stage) os \u2014 _HGR(without pretraining stage) Hak ea, \u2014 HGR 6 6 \u00a3 Eos g us 2 a a Gos Goa Rg 04 an \u2014 HGR(without fine-tuning stage) CA 03 \u2014 _ HGR(without pretraining stage) \u2014 HGR 0.2 00 25 so 75 100 125 150 17.5 20.0 5 5 0 6 20 2 oo 3 40 5 20 0 & 80 100 Epochs Epochs Epochs (a) (b) (O)",
        "type": "Image"
    },
    {
        "element_id": "3805489500bda3253ece45583175ac5e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        132.7,
                        583.8
                    ],
                    [
                        132.7,
                        630.8
                    ],
                    [
                        1564.0,
                        630.8
                    ],
                    [
                        1564.0,
                        583.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87767,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10
        },
        "text": "Fig. 7. Impact of HGR\u2019s different stages on experimental results under the MazeBase experiment. (a) Test results of Task 1. (b) Test results of Task 2. (c) Test results of Task 3.",
        "type": "FigureCaption"
    },
    {
        "element_id": "8f93b64f4fc28dd43ae3af3f98aee536",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        240.6,
                        686.4
                    ],
                    [
                        240.6,
                        1095.8
                    ],
                    [
                        728.8,
                        1095.8
                    ],
                    [
                        728.8,
                        686.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-10-12.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "93e79e0cd91dd50524b4ce784962d6bb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        920.0,
                        686.4
                    ],
                    [
                        920.0,
                        1149.8
                    ],
                    [
                        1510.6,
                        1149.8
                    ],
                    [
                        1510.6,
                        686.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-10-13.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10
        },
        "text": "AntGather Experiment SNN4HRL Reward 100 200 300 Epochs 400 500",
        "type": "Image"
    },
    {
        "element_id": "4303fd2c4ba1ff2a9655ffec03c6c965",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        132.4,
                        1127.6
                    ],
                    [
                        132.4,
                        1150.4
                    ],
                    [
                        547.2,
                        1150.4
                    ],
                    [
                        547.2,
                        1127.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.66851,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10
        },
        "text": "Fig. 8. AntGather experiment environment.",
        "type": "FigureCaption"
    },
    {
        "element_id": "d2d01fddc46305eca151a0bfbba2f834",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        189.4,
                        1198.6
                    ],
                    [
                        189.4,
                        1673.3
                    ],
                    [
                        780.0,
                        1673.3
                    ],
                    [
                        780.0,
                        1198.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-10-14.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10
        },
        "text": "AntGather Experiment 2 1 ii = go 2 m a \u2014 Tm =30,Ts=50 \u2014 Tu=50,T5;=70 \u2014 Tu=70,Ts=90 4 \u2014 Tw =90,Ts=110 o 100 200 300 400 500 Epochs",
        "type": "Image"
    },
    {
        "element_id": "44f3cdda570ce4754e823be0f7aa6be8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        864.5,
                        1182.3
                    ],
                    [
                        864.5,
                        1204.4
                    ],
                    [
                        1474.9,
                        1204.4
                    ],
                    [
                        1474.9,
                        1182.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87984,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10
        },
        "text": "Fig. 10. Algorithm comparison under the AntGather experiment.",
        "type": "FigureCaption"
    },
    {
        "element_id": "ce149a3d66dc5465b3db0c381e33fe86",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1168.8,
                        1251.5
                    ],
                    [
                        1168.8,
                        1273.6
                    ],
                    [
                        1261.8,
                        1273.6
                    ],
                    [
                        1261.8,
                        1251.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10
        },
        "text": "TABLE X",
        "type": "Title"
    },
    {
        "element_id": "6ab285770a51ae909df35fb943a27140",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        979.0,
                        1284.2
                    ],
                    [
                        979.0,
                        1333.5
                    ],
                    [
                        1451.6,
                        1333.5
                    ],
                    [
                        1451.6,
                        1284.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.5572,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10,
            "parent_id": "ce149a3d66dc5465b3db0c381e33fe86"
        },
        "text": "REWARD COMPARISON WITH DIFFERENT TM AND TS IN ANTGATHER EXPERIMENT",
        "type": "FigureCaption"
    },
    {
        "element_id": "f0ea262c2116c0555409579b98c8841a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        871.4,
                        1346.3
                    ],
                    [
                        871.4,
                        1508.2
                    ],
                    [
                        1533.5,
                        1508.2
                    ],
                    [
                        1533.5,
                        1346.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92261,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-10-9.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10,
            "parent_id": "ce149a3d66dc5465b3db0c381e33fe86",
            "text_as_html": "<table><thead><tr><th>Parameter value</th><th>Maximum reward</th><th>Average reward</th></tr></thead><tbody><tr><td>FORM = 30, Ts = 50)</td><td>1.34</td><td>0.42</td></tr><tr><td>HGR(Tyy = 50,75 = 70)</td><td>1.69</td><td>0.83</td></tr><tr><td>HGR(Tyy = 70, Ts = 90)</td><td>1.90</td><td>0.95</td></tr><tr><td>HGR(Ty, = 90, Ts = 110)</td><td>1.99</td><td>1.29</td></tr></tbody></table>"
        },
        "text": "Parameter value Maximum reward Average reward HGR(Ty = 30, T's = 50) 1.34 0.42 HGR(Ty = 50, Ts = 70) 1.69 0.83 HGR(Ty = 70, Ts = 90) 1,90 0.95 HGR(Tyy = 90,Ts = 110) 1.99 1.29",
        "type": "Table"
    },
    {
        "element_id": "cd2e8710777d25535dcb71a4ffca5baf",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1163.5,
                        1556.3
                    ],
                    [
                        1163.5,
                        1578.4
                    ],
                    [
                        1268.9,
                        1578.4
                    ],
                    [
                        1268.9,
                        1556.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.57583,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10
        },
        "text": "TABLE XI",
        "type": "Title"
    },
    {
        "element_id": "0215340373a343e7fd2debef5fd680eb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        941.0,
                        1589.5
                    ],
                    [
                        941.0,
                        1611.6
                    ],
                    [
                        1494.4,
                        1611.6
                    ],
                    [
                        1494.4,
                        1589.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.41565,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10,
            "parent_id": "cd2e8710777d25535dcb71a4ffca5baf"
        },
        "text": "REWARD COMPARISON IN THE ANTGATHER EXPERIMENT",
        "type": "FigureCaption"
    },
    {
        "element_id": "95d09ce7a94d57eb9fc14d8606a49e3a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.2,
                        1696.9
                    ],
                    [
                        135.2,
                        1744.5
                    ],
                    [
                        833.4,
                        1744.5
                    ],
                    [
                        833.4,
                        1696.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90635,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10,
            "parent_id": "cd2e8710777d25535dcb71a4ffca5baf"
        },
        "text": "Fig. 9. Result comparison with different TM and TS under the AntGather experiment.",
        "type": "FigureCaption"
    },
    {
        "element_id": "f4422c7b21062d4ec7b0186fd80ef6a1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        875.2,
                        1626.9
                    ],
                    [
                        875.2,
                        1790.5
                    ],
                    [
                        1541.7,
                        1790.5
                    ],
                    [
                        1541.7,
                        1626.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90502,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-10-10.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10,
            "parent_id": "cd2e8710777d25535dcb71a4ffca5baf",
            "text_as_html": "<table><thead><tr><th>Algorithm</th><th>Maximum reward</th><th>Average reward</th></tr></thead><tbody><tr><td>SNN4HRL</td><td>0.048</td><td>-0.215</td></tr><tr><td>HSP</td><td>1.16</td><td>0.343</td></tr><tr><td>HRAC</td><td>1.30</td><td>0.419</td></tr><tr><td>HGR</td><td>1.69</td><td>0.832</td></tr></tbody></table>"
        },
        "text": "Algorithm Maximum reward Average reward SNN4HRL 0.048 -0.215 HSP 1.16 0.343 HRAC 1.30 0.419 HGR 1.69 0.832",
        "type": "Table"
    },
    {
        "element_id": "e8fb216d630ab45d5e912553804eb008",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1827.4
                    ],
                    [
                        136.0,
                        1921.5
                    ],
                    [
                        833.4,
                        1921.5
                    ],
                    [
                        833.4,
                        1827.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93397,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10,
            "parent_id": "cd2e8710777d25535dcb71a4ffca5baf"
        },
        "text": "rewards (0.14) than HSP, but the performance is still no better than HGR. Regarding the HGR algorithm, its reward is the highest (i.e., 1.69).",
        "type": "NarrativeText"
    },
    {
        "element_id": "e64dfd947dfb952f16daab8aae17ea55",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1927.0
                    ],
                    [
                        136.0,
                        2087.5
                    ],
                    [
                        833.9,
                        2087.5
                    ],
                    [
                        833.9,
                        1927.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93586,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10,
            "parent_id": "cd2e8710777d25535dcb71a4ffca5baf"
        },
        "text": "The reward value in the AntGather experiment is reported in Table XI. For SNN4HRL, both the maximum reward and average reward are inferior to those of the other algorithms. The HGR\u2019s maximum reward and the average reward are also the highest among the baselines. These",
        "type": "NarrativeText"
    },
    {
        "element_id": "9ef61a4a0916e024c5dea1a3d09f68a5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1860.6
                    ],
                    [
                        866.6,
                        1954.7
                    ],
                    [
                        1565.5,
                        1954.7
                    ],
                    [
                        1565.5,
                        1860.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92968,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10,
            "parent_id": "cd2e8710777d25535dcb71a4ffca5baf"
        },
        "text": "results further indicate that HGR can advance the perfor- mance of the state-of-the-art HRL algorithms in complex environments.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a8a7d778db89265e19c82dda35fa4ac6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1960.2
                    ],
                    [
                        866.6,
                        2087.5
                    ],
                    [
                        1564.2,
                        2087.5
                    ],
                    [
                        1564.2,
                        1960.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93507,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10,
            "parent_id": "cd2e8710777d25535dcb71a4ffca5baf"
        },
        "text": "To verify the effects of these two mechanisms proposed in HGR, each mechanism is tested separately. The results are shown in Fig. 11. The magenta line is the result of the baseline algorithm HSP [30]. The red line is the result of the auxiliary",
        "type": "NarrativeText"
    },
    {
        "element_id": "d5f8d9a06ceb52c12dea1944660a9b29",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.4
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.77466,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 10,
            "parent_id": "cd2e8710777d25535dcb71a4ffca5baf"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:23:24 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "49aa8c0d210db059573b34616403525c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        319.3,
                        25.4
                    ],
                    [
                        319.3,
                        46.1
                    ],
                    [
                        1510.0,
                        46.1
                    ],
                    [
                        1510.0,
                        25.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81048,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11
        },
        "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "type": "Header"
    },
    {
        "element_id": "6a50ebda586cf0c02d1d40e07a2e85c6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        83.8
                    ],
                    [
                        136.0,
                        104.6
                    ],
                    [
                        1138.1,
                        104.6
                    ],
                    [
                        1138.1,
                        83.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79393,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "49aa8c0d210db059573b34616403525c"
        },
        "text": "LIU et al.: BOOSTING REINFORCEMENT LEARNING VIA HIERARCHICAL GAME PLAYING WITH STATE RELAY",
        "type": "NarrativeText"
    },
    {
        "element_id": "691799ec015a4aa156f51754a29828fe",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        189.4,
                        150.2
                    ],
                    [
                        189.4,
                        624.9
                    ],
                    [
                        780.0,
                        624.9
                    ],
                    [
                        780.0,
                        150.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-11-15.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11
        },
        "text": "AntGather Experiment go = s z 5 4 cal \u2014 ASP \u2014 _Only+Auxiliary Penalty 2 \u2014 Only+Relay \u2014\u2014 HGR(Auxiliary Penalty+Relay) o 100 200 300 400 500 Epochs",
        "type": "Image"
    },
    {
        "element_id": "64f66d858fbe96f8d8e15f76ceb3a6f8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        920.0,
                        150.2
                    ],
                    [
                        920.0,
                        624.7
                    ],
                    [
                        1510.6,
                        624.7
                    ],
                    [
                        1510.6,
                        150.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-11-16.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11
        },
        "text": "AntGather Experiment 2 7 = s z & a, 6 \u2014 HGR6without fine-tuning stage) \u2014\u2014 HGR(without pretraining stage) \u2014 HGR - o 100 200 300 400 500 Epochs",
        "type": "Image"
    },
    {
        "element_id": "829cc992e2abf78fb7d08c5d0cae056d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.3,
                        649.0
                    ],
                    [
                        135.3,
                        696.1
                    ],
                    [
                        835.2,
                        696.1
                    ],
                    [
                        835.2,
                        649.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90436,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11
        },
        "text": "Fig. 11. Comparison of different mechanisms of the HGR algorithm under the AntGather experiment.",
        "type": "FigureCaption"
    },
    {
        "element_id": "795abe542408c0917e8f28df9525c957",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        648.8
                    ],
                    [
                        866.6,
                        695.9
                    ],
                    [
                        1565.4,
                        695.9
                    ],
                    [
                        1565.4,
                        648.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90661,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11
        },
        "text": "Fig. 12. Impact of HGR\u2019s different stages on the experimental results of the AntGather experiment.",
        "type": "FigureCaption"
    },
    {
        "element_id": "b03163717e323e5d99434211ff6cd4fd",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        430.8,
                        739.2
                    ],
                    [
                        430.8,
                        761.3
                    ],
                    [
                        538.6,
                        761.3
                    ],
                    [
                        538.6,
                        739.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11
        },
        "text": "TABLE XII",
        "type": "Title"
    },
    {
        "element_id": "e9c7bdc50130461c38e9d77e0acb7522",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        154.5,
                        772.1
                    ],
                    [
                        154.5,
                        794.5
                    ],
                    [
                        815.2,
                        794.5
                    ],
                    [
                        815.2,
                        772.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.63132,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "b03163717e323e5d99434211ff6cd4fd"
        },
        "text": "REWARD COMPARISON OF THE ANTGATHER ABLATION EXPERIMENT",
        "type": "FigureCaption"
    },
    {
        "element_id": "02d434c45cd919446ae3d83681fd835c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        141.0,
                        809.6
                    ],
                    [
                        141.0,
                        988.8
                    ],
                    [
                        824.1,
                        988.8
                    ],
                    [
                        824.1,
                        809.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92575,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-11-11.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "b03163717e323e5d99434211ff6cd4fd",
            "text_as_html": "<table><thead><tr><th>Algorithm</th><th>Maximum reward</th><th>O Average reward</th></tr></thead><tbody><tr><td>Only+Auxiliary Penalty</td><td>139</td><td>0.559</td></tr><tr><td>Only+Relay</td><td>1.53</td><td>0.655</td></tr><tr><td>HGR(without fine-tuning stage)</td><td>0.11</td><td>-0.240</td></tr><tr><td>HGR(without pretraining stage)</td><td>0.12</td><td>0.221</td></tr><tr><td>HGR</td><td>1.69</td><td>0.832</td></tr></tbody></table>"
        },
        "text": "Algorithm Maximum reward O Average reward Only+Auxiliary Penalty 139 0.559 Only+Relay 1.53 0.655 HGR(without fine-tuning stage) 0.11 -0.240 HGR(without pretraining stage) 0.12 0.221 HGR 1.69 0.832",
        "type": "Table"
    },
    {
        "element_id": "d4936b01a439cbc877666ba4b6860027",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.5,
                        1050.7
                    ],
                    [
                        135.5,
                        1181.5
                    ],
                    [
                        833.4,
                        1181.5
                    ],
                    [
                        833.4,
                        1050.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9371,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "b03163717e323e5d99434211ff6cd4fd"
        },
        "text": "penalty mechanism (Only + Auxiliary Penalty), and the black line is that of the relay mechanism (Only + Relay). The dodger blue line is the joint effect of the two mechanisms (Auxiliary Penalty + Relay).",
        "type": "NarrativeText"
    },
    {
        "element_id": "958cc28e98399d0e7ef2c36aa4878300",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1187.1
                    ],
                    [
                        136.0,
                        1580.0
                    ],
                    [
                        836.3,
                        1580.0
                    ],
                    [
                        836.3,
                        1187.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95203,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "b03163717e323e5d99434211ff6cd4fd"
        },
        "text": "As Fig. 11 and Table XII show, introducing the auxiliary penalty mechanism improves the stability of the training process and reduces the fluctuation of rewards received dur- ing training compared with HSP [30]. The final reward is approximately 1.39, which is also higher than HSP. In comparison, the relay mechanism gains better train- ing results, and the reward value reaches approximately 1.53. By integrating the two mechanisms, the final reward value obtained by the HGR algorithm reaches 1.69 or more, further indicating the effectiveness of the two pro- posed mechanisms and their algorithm. joint effect in the HGR",
        "type": "NarrativeText"
    },
    {
        "element_id": "31e0a56cd302d220b37d2b70ef43f1a5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        758.7
                    ],
                    [
                        866.6,
                        1118.5
                    ],
                    [
                        1568.3,
                        1118.5
                    ],
                    [
                        1568.3,
                        758.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95681,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "b03163717e323e5d99434211ff6cd4fd"
        },
        "text": "penalty mechanism. The first stage of the algorithm does not require external environment incentives and only relies on the game between two agents. One of these agents con- tinues proposing new tasks while the other agent attempts to complete the tasks. The auxiliary penalty helps adjust the difficulty of the tasks proposed by the first agent, and the relay mechanism helps improve the sample utilization efficiency and enables the second agent to explore more information about the environment. Therefore, after train- ing, we obtain an agent who is very familiar with the environment.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3c6ac385538f1ffbb17b8b160a9e6bb8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1124.0
                    ],
                    [
                        866.6,
                        1284.5
                    ],
                    [
                        1565.4,
                        1284.5
                    ],
                    [
                        1565.4,
                        1124.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94602,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "b03163717e323e5d99434211ff6cd4fd"
        },
        "text": "In the second stage, a high-level policy guides the agent obtained in the first stage, and the BP neural network is used to train the high-level policy to propose appropriate subgoals. The hierarchical structure is suitable for complex environments with sparse rewards, such as AntGather.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c3a59f9c8616ff25d90035d0523d920d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1290.1
                    ],
                    [
                        866.6,
                        1517.4
                    ],
                    [
                        1566.5,
                        1517.4
                    ],
                    [
                        1566.5,
                        1290.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95083,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "b03163717e323e5d99434211ff6cd4fd"
        },
        "text": "In the pretraining process of the proposed algorithm, the game is played between two agents. In future studies, we will consider the case of games played among multiple agents [43], which enables parallel learning of multiple agents and allows the Student to learn more knowledge within the same amount of time, thereby accelerating the environment exploration process.",
        "type": "NarrativeText"
    },
    {
        "element_id": "df2c512de7b746ea6b7d1418a30830df",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1137.8,
                        1542.0
                    ],
                    [
                        1137.8,
                        1569.7
                    ],
                    [
                        1292.8,
                        1569.7
                    ],
                    [
                        1292.8,
                        1542.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11
        },
        "text": "REFERENCES",
        "type": "Title"
    },
    {
        "element_id": "002d5c460bf57e522bd5ebcc34519862",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1585.6
                    ],
                    [
                        136.0,
                        1712.9
                    ],
                    [
                        833.4,
                        1712.9
                    ],
                    [
                        833.4,
                        1585.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94033,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "df2c512de7b746ea6b7d1418a30830df"
        },
        "text": "To demonstrate the impact of HGR\u2019s different stages on the experimental results, we conducted one additional abla- tion experiment in AntGather. The results are illustrated in Fig. 12 and Table XII.",
        "type": "NarrativeText"
    },
    {
        "element_id": "8a47ad5389aeb26590d87abaa6c6a403",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1718.4
                    ],
                    [
                        136.0,
                        1945.3
                    ],
                    [
                        835.7,
                        1945.3
                    ],
                    [
                        835.7,
                        1718.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95336,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "df2c512de7b746ea6b7d1418a30830df"
        },
        "text": "According to Fig. 12 and Table XII, although the average and maximum rewards of HGR (without the pretraining stage) are slightly higher than those of HGR (without the fine- tuning stage), each performance is much worse than that of HGR. This shows that hierarchical structure and playing games between agents are both indispensable and take a key part in the effectiveness of HGR.",
        "type": "NarrativeText"
    },
    {
        "element_id": "e1e830efcc6044e5a36c2d68243d3c81",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.7,
                        1586.0
                    ],
                    [
                        877.7,
                        1633.5
                    ],
                    [
                        1564.0,
                        1633.5
                    ],
                    [
                        1564.0,
                        1586.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90644,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "df2c512de7b746ea6b7d1418a30830df"
        },
        "text": "[1] X. Wang et al., \u201cDeep reinforcement learning: A survey,\u201d IEEE Trans. Neural Netw. Learn. Syst, vol. 35, no. 4, pp. 5064\u20135078, Apr. 2024.",
        "type": "ListItem"
    },
    {
        "element_id": "a99f920b57d3770f07635622779d201d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.7,
                        1638.3
                    ],
                    [
                        877.7,
                        1735.2
                    ],
                    [
                        1567.8,
                        1735.2
                    ],
                    [
                        1567.8,
                        1638.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9284,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "df2c512de7b746ea6b7d1418a30830df"
        },
        "text": "[2] S. Wen, Z. Wen, D. Zhang, H. Zhang, and T. Wang, \u201cA multi-robot path- planning algorithm for autonomous navigation using meta-reinforcement learning based on transfer learning,\u201d Appl. Soft Comput., vol. 110, Oct. 2021, Art. no. 107605.",
        "type": "ListItem"
    },
    {
        "element_id": "f6dff5f489a2ba6707b9e1e8480f45a6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.7,
                        1737.2
                    ],
                    [
                        877.7,
                        1835.2
                    ],
                    [
                        1564.9,
                        1835.2
                    ],
                    [
                        1564.9,
                        1737.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93318,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "df2c512de7b746ea6b7d1418a30830df"
        },
        "text": "[3] E. Zhao, N. Zhou, C. Liu, H. Su, Y. Liu, and J. Cong, \u201cTime- aware MADDPG with LSTM for multi-agent obstacle avoidance: A comparative study,\u201d Complex Intell. Syst., pp. 1\u201315, Mar. 2024, doi: 10.1007/s40747-024-01389-0.",
        "type": "ListItem"
    },
    {
        "element_id": "38bdca7afd77c819d6201e99ceeac88a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.7,
                        1837.7
                    ],
                    [
                        877.7,
                        1934.9
                    ],
                    [
                        1564.0,
                        1934.9
                    ],
                    [
                        1564.0,
                        1837.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9369,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "df2c512de7b746ea6b7d1418a30830df"
        },
        "text": "[4] Y. Jin, S. Wei, J. Yuan, and X. Zhang, \u201cHierarchical and stable multiagent reinforcement learning for cooperative navigation control,\u201d IEEE Trans. Neural Netw. Learn. Syst., vol. 34, no. 1, pp. 90\u2013103, Jan. 2023.",
        "type": "ListItem"
    },
    {
        "element_id": "f290f72384c4143ed42d76ab9b7a7cb0",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.7,
                        1937.0
                    ],
                    [
                        877.7,
                        1984.7
                    ],
                    [
                        1564.0,
                        1984.7
                    ],
                    [
                        1564.0,
                        1937.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90398,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "df2c512de7b746ea6b7d1418a30830df"
        },
        "text": "[5] D. Silver et al., \u201cMastering the game of go with deep neural networks and tree search,\u201d Nature, vol. 529, no. 7587, pp. 484\u2013489, Jan. 2016.",
        "type": "ListItem"
    },
    {
        "element_id": "f6a100b3b7a3f7a12c21f509740bd59b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        383.4,
                        1984.7
                    ],
                    [
                        383.4,
                        2012.4
                    ],
                    [
                        585.0,
                        2012.4
                    ],
                    [
                        585.0,
                        1984.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80902,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11
        },
        "text": "V. CONCLUSION",
        "type": "Title"
    },
    {
        "element_id": "96fd433529c3831b43bf31db2b06a959",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        2026.7
                    ],
                    [
                        136.0,
                        2087.5
                    ],
                    [
                        833.4,
                        2087.5
                    ],
                    [
                        833.4,
                        2026.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89241,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "f6a100b3b7a3f7a12c21f509740bd59b"
        },
        "text": "We proposed an HRL algorithm for motion planning based on the state relay mechanism and the auxiliary",
        "type": "NarrativeText"
    },
    {
        "element_id": "7bcacd846c9cf9de39cfb63a9599945d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.7,
                        1989.5
                    ],
                    [
                        877.7,
                        2086.3
                    ],
                    [
                        1564.0,
                        2086.3
                    ],
                    [
                        1564.0,
                        1989.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9292,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "f6a100b3b7a3f7a12c21f509740bd59b"
        },
        "text": "[6] Y. Wu, S. Liao, X. Liu, Z. Li, and R. Lu, \u201cDeep reinforcement learning on autonomous driving policy with auxiliary critic network,\u201d IEEE Trans. Neural Netw. Learn. Syst., vol. 34, no. 7, pp. 3680\u20133690, Jul. 2023.",
        "type": "ListItem"
    },
    {
        "element_id": "86ad7ac2bea2ccf9790db27780f324e8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.4
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.68013,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11,
            "parent_id": "f6a100b3b7a3f7a12c21f509740bd59b"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:23:24 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "67baea47dda7b9779870149b79f96b19",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1544.6,
                        84.4
                    ],
                    [
                        1544.6,
                        105.3
                    ],
                    [
                        1564.8,
                        105.3
                    ],
                    [
                        1564.8,
                        84.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.75572,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 11
        },
        "text": "11",
        "type": "Header"
    },
    {
        "element_id": "54c51f4f711a1da043b2767a7288a913",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        322.2,
                        25.4
                    ],
                    [
                        322.2,
                        46.0
                    ],
                    [
                        1512.0,
                        46.0
                    ],
                    [
                        1512.0,
                        25.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82173,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "type": "Header"
    },
    {
        "element_id": "1de39a78c2574aefb7006f2812e94f13",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.3,
                        84.3
                    ],
                    [
                        134.3,
                        105.5
                    ],
                    [
                        155.9,
                        105.5
                    ],
                    [
                        155.9,
                        84.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.7818,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "12",
        "type": "Header"
    },
    {
        "element_id": "4c7f0173ff83a1a23a64e2c1579b0b2d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        885.8,
                        85.2
                    ],
                    [
                        885.8,
                        104.6
                    ],
                    [
                        1564.1,
                        104.6
                    ],
                    [
                        1564.1,
                        85.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.8191,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS",
        "type": "NarrativeText"
    },
    {
        "element_id": "fa3ca484ef6eb2eeafce8facb092cea0",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        147.1,
                        166.0
                    ],
                    [
                        147.1,
                        238.0
                    ],
                    [
                        833.4,
                        238.0
                    ],
                    [
                        833.4,
                        166.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93267,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[7] R. Parr and S. Russell, \u201cReinforcement learning with hierarchies of machines,\u201d in Proc. Conf. Adv. Neural Inf. Process. Syst., 1997, pp. 1043\u20131049.",
        "type": "ListItem"
    },
    {
        "element_id": "ee48d692c1612ee86f75fa5432bc1baf",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        166.0
                    ],
                    [
                        866.6,
                        238.0
                    ],
                    [
                        1564.0,
                        238.0
                    ],
                    [
                        1564.0,
                        166.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93339,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[31] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, \u201cLearning rep- resentations by back-propagating errors,\u201d Nature, vol. 323, no. 6088, pp. 533\u2013536, Oct. 1986.",
        "type": "ListItem"
    },
    {
        "element_id": "41f68c4ca5ff2b2e37a5ffb7e8625d1c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        147.1,
                        242.8
                    ],
                    [
                        147.1,
                        315.0
                    ],
                    [
                        833.4,
                        315.0
                    ],
                    [
                        833.4,
                        242.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92859,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[8] R. S. Sutton, D. Precup, and S. Singh, \u201cBetween MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning,\u201d Artif. Intell., vol. 112, nos. 1\u20132, pp. 181\u2013211, Aug. 1999.",
        "type": "ListItem"
    },
    {
        "element_id": "bf40eb89673ee52b74a6da890e3d8d86",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        242.8
                    ],
                    [
                        866.6,
                        314.8
                    ],
                    [
                        1564.0,
                        314.8
                    ],
                    [
                        1564.0,
                        242.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92934,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[32] M.-P. Song, G.-C. Gu, and G.-Y. Zhang, \u201cSurvey of multi-agent rein- forcement learning in Markov games,\u201d Control Decis., vol. 20, no. 10, p. 1081, 2005.",
        "type": "ListItem"
    },
    {
        "element_id": "6c89bb5cfba25184e61711ab88ac3638",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        147.1,
                        319.5
                    ],
                    [
                        147.1,
                        391.5
                    ],
                    [
                        835.0,
                        391.5
                    ],
                    [
                        835.0,
                        319.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92736,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[9] T. G. Dietterich, \u201cHierarchical reinforcement learning with the MAXQ value function decomposition,\u201d J. Artif. Intell. Res., vol. 13, pp. 227\u2013303, Nov. 2000.",
        "type": "ListItem"
    },
    {
        "element_id": "9a0a5377196f21edf9ea14901ed8d053",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        319.5
                    ],
                    [
                        866.6,
                        391.5
                    ],
                    [
                        1564.4,
                        391.5
                    ],
                    [
                        1564.4,
                        319.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93049,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[33] C. Florensa, D. Held, X. Geng, and P. Abbeel, \u201cAutomatic goal genera- tion for reinforcement learning agents,\u201d in Proc. Int. Conf. Mach. Learn., vol. 80, 2018, pp. 1515\u20131528.",
        "type": "ListItem"
    },
    {
        "element_id": "51732dadd8a9c12512da1c5e00e26985",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        394.2
                    ],
                    [
                        136.0,
                        466.2
                    ],
                    [
                        835.4,
                        466.2
                    ],
                    [
                        835.4,
                        394.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93432,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[10] J. Cong, Y. Liu, and C. Liu, \u201cGuiding task learning by hierarchical rl with an experience replay mechanism through reward machines,\u201d in Proc. PRICAI, 2024, pp. 164\u2013170.",
        "type": "ListItem"
    },
    {
        "element_id": "12be41e973bb00002a359bc9bf812c03",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        396.3
                    ],
                    [
                        866.6,
                        468.2
                    ],
                    [
                        1564.0,
                        468.2
                    ],
                    [
                        1564.0,
                        396.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93644,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[34] C. Florensa, D. Held, M. Wulfmeier, and P. Abbeel, \u201cReverse curriculum generation for reinforcement learning,\u201d in Proc. Int. Conf. Robot Learn., vol. 78, 2017, pp. 482\u2013495.",
        "type": "ListItem"
    },
    {
        "element_id": "1cf172fc13bd0efceea429c9b92963b8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        471.0
                    ],
                    [
                        136.0,
                        567.9
                    ],
                    [
                        835.7,
                        567.9
                    ],
                    [
                        835.7,
                        471.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94067,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[11] T. D. Kulkarni, K. Narasimhan, A. Saeedi, and J. Tenenbaum, \u201cHierar- chical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation,\u201d in Proc. Adv. Neural Inf. Process. Syst., vol. 29, 2016, pp. 3682\u20133690.",
        "type": "ListItem"
    },
    {
        "element_id": "e3c265e4647f9d5f5960014b38cb8fb8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        572.6
                    ],
                    [
                        136.0,
                        619.7
                    ],
                    [
                        833.4,
                        619.7
                    ],
                    [
                        833.4,
                        572.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91554,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[12] V. Mnih, \u201cHuman-level control through deep reinforcement learning,\u201d Nature, vol. 518, pp. 529\u2013533, Feb. 2015.",
        "type": "ListItem"
    },
    {
        "element_id": "c1f0ed031a098d56ff9cd054fd1455e8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        473.0
                    ],
                    [
                        866.6,
                        545.0
                    ],
                    [
                        1564.0,
                        545.0
                    ],
                    [
                        1564.0,
                        473.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93567,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[35] S. Pateria, B. Subagdja, A.-H. Tan, and C. Quek, \u201cHierarchical reinforce- ment learning: A comprehensive survey,\u201d ACM Comput. Surv., vol. 54, no. 5, pp. 1\u201335, 2021.",
        "type": "ListItem"
    },
    {
        "element_id": "7674b3889bd36bd4472c41595ca41a02",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        549.8
                    ],
                    [
                        866.6,
                        621.7
                    ],
                    [
                        1564.0,
                        621.7
                    ],
                    [
                        1564.0,
                        549.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93093,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[36] Z. Cao and C.-T. Lin, \u201cReinforcement learning from hierarchical critics,\u201d IEEE Trans. Neural Netw. Learn. Syst., vol. 34, no. 2, pp. 1066\u20131073, Feb. 2023.",
        "type": "ListItem"
    },
    {
        "element_id": "62c595eb1bcb3092a1a4996fba353499",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        624.5
                    ],
                    [
                        136.0,
                        696.4
                    ],
                    [
                        834.7,
                        696.4
                    ],
                    [
                        834.7,
                        624.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93469,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[13] A. S. Vezhnevets et al., \u201cFeudal networks for hierarchical reinforce- ment learning,\u201d in Proc. Int. Conf. Mach. Learn. (ICML), 2017, pp. 3540\u20133549.",
        "type": "ListItem"
    },
    {
        "element_id": "a4e0127eb683a71d6445e4a7bf8f45fa",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        701.2
                    ],
                    [
                        136.0,
                        773.2
                    ],
                    [
                        833.4,
                        773.2
                    ],
                    [
                        833.4,
                        701.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93501,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[14] C. Florensa, Y. Duan, and P. Abbeel, \u201cStochastic neural networks for hierarchical reinforcement learning,\u201d in Proc. 5th Int. Conf. Learn. Represent., Toulon, France, 2017, pp. 1\u201317.",
        "type": "ListItem"
    },
    {
        "element_id": "3454700507d076b1f0621287cd4b28c7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        778.0
                    ],
                    [
                        136.0,
                        825.0
                    ],
                    [
                        833.4,
                        825.0
                    ],
                    [
                        833.4,
                        778.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91422,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[15] M. Andrychowicz et al., \u201cHindsight experience replay,\u201d 2017, arXiv:1707.01495.",
        "type": "ListItem"
    },
    {
        "element_id": "1dc662fe9128a020019f009cfb9bc817",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        624.5
                    ],
                    [
                        866.6,
                        671.5
                    ],
                    [
                        1564.0,
                        671.5
                    ],
                    [
                        1564.0,
                        624.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91996,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[37] J. Lai, J. Y. Wei, and X. L. Chen, \u201cOverview of hierarchical reinforce- ment learning,\u201d Comput. Eng. Appl., vol. 57, no. 3, pp. 72\u201379, 2021.",
        "type": "ListItem"
    },
    {
        "element_id": "6100c360da2b17a7e48c0a49fd9cb80c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        676.3
                    ],
                    [
                        866.6,
                        723.9
                    ],
                    [
                        1564.0,
                        723.9
                    ],
                    [
                        1564.0,
                        676.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91439,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[38] A. Pinkus, \u201cApproximation theory of the MLP model in neural net- works,\u201d Acta Numerica, vol. 8, pp. 143\u2013195, Jan. 1999.",
        "type": "ListItem"
    },
    {
        "element_id": "c57e0e2ac0a5073587096eb372d9fe13",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        728.2
                    ],
                    [
                        866.6,
                        825.0
                    ],
                    [
                        1564.0,
                        825.0
                    ],
                    [
                        1564.0,
                        728.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93815,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[39] S. Li, R. Wang, M. Tang, and C. Zhang, \u201cHierarchical reinforce- ment learning with advantage-based auxiliary rewards,\u201d in Proc. Adv. Neural Inf. Process. Syst., vol. 32, Vancouver, BC, Canada, 2019, pp. 1407\u20131417.",
        "type": "ListItem"
    },
    {
        "element_id": "7e7b1a277b02ba7e56f4f04c6b8d888b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        827.8
                    ],
                    [
                        136.0,
                        924.6
                    ],
                    [
                        833.4,
                        924.6
                    ],
                    [
                        833.4,
                        827.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94064,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[16] L. Schramm, Y. Deng, E. Granados, and A. Boularias, \u201cUSHER: Unbiased sampling for hindsight experience replay,\u201d in Proc. Conf. Robot Learn., vol. 205, Auckland, New Zealand, Dec. 2022, pp. 2073\u20132082.",
        "type": "ListItem"
    },
    {
        "element_id": "be08d521d9f8845756766386b14e43ee",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        929.4
                    ],
                    [
                        136.0,
                        1001.4
                    ],
                    [
                        833.4,
                        1001.4
                    ],
                    [
                        833.4,
                        929.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93644,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[17] L. Moro, A. Likmeta, E. Prati, and M. Restelli, \u201cGoal-directed plan- ning via hindsight experience replay,\u201d in Proc. 10th Int. Conf. Learn. Represent., 2022, pp. 1\u201316.",
        "type": "ListItem"
    },
    {
        "element_id": "bb108e597c275fb2d8a667215a51e499",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1006.2
                    ],
                    [
                        136.0,
                        1078.1
                    ],
                    [
                        833.4,
                        1078.1
                    ],
                    [
                        833.4,
                        1006.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93597,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[18] A. Demin and D. Ponomaryov, \u201cInterpretable reinforcement learning with multilevel subgoal discovery,\u201d in Proc. 21st IEEE Int. Conf. Mach. Learn. Appl. (ICMLA), Dec. 2022, pp. 251\u2013258.",
        "type": "ListItem"
    },
    {
        "element_id": "649e9635e298029a33666d3775a5a022",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1082.9
                    ],
                    [
                        136.0,
                        1179.8
                    ],
                    [
                        836.7,
                        1179.8
                    ],
                    [
                        836.7,
                        1082.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93925,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[19] S. Pateria, B. Subagdja, A. Tan, and C. Quek, \u201cEnd-to-end hierarchi- cal reinforcement learning with integrated subgoal discovery,\u201d IEEE Trans. Neural Netw. Learn. Syst., vol. 33, no. 12, pp. 7778\u20137790, Dec. 2022.",
        "type": "ListItem"
    },
    {
        "element_id": "b13c8f80bc7f96ac3aac3ce766e19a96",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        829.8
                    ],
                    [
                        866.6,
                        901.8
                    ],
                    [
                        1565.7,
                        901.8
                    ],
                    [
                        1565.7,
                        829.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93078,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[40] S. Sukhbaatar, A. Szlam, G. Synnaeve, S. Chintala, and R. Fergus, \u201cMazeBase: A sandbox for learning from games,\u201d 2015, arXiv:1511.07401.",
        "type": "ListItem"
    },
    {
        "element_id": "a5660492a7e8a1aad4c662a3cbe253af",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        904.5
                    ],
                    [
                        866.6,
                        976.5
                    ],
                    [
                        1564.0,
                        976.5
                    ],
                    [
                        1564.0,
                        904.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9306,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[41] E. Todorov, T. Erez, and Y. Tassa, \u201cMuJoCo: A physics engine for model-based control,\u201d in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., Oct. 2012, pp. 5026\u20135033.",
        "type": "ListItem"
    },
    {
        "element_id": "07cc52715ca3f922f8d3ef95de3fed53",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        981.3
                    ],
                    [
                        866.6,
                        1028.3
                    ],
                    [
                        1564.0,
                        1028.3
                    ],
                    [
                        1564.0,
                        981.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91216,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[42] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, \u201cProximal policy optimization algorithms,\u201d 2017, arXiv:1707.06347.",
        "type": "ListItem"
    },
    {
        "element_id": "7f429ea6bdaac6ddcf53ae67b969258c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1033.1
                    ],
                    [
                        866.6,
                        1105.1
                    ],
                    [
                        1564.0,
                        1105.1
                    ],
                    [
                        1564.0,
                        1033.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93628,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[43] C. Liu, E. Zhu, Q. Zhang, and X. Wei, \u201cModeling of agent cognition in extensive games via artificial neural networks,\u201d IEEE Trans. Neural Netw. Learn. Syst., vol. 29, no. 10, pp. 4857\u20134868, Oct. 2018.",
        "type": "ListItem"
    },
    {
        "element_id": "d313dc468915395e679246f8605c356d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1182.5
                    ],
                    [
                        136.0,
                        1279.4
                    ],
                    [
                        833.5,
                        1279.4
                    ],
                    [
                        833.5,
                        1182.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94143,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[20] T. Zhang, S. Guo, T. Tan, X. Hu, and F. Chen, \u201cAdjacency constraint for efficient hierarchical reinforcement learning,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 45, no. 4, pp. 4152\u20134166, Apr. 2023.",
        "type": "ListItem"
    },
    {
        "element_id": "c7ac84ee53af010a60dd2ab4db2c73c7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1284.2
                    ],
                    [
                        136.0,
                        1381.1
                    ],
                    [
                        834.5,
                        1381.1
                    ],
                    [
                        834.5,
                        1284.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94005,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[21] C. Liu, E. Zhu, Q. Zhang, and X. Wei, \u201cExploring the effects of computational costs in extensive games via modeling and simulation,\u201d Int. J. Intell. Syst., vol. 36, no. 8, pp. 4065\u20134087, Aug. 2021.",
        "type": "ListItem"
    },
    {
        "element_id": "75ac79ae7f68315830a999a8752286b4",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1385.9
                    ],
                    [
                        136.0,
                        1457.8
                    ],
                    [
                        833.4,
                        1457.8
                    ],
                    [
                        833.4,
                        1385.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93465,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[22] J. R. H. Mari\u00f1o and C. F. M. Toledo, \u201cEvolving interpretable strate- gies for zero-sum games,\u201d Appl. Soft Comput., vol. 122, Jun. 2022, Art. no. 108860.",
        "type": "ListItem"
    },
    {
        "element_id": "8c68d5dc1cd04b88226f9e3f5069f71b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1460.6
                    ],
                    [
                        136.0,
                        1557.4
                    ],
                    [
                        833.6,
                        1557.4
                    ],
                    [
                        833.6,
                        1460.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94056,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[23] M. Li, J. Qin, Q. Ma, W. X. Zheng, and Y. Kang, \u201cHierarchical optimal synchronization for linear systems via reinforcement learning: A Stackelberg-Nash game perspective,\u201d IEEE Trans. Neural Netw. Learn. Syst., vol. 32, no. 4, pp. 1600\u20131611, Apr. 2021.",
        "type": "ListItem"
    },
    {
        "element_id": "5719818128ca5c14dd3a8a2a98dca052",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1562.2
                    ],
                    [
                        136.0,
                        1634.2
                    ],
                    [
                        838.2,
                        1634.2
                    ],
                    [
                        838.2,
                        1562.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93245,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12,
            "parent_id": "1de39a78c2574aefb7006f2812e94f13"
        },
        "text": "[24] B. M. Albaba and Y. Yildiz, \u201cDriver modeling through deep reinforce- ment learning and behavioral game theory,\u201d IEEE Trans. Control Syst. Technol., vol. 30, no. 2, pp. 885\u2013892, Mar. 2022.",
        "type": "ListItem"
    },
    {
        "element_id": "83db042e217dd4f1728f8de6b51a7b4e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        861.8,
                        1301.6
                    ],
                    [
                        861.8,
                        1594.9
                    ],
                    [
                        1071.3,
                        1594.9
                    ],
                    [
                        1071.3,
                        1301.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-12-17.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "9b2574ce4dce5b00414a75919deeaa55",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1089.0,
                        1311.1
                    ],
                    [
                        1089.0,
                        1433.0
                    ],
                    [
                        1572.1,
                        1433.0
                    ],
                    [
                        1572.1,
                        1311.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92331,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "Chanjuan Liu (Member, IEEE) received the B.E. degree in software engineering from Jinan Univer- sity, Guangzhou, China, in 2010, and the Ph.D. degree in computer software and theory from Peking University, Beijing, China, in 2016.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a1dabf7fe8c2e36c69ea41dfcccf84a1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1090.5,
                        1435.8
                    ],
                    [
                        1090.5,
                        1557.5
                    ],
                    [
                        1572.9,
                        1557.5
                    ],
                    [
                        1572.9,
                        1435.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92852,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "She is currently an Associate Professor with the School of Computer Science and Technology, Dalian University of Technology, Dalian, China. Her current research interests include deep learning and game theory.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ef9673ad6c9a389d5e385b4022e811ba",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1639.0
                    ],
                    [
                        136.0,
                        1686.0
                    ],
                    [
                        835.4,
                        1686.0
                    ],
                    [
                        835.4,
                        1639.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9157,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "[25] A. L. Samuel, \u201cSome studies in machine learning using the game of checkers,\u201d IBM J. Res. Develop., vol. 3, no. 3, pp. 210\u2013229, Jul. 1959.",
        "type": "ListItem"
    },
    {
        "element_id": "b3049414a0e9077cf3f64ae836507038",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1690.3
                    ],
                    [
                        136.0,
                        1737.9
                    ],
                    [
                        837.1,
                        1737.9
                    ],
                    [
                        837.1,
                        1690.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91218,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "[26] G. Tesauro, \u201cTemporal difference learning and TD-Gammon,\u201d Commun. ACM, vol. 38, no. 3, pp. 58\u201368, Mar. 1995.",
        "type": "ListItem"
    },
    {
        "element_id": "e1ff80bf19457eb9222323af1217a288",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1742.7
                    ],
                    [
                        136.0,
                        1789.7
                    ],
                    [
                        833.8,
                        1789.7
                    ],
                    [
                        833.8,
                        1742.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.907,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "[27] D. Silver et al., \u201cMastering the game of go without human knowledge,\u201d Nature, vol. 550, no. 7676, pp. 354\u2013359, Oct. 2017.",
        "type": "ListItem"
    },
    {
        "element_id": "30f1058ffc27aa75e08bbae0d2e55cdf",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1794.5
                    ],
                    [
                        136.0,
                        1866.4
                    ],
                    [
                        835.9,
                        1866.4
                    ],
                    [
                        835.9,
                        1794.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93107,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "[28] J. Schrittwieser et al., \u201cMastering atari, go, chess and shogi by plan- ning with a learned model,\u201d Nature, vol. 588, no. 7839, pp. 604\u2013609, Dec. 2020.",
        "type": "ListItem"
    },
    {
        "element_id": "883667625d580d3b3efe4f7efeca3657",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1868.2
                    ],
                    [
                        136.0,
                        1966.1
                    ],
                    [
                        835.3,
                        1966.1
                    ],
                    [
                        835.3,
                        1868.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93468,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "[29] S. Sukhbaatar, Z. Lin, I. Kostrikov, G. Synnaeve, A. Szlam, and R. Fergus, \u201cIntrinsic motivation and automatic curricula via asymmetric self-play,\u201d in Proc. 6th Int. Conf. Learn. Represent., Vancouver, BC, Canada, 2018, pp. 1\u201316.",
        "type": "ListItem"
    },
    {
        "element_id": "6b0f98b021acd0bb70b22d2833a3c961",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1970.8
                    ],
                    [
                        136.0,
                        2042.8
                    ],
                    [
                        840.2,
                        2042.8
                    ],
                    [
                        840.2,
                        1970.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92964,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "[30] S. Sukhbaatar, E. Denton, A. Szlam, and R. Fergus, \u201cLearning goal embeddings via self-play for hierarchical reinforcement learning,\u201d 2018, arXiv:1811.09083.",
        "type": "ListItem"
    },
    {
        "element_id": "ea0e95175b2d399bfd86933e783d0ba7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        860.8,
                        1782.8
                    ],
                    [
                        860.8,
                        2065.0
                    ],
                    [
                        1072.3,
                        2065.0
                    ],
                    [
                        1072.3,
                        1782.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-12-18.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "c088a6bcc721841256ce4398ac6bff05",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1090.4,
                        1782.9
                    ],
                    [
                        1090.4,
                        1904.8
                    ],
                    [
                        1572.6,
                        1904.8
                    ],
                    [
                        1572.6,
                        1782.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9265,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "Jinmiao Cong received the B.E. degree in computer science and technology from Dalian University of Technology, Dalian, China, in 2021, where he is currently pursuing the master\u2019s degree in computer science and technology.",
        "type": "NarrativeText"
    },
    {
        "element_id": "640f19d1ad4f8b0f5d2759587ddf0564",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1093.5,
                        1907.6
                    ],
                    [
                        1093.5,
                        1954.7
                    ],
                    [
                        1568.9,
                        1954.7
                    ],
                    [
                        1568.9,
                        1907.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89321,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "His research interests include deep reinforcement learning and multiagent systems.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9eafab403d53c86b4f9bb35cd67c301d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        143.3,
                        2121.9
                    ],
                    [
                        143.3,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2121.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73613,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 12
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:23:24 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "62122fb03760ea541abdc3706522ee90",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        322.2,
                        26.2
                    ],
                    [
                        322.2,
                        46.2
                    ],
                    [
                        1510.0,
                        46.2
                    ],
                    [
                        1510.0,
                        26.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82194,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "type": "Header"
    },
    {
        "element_id": "948557d438f2f8e816687b045aeb47bb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        84.9
                    ],
                    [
                        136.0,
                        104.6
                    ],
                    [
                        1135.3,
                        104.6
                    ],
                    [
                        1135.3,
                        84.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.69137,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13,
            "parent_id": "62122fb03760ea541abdc3706522ee90"
        },
        "text": "LIU et al.: BOOSTING REINFORCEMENT LEARNING VIA HIERARCHICAL GAME PLAYING WITH STATE RELAY",
        "type": "NarrativeText"
    },
    {
        "element_id": "92a68f438c06e4ea3f4425dd578c7f0a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        125.3,
                        138.3
                    ],
                    [
                        125.3,
                        433.4
                    ],
                    [
                        346.6,
                        433.4
                    ],
                    [
                        346.6,
                        138.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-13-19.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "13681c2e4246aaf0d1a3527833dccaac",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        360.0,
                        165.9
                    ],
                    [
                        360.0,
                        312.7
                    ],
                    [
                        841.4,
                        312.7
                    ],
                    [
                        841.4,
                        165.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92487,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "Guangyuan Liu received the B.E. degree in com- puter science and technology from Northeastern University, Shenyang, China, in 2020. He is cur- rently pursuing the master\u2019s degree in computer science and technology with Dalian University of Technology, Dalian, China.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3ebf72376de19205b69e3f6040f11ad1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        364.0,
                        315.5
                    ],
                    [
                        364.0,
                        362.5
                    ],
                    [
                        835.6,
                        362.5
                    ],
                    [
                        835.6,
                        315.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88424,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "His research interests include deep learning and combinatorial optimization.",
        "type": "NarrativeText"
    },
    {
        "element_id": "fc4496b117b07886f7ce2728b363255e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        864.2,
                        157.6
                    ],
                    [
                        864.2,
                        430.6
                    ],
                    [
                        1069.2,
                        430.6
                    ],
                    [
                        1069.2,
                        157.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-13-20.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "7db2f6139dac9e79d2de515e1c851e8e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1090.1,
                        165.9
                    ],
                    [
                        1090.1,
                        312.7
                    ],
                    [
                        1573.7,
                        312.7
                    ],
                    [
                        1573.7,
                        165.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9275,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "Xirong Xu received the B.E. degree in applied mathematics from the East China University of Sci- ence and Technology, Shanghai, China, in 1990, and the M.E. and Ph.D. degrees in computer software and theory from Dalian University of Technology, Dalian, China, in 2002 and 2005, respectively.",
        "type": "NarrativeText"
    },
    {
        "element_id": "599343563ef9e2b2960d7423868a1f6d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1091.5,
                        315.5
                    ],
                    [
                        1091.5,
                        412.3
                    ],
                    [
                        1574.4,
                        412.3
                    ],
                    [
                        1574.4,
                        315.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91172,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "She is currently an Associate Professor with the School of Computer Science and Technology, Dalian University of Technology. Her current research interest is combinatorial optimization.",
        "type": "NarrativeText"
    },
    {
        "element_id": "50d005f4e959c358f36196c2c1daa490",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        123.0,
                        609.7
                    ],
                    [
                        123.0,
                        879.1
                    ],
                    [
                        349.0,
                        879.1
                    ],
                    [
                        349.0,
                        609.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-13-21.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "0017e85dcf6b881791132fcc5f1b2718",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        358.0,
                        607.9
                    ],
                    [
                        358.0,
                        704.9
                    ],
                    [
                        841.2,
                        704.9
                    ],
                    [
                        841.2,
                        607.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91844,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "Guifei Jiang received the double Ph.D. degree in computer science from Western Sydney Univer- sity, Penrith, NSW, Australia, and the University of Toulouse, Toulouse, France, in 2016.",
        "type": "NarrativeText"
    },
    {
        "element_id": "7176f2836f35271705f6149c4cef46cf",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        362.1,
                        707.7
                    ],
                    [
                        362.1,
                        804.6
                    ],
                    [
                        843.0,
                        804.6
                    ],
                    [
                        843.0,
                        707.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9167,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "She is currently an Associate Professor with Nankai University, Tianjin, China. Her research interests include general game playing and multi- agent systems.",
        "type": "NarrativeText"
    },
    {
        "element_id": "de2ad5914f9b387ea88b3f91d9b9e1ac",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        862.2,
                        574.4
                    ],
                    [
                        862.2,
                        887.9
                    ],
                    [
                        1071.2,
                        887.9
                    ],
                    [
                        1071.2,
                        574.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-13-22.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "614f0a25221d3718fc155488b5051c73",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1092.6,
                        594.3
                    ],
                    [
                        1092.6,
                        766.0
                    ],
                    [
                        1571.9,
                        766.0
                    ],
                    [
                        1571.9,
                        594.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93462,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "Enqiang Zhu received the B.E. degree in informa- tion and computing science and the M.E. degree in operational research and cybernetics from Lanzhou Jiaotong University, Lanzhou, China, in 2007 and 2010, respectively, and the Ph.D. degree in computer science from Peking University, Beijing, China, in 2015.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c4296b90f57bd167c62a0f6c3e7b36ec",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1086.1,
                        768.8
                    ],
                    [
                        1086.1,
                        865.6
                    ],
                    [
                        1571.2,
                        865.6
                    ],
                    [
                        1571.2,
                        768.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92358,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "He is currently a Professor with the Institute of Computing Science and Technology, Guangzhou University, Guangzhou, China. His current research interests include graph theory and machine learning.",
        "type": "NarrativeText"
    },
    {
        "element_id": "b3f0eec6b5d0fc77dc105178cb99ee0b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.7
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84653,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:23:24 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "e819d003c3abb55e4c430ef4d48bdd99",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1544.6,
                        85.0
                    ],
                    [
                        1544.6,
                        105.1
                    ],
                    [
                        1565.0,
                        105.1
                    ],
                    [
                        1565.0,
                        85.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.76415,
            "file_directory": "./uol-docs",
            "filename": "Boosting_Reinforcement_Learning_via_Hierarchical_Game_Playing_With_State_Relay.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:23:38",
            "page_number": 13
        },
        "text": "13",
        "type": "Header"
    }
]