[
    {
        "element_id": "490e2fb6344528d0303e53d4ace48729",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        90.9,
                        141.2
                    ],
                    [
                        90.9,
                        225.2
                    ],
                    [
                        443.9,
                        225.2
                    ],
                    [
                        443.9,
                        141.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.65865,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-1-1.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1
        },
        "text": "robotics",
        "type": "Image"
    },
    {
        "element_id": "df9fd170ab7592903db9a72186ef91ba",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1435.8,
                        155.4
                    ],
                    [
                        1435.8,
                        231.7
                    ],
                    [
                        1551.4,
                        231.7
                    ],
                    [
                        1551.4,
                        155.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-1-2.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "b2a6d164134e17b23d0a1e638f73f8df",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        97.3,
                        290.3
                    ],
                    [
                        97.3,
                        321.7
                    ],
                    [
                        177.6,
                        321.7
                    ],
                    [
                        177.6,
                        290.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.78408,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1
        },
        "text": "Article",
        "type": "NarrativeText"
    },
    {
        "element_id": "a3efebca25412771d9684b0fc659f48c",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        92.8,
                        329.9
                    ],
                    [
                        92.8,
                        433.3
                    ],
                    [
                        1251.8,
                        433.3
                    ],
                    [
                        1251.8,
                        329.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.76972,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1
        },
        "text": "Research on Game-Playing Agents Based on Deep Reinforcement Learning",
        "type": "Title"
    },
    {
        "element_id": "0bff8351d6c2f5c034748b46a5b2fc9c",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        97.7,
                        465.0
                    ],
                    [
                        97.7,
                        500.3
                    ],
                    [
                        794.1,
                        500.3
                    ],
                    [
                        794.1,
                        465.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74954,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1,
            "parent_id": "a3efebca25412771d9684b0fc659f48c"
        },
        "text": "Kai Zhao 1 , Jia Song 1,* , Yuxie Luo 1 and Yang Liu 2",
        "type": "NarrativeText"
    },
    {
        "element_id": "e15664050c09b2c3c74c1e6c0f4ef9ca",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        446.2,
                        561.2
                    ],
                    [
                        446.2,
                        617.3
                    ],
                    [
                        1561.5,
                        617.3
                    ],
                    [
                        1561.5,
                        561.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89296,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1,
            "parent_id": "a3efebca25412771d9684b0fc659f48c"
        },
        "text": "1 School of Astronautics, Beihang University (BUAA), Beijing 100191, China; zk19970207@buaa.edu.cn (K.Z.); luoyuxie@buaa.edu.cn (Y.L.)",
        "type": "ListItem"
    },
    {
        "element_id": "f4e29d87110d3dc2574a53bddd7ea72e",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        454.5,
                        621.0
                    ],
                    [
                        454.5,
                        677.1
                    ],
                    [
                        1568.3,
                        677.1
                    ],
                    [
                        1568.3,
                        621.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89904,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1,
            "parent_id": "a3efebca25412771d9684b0fc659f48c"
        },
        "text": "2 School of Automation Science and Electrical Engineering, Beihang University (BUAA), Beijing 100191, China; ylbuaa@163.com",
        "type": "ListItem"
    },
    {
        "element_id": "2a27fcd9e6b4c58908a546402f30b392",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.2,
                        684.5
                    ],
                    [
                        460.2,
                        707.0
                    ],
                    [
                        879.9,
                        707.0
                    ],
                    [
                        879.9,
                        684.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.85238,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1,
            "parent_id": "a3efebca25412771d9684b0fc659f48c"
        },
        "text": "* Correspondence: songjia@buaa.edu.cn",
        "type": "ListItem"
    },
    {
        "element_id": "d8e0401deb826a596500f57684323cbf",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.0,
                        751.7
                    ],
                    [
                        461.0,
                        1029.2
                    ],
                    [
                        1559.7,
                        1029.2
                    ],
                    [
                        1559.7,
                        751.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94921,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1,
            "parent_id": "a3efebca25412771d9684b0fc659f48c"
        },
        "text": "Abstract: Path planning is a key technology for the autonomous mobility of intelligent robots. However, there are few studies on how to carry out path planning in real time under the confrontation environment. Therefore, based on the deep deterministic policy gradient (DDPG) algorithm, this paper designs the reward function and adopts the incremental training and reward compensation method to improve the training ef\ufb01ciency and obtain the penetration strategy. The Monte Carlo experiment results show that the algorithm can effectively avoid static obstacles, break through the interception, and \ufb01nally reach the target area. Moreover, the algorithm is also validated in the Webots simulator.",
        "type": "NarrativeText"
    },
    {
        "element_id": "4a38136376d2d551ad2f13e3b62ddd2f",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        455.0,
                        1073.2
                    ],
                    [
                        455.0,
                        1134.5
                    ],
                    [
                        1561.6,
                        1134.5
                    ],
                    [
                        1561.6,
                        1073.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91998,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1,
            "parent_id": "a3efebca25412771d9684b0fc659f48c"
        },
        "text": "Keywords: deep reinforcement learning (DRL); deep deterministic policy gradient (DDPG); dynamic path planning; confrontation environment",
        "type": "NarrativeText"
    },
    {
        "element_id": "55e6eca0bf2950cb07bceca5c76789f9",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        90.3,
                        1221.7
                    ],
                    [
                        90.3,
                        1266.8
                    ],
                    [
                        244.2,
                        1266.8
                    ],
                    [
                        244.2,
                        1221.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.75641,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1
        },
        "text": "\u00a9 check for updates",
        "type": "Title"
    },
    {
        "element_id": "69e52f9ada23c4c247bb3e5d3dc79f59",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1246.3
                    ],
                    [
                        462.2,
                        1274.0
                    ],
                    [
                        651.4,
                        1274.0
                    ],
                    [
                        651.4,
                        1246.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84393,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1
        },
        "text": "1. Introduction",
        "type": "Title"
    },
    {
        "element_id": "eae0e4d7061b55f4c8f6d2ebc735e9c4",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.5,
                        1285.0
                    ],
                    [
                        98.5,
                        1470.6
                    ],
                    [
                        423.8,
                        1470.6
                    ],
                    [
                        423.8,
                        1285.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88743,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1,
            "parent_id": "69e52f9ada23c4c247bb3e5d3dc79f59"
        },
        "text": "Citation: Zhao, K.; Song, J.; Luo, Y.; Liu, Y. Research on Game-Playing Agents Based on Deep Reinforcement Learning. Robotics 2022, 11, 35. https://doi.org/10.3390/ robotics11020035",
        "type": "NarrativeText"
    },
    {
        "element_id": "3008d7b16cdb3897c728ede76fc795d2",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.1,
                        1499.1
                    ],
                    [
                        99.1,
                        1520.4
                    ],
                    [
                        388.5,
                        1520.4
                    ],
                    [
                        388.5,
                        1499.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72632,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1,
            "parent_id": "69e52f9ada23c4c247bb3e5d3dc79f59"
        },
        "text": "Academic Editor: Guanghui Wen",
        "type": "NarrativeText"
    },
    {
        "element_id": "4fbbdbdabe10c314b51a6e5b658af367",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.4,
                        1551.6
                    ],
                    [
                        98.4,
                        1639.1
                    ],
                    [
                        330.3,
                        1639.1
                    ],
                    [
                        330.3,
                        1551.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82975,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1,
            "parent_id": "69e52f9ada23c4c247bb3e5d3dc79f59"
        },
        "text": "Received: 6 February 2022 Accepted: 15 March 2022 Published: 18 March 2022",
        "type": "NarrativeText"
    },
    {
        "element_id": "c5ff715d11c094e614cd13207a8a6123",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.0,
                        1290.0
                    ],
                    [
                        461.0,
                        1666.3
                    ],
                    [
                        1558.4,
                        1666.3
                    ],
                    [
                        1558.4,
                        1290.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95055,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1,
            "parent_id": "69e52f9ada23c4c247bb3e5d3dc79f59"
        },
        "text": "With the development of science and technology, intelligent robots have made great progress and played an important role in production and life [1]. Path planning and obsta- cle avoidance are challenging problems in the \ufb01eld of intelligent robots. However, most current studies focus on large, unknown environments or obstacles with static or random movement, without considering the confrontation environment. The confrontation and coordination of unmanned aerial vehicles (UAVs) are indispensable for the future. The traditional penetration strategy mainly includes deception and maneuver penetration [2]. Deception includes bait, stealth and interference, etc. Maneuvering penetration includes procedural, real-time intelligent maneuvers and multiple warhead maneuvers [3]. Com- pared with the traditional methods, intelligent strategy has advantages in online computing, wide applicability and strong robustness.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ca93db3c2da0ae354d5e97d8f737539e",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        92.7,
                        1668.3
                    ],
                    [
                        92.7,
                        1788.3
                    ],
                    [
                        430.4,
                        1788.3
                    ],
                    [
                        430.4,
                        1668.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88208,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1,
            "parent_id": "69e52f9ada23c4c247bb3e5d3dc79f59"
        },
        "text": "Publisher\u2019s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional af\ufb01l- iations.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a033b436759851d886b244320c18126b",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        1824.7
                    ],
                    [
                        99.2,
                        1879.8
                    ],
                    [
                        256.7,
                        1879.8
                    ],
                    [
                        256.7,
                        1824.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-1-3.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "9172721ae8e8af9e7ca0d5d2b42f9257",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        94.7,
                        1896.1
                    ],
                    [
                        94.7,
                        2150.3
                    ],
                    [
                        431.5,
                        2150.3
                    ],
                    [
                        431.5,
                        1896.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90475,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1
        },
        "text": "Copyright: \u00a9 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https:// creativecommons.org/licenses/by/ 4.0/).",
        "type": "NarrativeText"
    },
    {
        "element_id": "1352460c6ca1ef86dc630cae81d31a94",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.3,
                        1673.5
                    ],
                    [
                        461.3,
                        2154.5
                    ],
                    [
                        1558.4,
                        2154.5
                    ],
                    [
                        1558.4,
                        1673.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9465,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1
        },
        "text": "Reinforcement learning (RL), which is able to autonomously learn optimal strategies through continuous interaction with the environment, has become a research hotspot and is considered one of the most likely and important approaches to achieve general arti\ufb01cial intelligence computing [4\u20136]. Deep reinforcement learning (DRL) is widely used in intelligent control, path planning and other \ufb01elds [7\u201310]. Lei et al. proposed a method based on DRL to solve the problem of dynamic path planning of an unknown environment [11]. Based on layered control strategy and RL, a robust controller was proposed to realize robust control in the case of unknown dynamics parameters of quadrotors [12]. Gao et al. proposed a new incremental training model to solve the path planning problem of indoor robots based on RL [13]. Choi et al. proposed LSTM based RL to solve the navigation problem of robots with limited \ufb01eld of vision in a crowded environment [14]. The sampling-based planning is combined with RL to solve the large-range path planning problem [15]. Feng et al. solved collision avoidance problems with the help of DRL [16]. Dai et al. proposed a new distributed RL optimization algorithm to solve the dynamic economic",
        "type": "NarrativeText"
    },
    {
        "element_id": "49c517bee6fe0d792716aa6185980b0f",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.5,
                        2263.2
                    ],
                    [
                        98.5,
                        2285.8
                    ],
                    [
                        721.1,
                        2285.8
                    ],
                    [
                        721.1,
                        2263.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74311,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1
        },
        "text": "Robotics 2022, 11, 35. https://doi.org/10.3390/robotics11020035",
        "type": "NarrativeText"
    },
    {
        "element_id": "f628ecfac779bf3bd0741f346c94fffa",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1134.4,
                        2263.3
                    ],
                    [
                        1134.4,
                        2285.8
                    ],
                    [
                        1553.5,
                        2285.8
                    ],
                    [
                        1553.5,
                        2263.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.44058,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 1
        },
        "text": "https://www.mdpi.com/journal/robotics",
        "type": "NarrativeText"
    },
    {
        "element_id": "3670237c9e42077911d499d48b8b0e9c",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.3,
                        158.4
                    ],
                    [
                        98.3,
                        181.2
                    ],
                    [
                        291.3,
                        181.2
                    ],
                    [
                        291.3,
                        158.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74455,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 2
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "092797be17c6bbc6954288a27739fa04",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1486.9,
                        153.5
                    ],
                    [
                        1486.9,
                        181.3
                    ],
                    [
                        1555.1,
                        181.3
                    ],
                    [
                        1555.1,
                        153.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.63677,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 2
        },
        "text": "2 of 17",
        "type": "Header"
    },
    {
        "element_id": "8582036b00a9df71014ae4376d81fc26",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.4,
                        269.9
                    ],
                    [
                        461.4,
                        508.2
                    ],
                    [
                        1558.4,
                        508.2
                    ],
                    [
                        1558.4,
                        269.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9473,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 2,
            "parent_id": "092797be17c6bbc6954288a27739fa04"
        },
        "text": "dispatch problem for smart grid [17]. By virtue of the \ufb01tting and generalization ability of neural networks, DRL is more robust than traditional methods. In order to solve the problem of path planning in a large dynamic environment, Wang et al. proposed a globally guided RL method, in which the reward structure can be extended to any environment [18]. RL is also applied to the cooperative control of multi-agents [19]. Bei et al. proposed a new method for cooperative multi-agent reinforcement learning in both discrete and continuous action spaces [20].",
        "type": "NarrativeText"
    },
    {
        "element_id": "bf53536e1105409c0a2ebc8085622924",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        515.4
                    ],
                    [
                        462.2,
                        682.5
                    ],
                    [
                        1560.8,
                        682.5
                    ],
                    [
                        1560.8,
                        515.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93612,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 2,
            "parent_id": "092797be17c6bbc6954288a27739fa04"
        },
        "text": "However, few of the studies considered path planning in the confrontation scenario. In the face of this urgent requirement, we propose a penetration strategy based on the incremental training and reward compensation Deep Deterministic Policy Gradient (DDPG) algorithm, which does not need to model the environment. Furthermore, the strategy has real-time decision-making ability and can be applied to different environments.",
        "type": "NarrativeText"
    },
    {
        "element_id": "696d85cd58189187991baff26d3056f5",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        689.7
                    ],
                    [
                        462.2,
                        892.0
                    ],
                    [
                        1562.5,
                        892.0
                    ],
                    [
                        1562.5,
                        689.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94358,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 2,
            "parent_id": "092797be17c6bbc6954288a27739fa04"
        },
        "text": "The remainder of this paper is organized as follows. In Section 2, the confrontation environment is modeled. Then the reward function and the incremental training process are proposed in Section 3. In Section 4, the effectiveness of the proposed strategy is shown by Monte Carlo experiments and simulations in the Webots simulator. The superiority is con\ufb01rmed by comparing with arti\ufb01cial potential-\ufb01eld-based path planning. Finally, Section 5 draws the conclusion.",
        "type": "NarrativeText"
    },
    {
        "element_id": "20fb325c9300b885aa12e7a5313d8447",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        925.9
                    ],
                    [
                        462.2,
                        953.6
                    ],
                    [
                        903.2,
                        953.6
                    ],
                    [
                        903.2,
                        925.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88528,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 2,
            "parent_id": "092797be17c6bbc6954288a27739fa04"
        },
        "text": "2. The Confrontation Environment",
        "type": "Title"
    },
    {
        "element_id": "faa046a235a6df8b58f1ab6c0f94adc4",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.3,
                        967.9
                    ],
                    [
                        461.3,
                        1171.5
                    ],
                    [
                        1560.4,
                        1171.5
                    ],
                    [
                        1560.4,
                        967.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94629,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 2,
            "parent_id": "20fb325c9300b885aa12e7a5313d8447"
        },
        "text": "To simplify the problem, it is assumed that UAVs \ufb02y at a constant speed and altitude, and the confrontation environment is simpli\ufb01ed to a two-dimensional environment. The confrontation scenario includes penetrators, interceptors, static obstacles and a target area. The penetrator should break through the interception, bypass static obstacles, and reach the target area as soon as possible. Meanwhile, the interceptors try their best to intercept the penetrator before it reaches the target area. The confrontation scenario is shown in Figure 1.",
        "type": "NarrativeText"
    },
    {
        "element_id": "fb73c5cee2460c7d713beb6a6f2c75c0",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        474.8,
                        1215.1
                    ],
                    [
                        474.8,
                        1763.4
                    ],
                    [
                        1204.4,
                        1763.4
                    ],
                    [
                        1204.4,
                        1215.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92399,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-2-4.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 2
        },
        "text": "A y target area",
        "type": "Image"
    },
    {
        "element_id": "8edecc52b60cc2e2f176b4be20b823f4",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        458.9,
                        1800.4
                    ],
                    [
                        458.9,
                        1825.7
                    ],
                    [
                        870.6,
                        1825.7
                    ],
                    [
                        870.6,
                        1800.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.64228,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 2
        },
        "text": "Figure 1. The confrontation scenario.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d54efeefbbe628d4ca9b05aaff890d84",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        459.4,
                        1860.4
                    ],
                    [
                        459.4,
                        1958.4
                    ],
                    [
                        1562.9,
                        1958.4
                    ],
                    [
                        1562.9,
                        1860.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92218,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 2
        },
        "text": "P is the penetrator, and B is the interceptor. \u03b8p is the direction of the penetrator\u2019s velocity vp, and \u03b8b is the direction of the interceptor\u2019s velocity vb. The penetrator has a limited \ufb01eld of vision, while the interceptor has global vision.",
        "type": "NarrativeText"
    },
    {
        "element_id": "1fe2e5473fd99c37744f970403438beb",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        501.2,
                        1965.6
                    ],
                    [
                        501.2,
                        1993.3
                    ],
                    [
                        1562.7,
                        1993.3
                    ],
                    [
                        1562.7,
                        1965.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83645,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 2
        },
        "text": "Mathematical models of the penetrator and the interceptor are established as follows:",
        "type": "NarrativeText"
    },
    {
        "element_id": "51a63ec2f024e18330b8851a663895c9",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        762.6,
                        2025.2
                    ],
                    [
                        762.6,
                        2135.9
                    ],
                    [
                        1575.5,
                        2135.9
                    ],
                    [
                        1575.5,
                        2025.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81408,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 2
        },
        "text": "\u02d9xi vi cos \u03b8i 0 \u02d9yi \u02d9\u03b8i = vi sin \u03b8i 0 + 0 \u03c9i , (1)",
        "type": "Formula"
    },
    {
        "element_id": "f7b3087e7b2c832fb67b541a9be96e92",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.5,
                        158.3
                    ],
                    [
                        98.5,
                        181.2
                    ],
                    [
                        291.1,
                        181.2
                    ],
                    [
                        291.1,
                        158.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.77,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 3
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "d72ab5c47d829c288c87adc78f9edba4",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        451.3,
                        267.9
                    ],
                    [
                        451.3,
                        337.4
                    ],
                    [
                        1553.9,
                        337.4
                    ],
                    [
                        1553.9,
                        267.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90886,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 3,
            "parent_id": "f7b3087e7b2c832fb67b541a9be96e92"
        },
        "text": "where i is the penetrator P or the interceptor B, (xi, yi) is the agent\u2019s position, \u03b8i is the direction of the agent, and \u03c9i is the angular velocity, \u03c9i \u2208 [\u2212\u03c9i_max, \u03c9i_max].",
        "type": "NarrativeText"
    },
    {
        "element_id": "b75515eb66511d09cfb8b13b8bcd614d",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.3,
                        340.5
                    ],
                    [
                        460.3,
                        407.1
                    ],
                    [
                        1558.4,
                        407.1
                    ],
                    [
                        1558.4,
                        340.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88959,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 3,
            "parent_id": "f7b3087e7b2c832fb67b541a9be96e92"
        },
        "text": "In the scenario of Figure 1, it is shown that P and B have different maneuverability. Set that ap > ab, where ai = vi\u03c9i.",
        "type": "NarrativeText"
    },
    {
        "element_id": "4bc1c49cfca661439dea027e4e8c37d1",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        459.5,
                        410.8
                    ],
                    [
                        459.5,
                        612.8
                    ],
                    [
                        1558.4,
                        612.8
                    ],
                    [
                        1558.4,
                        410.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94837,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 3,
            "parent_id": "f7b3087e7b2c832fb67b541a9be96e92"
        },
        "text": "Figure 2 shows the limited view of the penetrator. The agent can sense whether there are obstacles in the 12 directions evenly distributed around it. The detection radius is rp. When obstacles enter the detection range of the penetrator, the corresponding detection signal is 1; otherwise, it is 0. The interceptor, on the other hand, has a global view and can sense the position and speed of the penetrator in real time. The interceptor adopts proportional guidance as the interception strategy.",
        "type": "NarrativeText"
    },
    {
        "element_id": "377b11e65b5e34b689b56958bc626289",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        468.5,
                        667.8
                    ],
                    [
                        468.5,
                        1294.5
                    ],
                    [
                        1064.9,
                        1294.5
                    ],
                    [
                        1064.9,
                        667.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90819,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-3-5.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 3
        },
        "text": "0 p V o I I I I / ON /penetfationu, / \u00e9 agent \u00bb \u00b0 0 0",
        "type": "Image"
    },
    {
        "element_id": "6510e64c696ee4df7fab806d63a7a2f7",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1330.3
                    ],
                    [
                        462.2,
                        1355.6
                    ],
                    [
                        974.3,
                        1355.6
                    ],
                    [
                        974.3,
                        1330.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81406,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 3
        },
        "text": "Figure 2. The sensory ability of the penetrator.",
        "type": "NarrativeText"
    },
    {
        "element_id": "75c1577a9ea6fdba8ff90734baed48a8",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.0,
                        1384.7
                    ],
                    [
                        460.0,
                        1412.3
                    ],
                    [
                        880.1,
                        1412.3
                    ],
                    [
                        880.1,
                        1384.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91376,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 3
        },
        "text": "3. RL-Based Penetration Strategy",
        "type": "Title"
    },
    {
        "element_id": "5c28d881a9d173ae72f67a45f8e30956",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.3,
                        1428.3
                    ],
                    [
                        461.3,
                        1737.9
                    ],
                    [
                        1556.3,
                        1737.9
                    ],
                    [
                        1556.3,
                        1428.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95084,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 3,
            "parent_id": "75c1577a9ea6fdba8ff90734baed48a8"
        },
        "text": "In this paper, the path-planning problem is expressed as a Markov decision process (MDP), modeled as a tuple (5, A, T, R, y), where S is the system\u2019s state space, A is the action space, and T : T(s;41 = s |s\u00a2 = 5,4, = a) is the state transition model. R: S x A \u2014 Ris the reward function. y \u20ac (0,1) is the discount factor that reflects the preference of immediate rewards over future ones. 7t : S \u2014 A is the policy that prescribes an action a \u20ac A for each state s \u20ac S. The value function V7(s) = Y,e, 7(als)g\u201d(s,a) is defined as the excepted return, starting with state s following policy 7t. While the maximum value of V\u201d is defined as V*(s). g\u201d(s,a) is the action value function, whilst the optimal action value function is called q*(s,a).",
        "type": "NarrativeText"
    },
    {
        "element_id": "bf3dbbc66748af315e60b3d4bbbc1819",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.4,
                        1745.1
                    ],
                    [
                        461.4,
                        1877.4
                    ],
                    [
                        1568.1,
                        1877.4
                    ],
                    [
                        1568.1,
                        1745.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93863,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 3,
            "parent_id": "75c1577a9ea6fdba8ff90734baed48a8"
        },
        "text": "For the confrontation scenario, as Figure 1 shows, both state and action are continuous variables. So the neural network is used to approximate the action value function Q : qw(s, a) = f (s, a, w), where w represents the parameters of the neural network Q. The training of DRL is to \ufb01nd the appropriate network parameters.",
        "type": "NarrativeText"
    },
    {
        "element_id": "0a0dfab4d79ea7f9492ed0a835adeca1",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        458.5,
                        1911.4
                    ],
                    [
                        458.5,
                        1939.0
                    ],
                    [
                        977.1,
                        1939.0
                    ],
                    [
                        977.1,
                        1911.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.70634,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 3,
            "parent_id": "75c1577a9ea6fdba8ff90734baed48a8"
        },
        "text": "3.1. DDPG Based Game Penetration Strategy",
        "type": "NarrativeText"
    },
    {
        "element_id": "0441d19727719a48e829a058cbb0e063",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1955.0
                    ],
                    [
                        462.2,
                        2087.4
                    ],
                    [
                        1562.1,
                        2087.4
                    ],
                    [
                        1562.1,
                        1955.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9358,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 3,
            "parent_id": "75c1577a9ea6fdba8ff90734baed48a8"
        },
        "text": "The penetration strategy used in this paper is the DDPG algorithm, which is the extension of the deep Q network (DQN). DDPG adds a policy network to output actions directly, which is why it can be applied in continuous space [21]. DDPG needs to learn both the Q network and the policy network. The structure is shown in Figure 3.",
        "type": "NarrativeText"
    },
    {
        "element_id": "52ca659ffab0cdd11bfa2b0d52384b50",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1486.7,
                        154.0
                    ],
                    [
                        1486.7,
                        181.2
                    ],
                    [
                        1555.2,
                        181.2
                    ],
                    [
                        1555.2,
                        154.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.6073,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 3
        },
        "text": "3 of 17",
        "type": "Header"
    },
    {
        "element_id": "7accfeb29fc445a0ec290514387a98f1",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.1,
                        158.2
                    ],
                    [
                        98.1,
                        181.2
                    ],
                    [
                        291.1,
                        181.2
                    ],
                    [
                        291.1,
                        158.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.55447,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 4
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "49ea9a7304f27744b0189423f28c1d86",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        464.1,
                        264.8
                    ],
                    [
                        464.1,
                        1127.3
                    ],
                    [
                        966.7,
                        1127.3
                    ],
                    [
                        966.7,
                        264.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.77207,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-4-6.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 4
        },
        "text": "g,,(S.a) policy network state S",
        "type": "Image"
    },
    {
        "element_id": "b3a4f2493c164a8b4bc291016359ede5",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        458.6,
                        1176.1
                    ],
                    [
                        458.6,
                        1201.4
                    ],
                    [
                        829.7,
                        1201.4
                    ],
                    [
                        829.7,
                        1176.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73997,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 4
        },
        "text": "Figure 3. The structure of DDPG.",
        "type": "FigureCaption"
    },
    {
        "element_id": "ef64dc1044f750799281e27ae930811f",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1235.9
                    ],
                    [
                        462.2,
                        1438.7
                    ],
                    [
                        1554.3,
                        1438.7
                    ],
                    [
                        1554.3,
                        1235.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95386,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 4
        },
        "text": "\u03d1 is the parameters of the policy network. Such a structure is called actor\u2013critic. The Q network is used to export the action value, which is called the critic. The policy network output represents actions, which is called the actor. Speci\ufb01cally, the network structures used in this paper are shown in Figures 4 and 5. Compared with the actor network, the critic network has a more complex structure. This difference enables the critic to infer the underlying state from the measurements and deal with the state transition.",
        "type": "NarrativeText"
    },
    {
        "element_id": "726b90328728925c6f3c5dadbe91b097",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.4,
                        1478.8
                    ],
                    [
                        462.4,
                        1933.8
                    ],
                    [
                        1548.2,
                        1933.8
                    ],
                    [
                        1548.2,
                        1478.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93136,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-4-7.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 4
        },
        "text": "( Actor network fully connected fully connected Wi state layer layer ReLU Tanh activation activation function function action",
        "type": "Image"
    },
    {
        "element_id": "6dc0e74bc24f0de12a746848e22f89d4",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1956.3
                    ],
                    [
                        462.2,
                        1981.6
                    ],
                    [
                        906.4,
                        1981.6
                    ],
                    [
                        906.4,
                        1956.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.86022,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 4
        },
        "text": "Figure 4. Structure of the actor network.",
        "type": "FigureCaption"
    },
    {
        "element_id": "1e480f69c800337a42e7c89516d7ed71",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1488.0,
                        154.5
                    ],
                    [
                        1488.0,
                        181.2
                    ],
                    [
                        1555.3,
                        181.2
                    ],
                    [
                        1555.3,
                        154.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.45247,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 4
        },
        "text": "4 of 17",
        "type": "Header"
    },
    {
        "element_id": "214d8d43cb8fc2f9b4e2d1b330c7ac74",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        96.9,
                        158.1
                    ],
                    [
                        96.9,
                        181.2
                    ],
                    [
                        293.5,
                        181.2
                    ],
                    [
                        293.5,
                        158.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.75262,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 5
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "737d6167d775194ec207f3904ef03a7f",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        479.5,
                        282.0
                    ],
                    [
                        479.5,
                        816.6
                    ],
                    [
                        1259.7,
                        816.6
                    ],
                    [
                        1259.7,
                        282.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93337,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-5-8.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 5
        },
        "text": "i Critic network Fully connection ritic networl state layer Fully connection layer ReLU activation function ReLU activation function Output of Critic Fully connection layer actior",
        "type": "Image"
    },
    {
        "element_id": "2a9d56508dd4f0d5a1c882a89df7b5df",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.9,
                        867.1
                    ],
                    [
                        460.9,
                        892.4
                    ],
                    [
                        905.5,
                        892.4
                    ],
                    [
                        905.5,
                        867.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87028,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 5
        },
        "text": "Figure 5. Structure of the critic network.",
        "type": "NarrativeText"
    },
    {
        "element_id": "1ab720614701a70f53d6ee53486f0d38",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        459.1,
                        927.7
                    ],
                    [
                        459.1,
                        1025.1
                    ],
                    [
                        1565.3,
                        1025.1
                    ],
                    [
                        1565.3,
                        927.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9404,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 5
        },
        "text": "In order to reduce the correlation of data and dif\ufb01culty of training, this paper adopts the method of experiential replay and independent target network training. The algorithm \ufb02ow presented in this paper is shown in Algorithm 1.",
        "type": "NarrativeText"
    },
    {
        "element_id": "b49ab6e75c918e5a1ae18b6719653df4",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        459.8,
                        1065.7
                    ],
                    [
                        459.8,
                        1093.9
                    ],
                    [
                        1135.2,
                        1093.9
                    ],
                    [
                        1135.2,
                        1065.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.77734,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 5
        },
        "text": "Algorithm 1 Attack and defense adversarial algorithm.",
        "type": "FigureCaption"
    },
    {
        "element_id": "52f6518d9f3c58ca5b3d5d0c9e3c96ae",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        489.9,
                        1096.7
                    ],
                    [
                        489.9,
                        1759.7
                    ],
                    [
                        1553.5,
                        1759.7
                    ],
                    [
                        1553.5,
                        1096.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88586,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 5
        },
        "text": "Randomly initialize O network gw and policy network gy\u00bb parameters Initialize the target network parameters gi, and gi, Initialize the experience pool for episode = 1,2---Ndo Random initialization of penetration position, target area, static obstacle area and interceptor position within a certain range fori=1,2---T do State 5, is obtained according to the local field of vision Select the action based on the current state and exploration noise a; = g9(St) + Gi Perform the action a;,observe the return r;, get the next state s;+1 Put the sample (s;, 4, rt, 5:41) in the experience pool D Sample random mini-batch of (5, 41,11, 5;41) from D Optimize Critic network parameters w: Loss = MSE|quw(s, a), + yga|(s',a') Optimize Actor network parameters 4: Loss = \u2014qu(s,@) Every C steps update @, 8: w= tw+(1\u2014t)w0 = 10+ (1-T)6 end for end for",
        "type": "NarrativeText"
    },
    {
        "element_id": "e5e5712057bd50042788c042b425ee8c",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        489.9,
                        1742.3
                    ],
                    [
                        489.9,
                        1769.9
                    ],
                    [
                        581.4,
                        1769.9
                    ],
                    [
                        581.4,
                        1742.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 5
        },
        "text": "end for",
        "type": "Title"
    },
    {
        "element_id": "c2268f21f0a63db87b67662971b5ab98",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.3,
                        1815.5
                    ],
                    [
                        461.3,
                        1912.9
                    ],
                    [
                        1571.9,
                        1912.9
                    ],
                    [
                        1571.9,
                        1815.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93259,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 5,
            "parent_id": "e5e5712057bd50042788c042b425ee8c"
        },
        "text": "The state input of DDPG is an 18-dimensional vector. They are 12-dimensional detec- tion states, position xp, yp, speed vxp, vyp and position of the target area (xt, yt), respectively. The action output is a 1-dimensional variable, i.e., the angular velocity of the penetrator.",
        "type": "NarrativeText"
    },
    {
        "element_id": "15b1ad4e57a803af321c1fc334794b6b",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.4,
                        1947.5
                    ],
                    [
                        461.4,
                        1975.1
                    ],
                    [
                        918.6,
                        1975.1
                    ],
                    [
                        918.6,
                        1947.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.85826,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 5,
            "parent_id": "e5e5712057bd50042788c042b425ee8c"
        },
        "text": "3.1.1. Design of the Reward Function",
        "type": "NarrativeText"
    },
    {
        "element_id": "ae62884df50a59d74bf9c76afa2ebf90",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1990.6
                    ],
                    [
                        462.2,
                        2157.8
                    ],
                    [
                        1562.0,
                        2157.8
                    ],
                    [
                        1562.0,
                        1990.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93482,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 5,
            "parent_id": "e5e5712057bd50042788c042b425ee8c"
        },
        "text": "In the confrontation scenario shown in Figure 1, the main objective of the penetrator is to break through the interception, bypass \ufb01xed obstacles, and reach the target area as soon as possible. At the same time, the movement range of the penetrator is limited. When it is intercepted, moves out of the boundary or hits static obstacles, the task fails, and this round of training is terminated in advance. The reward function is a key element in DRL",
        "type": "NarrativeText"
    },
    {
        "element_id": "825a8c84bd098b45ef876a00f910c354",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1487.8,
                        155.5
                    ],
                    [
                        1487.8,
                        181.2
                    ],
                    [
                        1555.6,
                        181.2
                    ],
                    [
                        1555.6,
                        155.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.60353,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 5
        },
        "text": "5 of 17",
        "type": "Header"
    },
    {
        "element_id": "093032385cb014dc7dd0719c49fc576f",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.5,
                        158.4
                    ],
                    [
                        98.5,
                        181.2
                    ],
                    [
                        291.2,
                        181.2
                    ],
                    [
                        291.2,
                        158.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.77514,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 6
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "bb16e9635722ffdc1d44f935cf7e88b9",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1487.1,
                        154.2
                    ],
                    [
                        1487.1,
                        181.2
                    ],
                    [
                        1554.6,
                        181.2
                    ],
                    [
                        1554.6,
                        154.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.59842,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 6,
            "parent_id": "093032385cb014dc7dd0719c49fc576f"
        },
        "text": "6 of 17",
        "type": "NarrativeText"
    },
    {
        "element_id": "3372b3ed27ec53808f28f1b5f0d39e80",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        457.4,
                        271.3
                    ],
                    [
                        457.4,
                        334.8
                    ],
                    [
                        1553.5,
                        334.8
                    ],
                    [
                        1553.5,
                        271.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91127,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 6,
            "parent_id": "093032385cb014dc7dd0719c49fc576f"
        },
        "text": "that supervises agents to learn and obtain the optimal policy. The reward function consists of three parts:",
        "type": "NarrativeText"
    },
    {
        "element_id": "db3f5cc528d378d965cdf369a4b34f77",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        803.6,
                        366.7
                    ],
                    [
                        803.6,
                        401.1
                    ],
                    [
                        1563.8,
                        401.1
                    ],
                    [
                        1563.8,
                        366.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.5518,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 6
        },
        "text": "R1 = \u03b21RT + \u03b22RP + \u03b23RS, (2)",
        "type": "Formula"
    },
    {
        "element_id": "80a32e3bad1b1bbbeaf3227260bce62a",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.7,
                        432.9
                    ],
                    [
                        460.7,
                        531.4
                    ],
                    [
                        1554.0,
                        531.4
                    ],
                    [
                        1554.0,
                        432.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92981,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 6
        },
        "text": "where RT is the instant reward associated with the distance between the target area, RP is the sparse penalty for terminating the round of training in advance, and RS is the instant reward associated with survival time. Specially, their expressions are as follows:",
        "type": "NarrativeText"
    },
    {
        "element_id": "6546f064dc4feb215751be51009632de",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        801.5,
                        568.1
                    ],
                    [
                        801.5,
                        770.1
                    ],
                    [
                        1539.7,
                        770.1
                    ],
                    [
                        1539.7,
                        568.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.86818,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 6
        },
        "text": "RT = 20 \u2212 D D \u2264 1 10 \u2212 D 1 < D \u2264 2 5 \u2212 D 2 < D \u2264 3 3 \u2212 D 3 < D \u2264 4 \u2212D 4 < D ,",
        "type": "Formula"
    },
    {
        "element_id": "070a37a169f5541bcf5ab7cbc5f0bbc0",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1521.3,
                        654.9
                    ],
                    [
                        1521.3,
                        682.6
                    ],
                    [
                        1553.5,
                        682.6
                    ],
                    [
                        1553.5,
                        654.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 6
        },
        "text": "(3)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "a967599b340155e8936397326c9ae174",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.0,
                        802.5
                    ],
                    [
                        461.0,
                        836.7
                    ],
                    [
                        746.6,
                        836.7
                    ],
                    [
                        746.6,
                        802.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79654,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 6
        },
        "text": "where D =||Xp \u2014 X;|l2.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f1b2638cb0b1f26964209ed6074f4e00",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        750.4,
                        870.3
                    ],
                    [
                        750.4,
                        946.7
                    ],
                    [
                        1553.5,
                        946.7
                    ],
                    [
                        1553.5,
                        870.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.71511,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 6
        },
        "text": "Rp = \u2212800 i f terminate in advance RS = 20 i f survive (4)",
        "type": "Formula"
    },
    {
        "element_id": "d1ddd6dcb3e4992cd16cfc134567725d",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.4,
                        979.4
                    ],
                    [
                        461.4,
                        1287.4
                    ],
                    [
                        1557.0,
                        1287.4
                    ],
                    [
                        1557.0,
                        979.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95417,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 6
        },
        "text": "Instant rewards can be obtained by the reward function at each time step. Therefore, the model can learn the speci\ufb01ed functions on the condition that the reward function is designed reasonably. In this paper, \u03b2i(i = 1, 2, 3) represents the weights of each reward function. Different weights cause different training results. When \u03b23 > 0, the agent is positively rewarded for survival and tends to learn to survive. However, when \u03b23 < 0, the agent is penalized for survival and tends to end the training as soon as possible. When a set of parameters is selected, the reward function is drawn as follows. It can be seen from Figures 6 and 7 that the reward function is correctly set up to guide the agent toward the target area.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c8be8a1621c34c6d5c19a1ef39572f69",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        428.0,
                        1282.4
                    ],
                    [
                        428.0,
                        1926.1
                    ],
                    [
                        1286.1,
                        1926.1
                    ],
                    [
                        1286.1,
                        1282.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-6-9.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 6
        },
        "text": "30 20 10 reward -10 20 10 y(m) 0 0 x(m)",
        "type": "Image"
    },
    {
        "element_id": "695c2f7fef0226b11b9ae570f0b2d706",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.8,
                        1919.8
                    ],
                    [
                        460.8,
                        1945.1
                    ],
                    [
                        801.4,
                        1945.1
                    ],
                    [
                        801.4,
                        1919.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.7012,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 6
        },
        "text": "Figure 6. The reward function.",
        "type": "FigureCaption"
    },
    {
        "element_id": "35e1201b854349927e2e2bf6ecc7bad8",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.5,
                        158.2
                    ],
                    [
                        98.5,
                        181.2
                    ],
                    [
                        290.9,
                        181.2
                    ],
                    [
                        290.9,
                        158.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73147,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "5a56561b4eec544cb070fc8c06f10342",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1487.5,
                        154.3
                    ],
                    [
                        1487.5,
                        181.2
                    ],
                    [
                        1554.9,
                        181.2
                    ],
                    [
                        1554.9,
                        154.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.67427,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "7 of 17",
        "type": "Header"
    },
    {
        "element_id": "7d4fe4a86894ef9d53cda5affe275891",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        412.6,
                        226.3
                    ],
                    [
                        412.6,
                        904.9
                    ],
                    [
                        1317.4,
                        904.9
                    ],
                    [
                        1317.4,
                        226.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-7-10.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "o) 5 10 15 20 x(m)",
        "type": "Image"
    },
    {
        "element_id": "e67ff4f980b190bdc8eac6af34ba79f4",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        459.7,
                        923.0
                    ],
                    [
                        459.7,
                        948.3
                    ],
                    [
                        891.5,
                        948.3
                    ],
                    [
                        891.5,
                        923.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83598,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "Figure 7. Top view of reward function.",
        "type": "FigureCaption"
    },
    {
        "element_id": "3d6453047f1137f90372697dc333c54a",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        977.8
                    ],
                    [
                        462.2,
                        1005.5
                    ],
                    [
                        1133.2,
                        1005.5
                    ],
                    [
                        1133.2,
                        977.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81626,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "3.1.2. Reward Compensation and Incremental Training",
        "type": "NarrativeText"
    },
    {
        "element_id": "446266db81ebd742ce66cb14268e41e7",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.2,
                        1020.4
                    ],
                    [
                        460.2,
                        1153.2
                    ],
                    [
                        1559.1,
                        1153.2
                    ],
                    [
                        1559.1,
                        1020.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93745,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "In Equation (3), the reward function RT is related to the distance from the starting point to the target region, which causes the reward function to vary greatly with the initial points. The different sizes of the return functions make training harder. To solve this, a compensation reward is proposed:",
        "type": "NarrativeText"
    },
    {
        "element_id": "043e6b5f9c93652921f82b6755bd5a97",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        842.5,
                        1185.5
                    ],
                    [
                        842.5,
                        1247.0
                    ],
                    [
                        1563.3,
                        1247.0
                    ],
                    [
                        1563.3,
                        1185.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.77496,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "Ra = [\\|Xp \u2014 Xillads, 6)",
        "type": "Formula"
    },
    {
        "element_id": "24b9251e0f6462a1dafee92ff5d3f723",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        459.7,
                        1273.2
                    ],
                    [
                        459.7,
                        1304.1
                    ],
                    [
                        987.2,
                        1304.1
                    ],
                    [
                        987.2,
                        1273.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.50296,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "where l is the directed line from XP to Xt.",
        "type": "NarrativeText"
    },
    {
        "element_id": "637dca17c2d2e7abc04fc06bf71e2055",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        511.6,
                        1308.6
                    ],
                    [
                        511.6,
                        1336.3
                    ],
                    [
                        1019.5,
                        1336.3
                    ],
                    [
                        1019.5,
                        1308.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.69788,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "In summary, the total reward function is",
        "type": "NarrativeText"
    },
    {
        "element_id": "fa560fd39dedebf298bbf5d785c026ff",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        812.1,
                        1374.2
                    ],
                    [
                        812.1,
                        1450.4
                    ],
                    [
                        1565.3,
                        1450.4
                    ],
                    [
                        1565.3,
                        1374.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82035,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "R = R1 + R2 R1 i f success else (6)",
        "type": "Formula"
    },
    {
        "element_id": "09cf2a9fa8babc7f403c9056c034e12a",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1483.1
                    ],
                    [
                        462.2,
                        1616.1
                    ],
                    [
                        1561.7,
                        1616.1
                    ],
                    [
                        1561.7,
                        1483.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93508,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "It should be pointed out that incremental training scheme can effectively improve the training ef\ufb01ciency and reduce training times [13]. Therefore, the task is decomposed according to the dif\ufb01culty of the training. Meanwhile, it should be noted that the weight of the reward functions should be adjusted reasonably in different training stages.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9d7e9f4dd9b1b68824058c57dabb0ae8",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.8,
                        1631.6
                    ],
                    [
                        460.8,
                        1694.1
                    ],
                    [
                        1560.3,
                        1694.1
                    ],
                    [
                        1560.3,
                        1631.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83593,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "1. In the early stage of training, the interceptor is not included. The main purpose is to train the agent to survive, and avoid the agent collision boundary and static obstacles;",
        "type": "ListItem"
    },
    {
        "element_id": "a1ea1492a33fcebc13e1de30fd1d2e03",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.9,
                        1701.2
                    ],
                    [
                        460.9,
                        1763.9
                    ],
                    [
                        1557.5,
                        1763.9
                    ],
                    [
                        1557.5,
                        1701.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.76756,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "2. In the middle stage, the interceptor is also not included, but \u03b23 is decreased to make the agent reach the target area as soon as possible and avoid collisions;",
        "type": "ListItem"
    },
    {
        "element_id": "5a1f1f29d0a73712f026a6c221efcb68",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        455.8,
                        1771.1
                    ],
                    [
                        455.8,
                        1833.6
                    ],
                    [
                        1569.5,
                        1833.6
                    ],
                    [
                        1569.5,
                        1771.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88201,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "3. In the \ufb01nal stage, the interceptor is included. The further training enables the agent to break through the intercept.",
        "type": "ListItem"
    },
    {
        "element_id": "61bcf1446b9556e7fd4d143a82030a9b",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        459.3,
                        1868.2
                    ],
                    [
                        459.3,
                        1895.9
                    ],
                    [
                        1300.2,
                        1895.9
                    ],
                    [
                        1300.2,
                        1868.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.85932,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "3.1.3. Arti\ufb01cial Potential Field (APF) Based Path Planning Algorithm",
        "type": "NarrativeText"
    },
    {
        "element_id": "dee6db69c1c133a27cdf7cce2d62bed8",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.4,
                        1911.4
                    ],
                    [
                        461.4,
                        2008.8
                    ],
                    [
                        1562.8,
                        2008.8
                    ],
                    [
                        1562.8,
                        1911.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92242,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "APF is a widely used path planning algorithm at present [22]. Its basic principle is to construct an APF environment in which the target point provides gravity and the obstacles provide repulsion. The improved APF method is de\ufb01ned as",
        "type": "NarrativeText"
    },
    {
        "element_id": "d1cb7277e8437ec03f49905f75dda01b",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        816.2,
                        2044.2
                    ],
                    [
                        816.2,
                        2124.1
                    ],
                    [
                        1554.8,
                        2124.1
                    ],
                    [
                        1554.8,
                        2044.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.85047,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 7
        },
        "text": "Uatx(x) = 1/2k(x \u2212 xt)2 Uaty(y) = 1/2k(y \u2212 yt)2 , (7)",
        "type": "Formula"
    },
    {
        "element_id": "749aa3928b3c77d5c1a5afb5c89b4bf4",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.5,
                        158.2
                    ],
                    [
                        98.5,
                        181.2
                    ],
                    [
                        291.2,
                        181.2
                    ],
                    [
                        291.2,
                        158.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.75781,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "1d10c2e31c75ca77f41e5bbed50eab78",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1487.0,
                        155.7
                    ],
                    [
                        1487.0,
                        181.2
                    ],
                    [
                        1554.9,
                        181.2
                    ],
                    [
                        1554.9,
                        155.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79555,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8,
            "parent_id": "749aa3928b3c77d5c1a5afb5c89b4bf4"
        },
        "text": "8 of 17",
        "type": "NarrativeText"
    },
    {
        "element_id": "b4bba01a8242061da0133741769e2986",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.6,
                        267.9
                    ],
                    [
                        460.6,
                        333.8
                    ],
                    [
                        1553.5,
                        333.8
                    ],
                    [
                        1553.5,
                        267.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90687,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8,
            "parent_id": "749aa3928b3c77d5c1a5afb5c89b4bf4"
        },
        "text": "where k represents the gravitational gain, and Uat(x, y) is the potential energy at (x, y). The gravitation functions are expressed as",
        "type": "NarrativeText"
    },
    {
        "element_id": "35fbe2fad7e50093b725ced520e3bfb4",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        709.6,
                        355.1
                    ],
                    [
                        709.6,
                        434.7
                    ],
                    [
                        1561.1,
                        434.7
                    ],
                    [
                        1561.1,
                        355.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.7612,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "Fatx(x) = \u2212grad[Uatx(x) = \u2212k(x \u2212 xt)] Faty(y) = \u2212grad[Uaty(y) = \u2212k(y \u2212 yt)] (8)",
        "type": "Formula"
    },
    {
        "element_id": "7a50ef63792b6f39f2c2e04739cdc873",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        516.6,
                        464.7
                    ],
                    [
                        516.6,
                        492.4
                    ],
                    [
                        1464.9,
                        492.4
                    ],
                    [
                        1464.9,
                        464.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87856,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "The repulsive potential \ufb01eld function generated by the obstacles is de\ufb01ned as",
        "type": "NarrativeText"
    },
    {
        "element_id": "bfbe6e883af07f0c0415fda0bb084cb4",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        710.3,
                        510.9
                    ],
                    [
                        710.3,
                        595.4
                    ],
                    [
                        1571.6,
                        595.4
                    ],
                    [
                        1571.6,
                        510.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74709,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "Ure(x, y) = 1/2\u03b7[1/\u03c1 \u2212 1/\u03c10]2d2 0 \u03c1 \u2264 \u03c10 \u03c1 > \u03c10 (9)",
        "type": "Formula"
    },
    {
        "element_id": "2dd5d8d2cf27d606ba674e97c14e6322",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        893.3,
                        602.8
                    ],
                    [
                        893.3,
                        653.3
                    ],
                    [
                        1560.0,
                        653.3
                    ],
                    [
                        1560.0,
                        602.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.50402,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "d = (x \u2212 xt)2 + (y \u2212 yt)2 (10)",
        "type": "Formula"
    },
    {
        "element_id": "d213350aad5c4b53e619d9f87fb9d6f9",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        856.0,
                        655.4
                    ],
                    [
                        856.0,
                        720.3
                    ],
                    [
                        1553.6,
                        720.3
                    ],
                    [
                        1553.6,
                        655.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73921,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "p= Yay) - 1, (11)",
        "type": "Formula"
    },
    {
        "element_id": "d184462988b88ea10b019ad7e5b5562d",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        459.8,
                        746.3
                    ],
                    [
                        459.8,
                        844.6
                    ],
                    [
                        1553.6,
                        844.6
                    ],
                    [
                        1553.6,
                        746.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91762,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "where \u03b7 is the repulsive gain coef\ufb01cient, \u03c1 represents the shortest distance between the agent and the obstacles, and r is the radius of the obstacles. \u03c10 is a constant parameter, represents the in\ufb02uence range of the obstacles. Similarly, the repulsion functions are expressed as",
        "type": "NarrativeText"
    },
    {
        "element_id": "577572aa1475bb4d6d7afc953f9bca57",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        796.6,
                        865.8
                    ],
                    [
                        796.6,
                        947.0
                    ],
                    [
                        1563.5,
                        947.0
                    ],
                    [
                        1563.5,
                        865.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73672,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "Frex = Frex1 + Frex2 0 \u03c1 \u2264 \u03c10 \u03c1 > \u03c10 (12)",
        "type": "Formula"
    },
    {
        "element_id": "73c72c32326b14b0b2c370f44edc6f96",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        790.1,
                        960.6
                    ],
                    [
                        790.1,
                        1039.4
                    ],
                    [
                        1558.8,
                        1039.4
                    ],
                    [
                        1558.8,
                        960.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.7983,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "Frey = Frey1 + Frey2 0 \u03c1 \u2264 \u03c10 \u03c1 > \u03c10 , (13)",
        "type": "Formula"
    },
    {
        "element_id": "81e6580d3c519decb1570a03606a2c99",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.0,
                        1070.2
                    ],
                    [
                        461.0,
                        1097.9
                    ],
                    [
                        537.2,
                        1097.9
                    ],
                    [
                        537.2,
                        1070.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88197,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "where",
        "type": "NarrativeText"
    },
    {
        "element_id": "01c714448fdbd26bf3732d0808a3fa8b",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        773.1,
                        1110.4
                    ],
                    [
                        773.1,
                        1203.3
                    ],
                    [
                        1553.5,
                        1203.3
                    ],
                    [
                        1553.5,
                        1110.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79517,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "Frex1 = \u03b7[ 1 \u03c1 \u2212 1 \u03c10 ] 1 \u03c13 (x \u2212 xb)d2 Frey1 = \u03b7[ 1 \u03c1 \u2212 1 \u03c10 ] 1 \u03c13 (y \u2212 yb)d2 (14)",
        "type": "Formula"
    },
    {
        "element_id": "10163d90f1189a61a3928e09f13f3440",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        791.3,
                        1216.7
                    ],
                    [
                        791.3,
                        1308.9
                    ],
                    [
                        1555.2,
                        1308.9
                    ],
                    [
                        1555.2,
                        1216.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.7751,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "Frex2 = \u2212\u03b7[ 1 \u03c1 \u2212 1 \u03c10 ]2(x \u2212 xt) Frey2 = \u2212\u03b7[ 1 \u03c1 \u2212 1 \u03c10 ]2(y \u2212 yt) (15)",
        "type": "Formula"
    },
    {
        "element_id": "f9083f7195ce34faa0533822244d9b33",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1342.3
                    ],
                    [
                        462.2,
                        1370.0
                    ],
                    [
                        1188.1,
                        1370.0
                    ],
                    [
                        1188.1,
                        1342.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84778,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "3.1.4. Proportional Guidance-Based Interception Algorithm",
        "type": "NarrativeText"
    },
    {
        "element_id": "976231a7fd915bc82b445f910ae8b21b",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.3,
                        1385.5
                    ],
                    [
                        461.3,
                        1517.8
                    ],
                    [
                        1558.4,
                        1517.8
                    ],
                    [
                        1558.4,
                        1385.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93251,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "The proportional guidance is to make the interceptor\u2019s rotational angular velocity pro- portional to the line-of-sight angular velocity. Assuming that the position of the interceptor is xb, yb, the speed is vxb, vyb, the position of the penetrator is x, y, and the speed is vx, vy. The relative position and speed of the interceptor to the penetrator are shown in (16):",
        "type": "NarrativeText"
    },
    {
        "element_id": "7f24e86952eba8c3e431ae7721bcaf99",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        865.0,
                        1552.4
                    ],
                    [
                        865.0,
                        1717.4
                    ],
                    [
                        1553.5,
                        1717.4
                    ],
                    [
                        1553.5,
                        1552.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.78549,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "xr = xb \u2212 x yr = yb \u2212 y vxr = vxb \u2212 vx vyr = vyb \u2212 vy (16)",
        "type": "Formula"
    },
    {
        "element_id": "a65fbc88a63984fd40ba0e4a5296dae0",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        519.4,
                        1749.0
                    ],
                    [
                        519.4,
                        1776.6
                    ],
                    [
                        1408.5,
                        1776.6
                    ],
                    [
                        1408.5,
                        1749.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84482,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "The interceptor\u2019s line-of-sight angle to the penetrator can be obtained as",
        "type": "NarrativeText"
    },
    {
        "element_id": "c794292fcf2613668205e97035335292",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1032.3,
                        1784.8
                    ],
                    [
                        1032.3,
                        1814.9
                    ],
                    [
                        1054.7,
                        1814.9
                    ],
                    [
                        1054.7,
                        1784.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "xr",
        "type": "Title"
    },
    {
        "element_id": "4698b5563d89340e110f6377bb46f2f7",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        889.0,
                        1795.0
                    ],
                    [
                        889.0,
                        1852.6
                    ],
                    [
                        1556.6,
                        1852.6
                    ],
                    [
                        1556.6,
                        1795.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80556,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "q = arctan( yr ) (17)",
        "type": "Formula"
    },
    {
        "element_id": "eaae23b1807e136d583777e12ac23bcc",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1882.6
                    ],
                    [
                        462.2,
                        1910.3
                    ],
                    [
                        917.5,
                        1910.3
                    ],
                    [
                        917.5,
                        1882.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88866,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "and the angle\u2019s rate can be written as",
        "type": "NarrativeText"
    },
    {
        "element_id": "d19e10e7d04592891de543574d9d6134",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        867.5,
                        1935.6
                    ],
                    [
                        867.5,
                        2011.3
                    ],
                    [
                        1553.5,
                        2011.3
                    ],
                    [
                        1553.5,
                        1935.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.78744,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "\u02d9q = vyrxr \u2212 vxryr x2 r + y2 r (18)",
        "type": "Formula"
    },
    {
        "element_id": "053bcce45b5f58405603e0e11739a1a4",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        521.3,
                        2038.6
                    ],
                    [
                        521.3,
                        2066.3
                    ],
                    [
                        1295.7,
                        2066.3
                    ],
                    [
                        1295.7,
                        2038.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.8311,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "Then, the angular velocity of the interceptor can be obtained by",
        "type": "NarrativeText"
    },
    {
        "element_id": "7479ebf6c1c438f3eeb2796d743394d7",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        903.4,
                        2099.2
                    ],
                    [
                        903.4,
                        2135.5
                    ],
                    [
                        1555.0,
                        2135.5
                    ],
                    [
                        1555.0,
                        2099.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.66745,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 8
        },
        "text": "\u03c9b = K( \u02d9q), (19)",
        "type": "Formula"
    },
    {
        "element_id": "31b751ef09f6d11d53fb2cd3167240d4",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.3,
                        158.4
                    ],
                    [
                        98.3,
                        181.2
                    ],
                    [
                        291.2,
                        181.2
                    ],
                    [
                        291.2,
                        158.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.70439,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 9
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "c290c22df1a1dfbb6fea242691506b81",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.0,
                        267.9
                    ],
                    [
                        461.0,
                        299.0
                    ],
                    [
                        1319.5,
                        299.0
                    ],
                    [
                        1319.5,
                        267.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 9,
            "parent_id": "31b751ef09f6d11d53fb2cd3167240d4"
        },
        "text": "where K is the coef\ufb01cient. In this paper, K = 2 and K = 3, respectively.",
        "type": "NarrativeText"
    },
    {
        "element_id": "1f1e71c71556ddee26fc4c0ce507dc63",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.4,
                        333.1
                    ],
                    [
                        461.4,
                        360.8
                    ],
                    [
                        802.1,
                        360.8
                    ],
                    [
                        802.1,
                        333.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83057,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 9,
            "parent_id": "31b751ef09f6d11d53fb2cd3167240d4"
        },
        "text": "4. Simulations and Results",
        "type": "Title"
    },
    {
        "element_id": "8ca5e2815e9de304af869ae6b9e5aa64",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        456.5,
                        370.3
                    ],
                    [
                        456.5,
                        398.0
                    ],
                    [
                        799.8,
                        398.0
                    ],
                    [
                        799.8,
                        370.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.59653,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 9,
            "parent_id": "1f1e71c71556ddee26fc4c0ce507dc63"
        },
        "text": "4.1. Simulations Based on RL",
        "type": "NarrativeText"
    },
    {
        "element_id": "95ee1da58c55ae47609cc0bec41107e6",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        521.3,
                        414.1
                    ],
                    [
                        521.3,
                        441.8
                    ],
                    [
                        979.4,
                        441.8
                    ],
                    [
                        979.4,
                        414.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.57175,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 9,
            "parent_id": "1f1e71c71556ddee26fc4c0ce507dc63"
        },
        "text": "The parameters are shown in Table 1.",
        "type": "NarrativeText"
    },
    {
        "element_id": "eb0cd978068fd777a4e084a4b289d9cc",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.9,
                        484.4
                    ],
                    [
                        460.9,
                        509.7
                    ],
                    [
                        854.6,
                        509.7
                    ],
                    [
                        854.6,
                        484.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.765,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 9,
            "parent_id": "1f1e71c71556ddee26fc4c0ce507dc63"
        },
        "text": "Table 1. Parameters of the scenario.",
        "type": "NarrativeText"
    },
    {
        "element_id": "824e5dc5a23a0cc42ae3ce8333d58ca2",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        492.3,
                        533.1
                    ],
                    [
                        492.3,
                        881.6
                    ],
                    [
                        1462.6,
                        881.6
                    ],
                    [
                        1462.6,
                        533.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.57001,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-9-1.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 9,
            "parent_id": "1f1e71c71556ddee26fc4c0ce507dc63",
            "text_as_html": "<table><thead><tr><th>Boundaries (m) Speed of the penetrator (m/s)</th><th></th><th>\u20141&lt;x&lt;20,\u20141&lt;y&lt;20 Vp =1 &lt;</th></tr></thead><tbody><tr><td>Radius of obstacles (m) Radius of the target area (m)</td><td></td><td>r=0.7 nl</td></tr><tr><td>Intercept radius (m) Detection radius of the penetrator (m)</td><td></td><td>1, 203 rp =1</td></tr><tr><td>The target area (m) Initial area of the</td><td>10&lt; x</td><td>&lt;12,10&lt;y &lt;12</td></tr><tr><td>penetrator (m) Initial direction of the penetrator (rad/s) Initial position of interceptors</td><td></td><td>0&lt;x&lt;10&lt;y&lt;1 7/4 (xp, yt, 70/4 rad)</td></tr></tbody></table>"
        },
        "text": "Item Value Boundaries (m) Speed of the penetrator (m/s) Angular velocity of the penetrator (rad/s) Speed of interceptors (m/s) Angular velocity of interceptors (rad/s) Radius of obstacles (m) Radius of the target area (m) Intercept radius (m) Detection radius of the penetrator (m) The target area (m) Initial area of the penetrator (m) \u22121 \u2264 x \u2264 20, \u22121 \u2264 y \u2264 20 vp = 1 \u22120.5 \u2264 \u03c9p \u2264 0.5 vb = 1.2 \u22120.4 \u2264 \u03c9b \u2264 0.4 r = 0.7 rt = 1 rb = 0.3 rp = 1 10 \u2264 xt \u2264 12, 10 \u2264 yt \u2264 12 0 \u2264 x \u2264 1, 0 \u2264 y \u2264 1 Initial direction of the penetrator (rad/s) \u03c0/4 Initial position of interceptors (xt, yt, \u03c0/4 rad)",
        "type": "Table"
    },
    {
        "element_id": "274f3947bd9541074457d1f58ab77f02",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        455.3,
                        930.7
                    ],
                    [
                        455.3,
                        1028.1
                    ],
                    [
                        1560.4,
                        1028.1
                    ],
                    [
                        1560.4,
                        930.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93308,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 9,
            "parent_id": "1f1e71c71556ddee26fc4c0ce507dc63"
        },
        "text": "The three subtasks all adopt the same network structure, as Figures 4 and 5 show. The weight factors \u03b21, \u03b22, \u03b23 are changed only during the training. Figure 8 shows the training results for different subtasks.",
        "type": "NarrativeText"
    },
    {
        "element_id": "12ef4c0bd0702efe3f068214237bfc41",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        448.6,
                        1067.0
                    ],
                    [
                        448.6,
                        2035.1
                    ],
                    [
                        1537.0,
                        2035.1
                    ],
                    [
                        1537.0,
                        1067.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91042,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-9-11.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 9
        },
        "text": "(a)  (b) ",
        "type": "Image"
    },
    {
        "element_id": "d07be3b70245cd9f099f369a30c01c44",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        694.4,
                        2026.6
                    ],
                    [
                        694.4,
                        2049.1
                    ],
                    [
                        718.9,
                        2049.1
                    ],
                    [
                        718.9,
                        2026.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 9
        },
        "text": "(c)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "6f0764e18636d130b5a1ce54b2d97441",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1197.4,
                        2026.6
                    ],
                    [
                        1197.4,
                        2049.1
                    ],
                    [
                        1225.7,
                        2049.1
                    ],
                    [
                        1225.7,
                        2026.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 9
        },
        "text": "(d)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "9a31442612d6ad62ef605d11af3a129a",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        454.5,
                        2084.6
                    ],
                    [
                        454.5,
                        2145.5
                    ],
                    [
                        1553.5,
                        2145.5
                    ],
                    [
                        1553.5,
                        2084.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91886,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 9
        },
        "text": "Figure 8. Results in different training stages. (a) Out of bounds before training; (b) the shortest path to reach the target area; (c) intercepted by the interceptors; (d) break through the interception.",
        "type": "FigureCaption"
    },
    {
        "element_id": "a60f4f0b7503cf22b658f6e000aa2f6a",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1487.6,
                        155.5
                    ],
                    [
                        1487.6,
                        181.2
                    ],
                    [
                        1555.6,
                        181.2
                    ],
                    [
                        1555.6,
                        155.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.51026,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 9
        },
        "text": "9 of 17",
        "type": "Header"
    },
    {
        "element_id": "1030b5bd64adcb170db0e4c82ac79918",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.4,
                        158.3
                    ],
                    [
                        98.4,
                        181.2
                    ],
                    [
                        291.0,
                        181.2
                    ],
                    [
                        291.0,
                        158.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.76272,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 10
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "fd8de934ddd1f58b61b7193c0519a028",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.4,
                        271.0
                    ],
                    [
                        461.4,
                        438.5
                    ],
                    [
                        1557.2,
                        438.5
                    ],
                    [
                        1557.2,
                        271.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92908,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 10,
            "parent_id": "1030b5bd64adcb170db0e4c82ac79918"
        },
        "text": "Figure 8a shows that the agent adopts a random strategy and exceeds the boundary before training. After the \ufb01rst and the second stages of training, the penetrator \ufb01nds the shortest path that meets its overload constraint to reach the target area. However, when the proportional guidance-based interceptors are added, the penetrator is blocked, as Figure 8c illustrates. After further training, the agent learns to penetrate \ufb01nally, as Figure 8d shows.",
        "type": "NarrativeText"
    },
    {
        "element_id": "cd9d61b07aa69d72f28d8d95c485e5bc",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        445.6
                    ],
                    [
                        462.2,
                        682.5
                    ],
                    [
                        1553.5,
                        682.5
                    ],
                    [
                        1553.5,
                        445.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93996,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 10,
            "parent_id": "1030b5bd64adcb170db0e4c82ac79918"
        },
        "text": "In the scene shown in Figure 8d, the angular velocity of the penetrator and the interceptor is illustrated in Figure 9. It can be seen that the penetrator reaches its maximum overload for penetration. Figure 10 illustrates the line-of-sight angles and their rates. The line-of-sight angles change rapidly with the decrease in the relative distance. This increases the dif\ufb01culty of interception and is conducive to the penetration. The penetrator breaks through the interception by taking advantage of its higher maneuverability, which proves the effectiveness of the penetration strategy.",
        "type": "NarrativeText"
    },
    {
        "element_id": "5caad56d73db1d48e5900695a7cd6c0e",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        467.4,
                        725.2
                    ],
                    [
                        467.4,
                        1361.0
                    ],
                    [
                        1258.0,
                        1361.0
                    ],
                    [
                        1258.0,
                        725.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92139,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-10-12.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 10
        },
        "text": "06 = = \u2014penetrator | | \u00b0 \u2014 interceptor | .--\u2014,. ee interceptor 2 angular velocity(rad/s) t(s)",
        "type": "Image"
    },
    {
        "element_id": "0b59231281c75b3034a790bf1846bd71",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1389.1
                    ],
                    [
                        462.2,
                        1414.4
                    ],
                    [
                        842.2,
                        1414.4
                    ],
                    [
                        842.2,
                        1389.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.71046,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 10
        },
        "text": "Figure 9. Angle velocity of agents.",
        "type": "FigureCaption"
    },
    {
        "element_id": "bc6df4bd054515fc4ab7436b851de4cc",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        660.0,
                        1444.6
                    ],
                    [
                        660.0,
                        1462.5
                    ],
                    [
                        1108.3,
                        1462.5
                    ],
                    [
                        1108.3,
                        1444.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.33125,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 10
        },
        "text": "distance between the interceptors and the penetrator",
        "type": "FigureCaption"
    },
    {
        "element_id": "dff1f4d89160b8a58e67d2c5abdcaf1c",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        472.0,
                        1454.4
                    ],
                    [
                        472.0,
                        2094.0
                    ],
                    [
                        1266.0,
                        2094.0
                    ],
                    [
                        1266.0,
                        1454.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91366,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-10-13.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 10
        },
        "text": "15 penetrator T T T T T T 10 \u2014 with the interceptor 1 = = \u2014 with the interceptor 2 | - 0 2 4 6 8 10 12 14 16 18 angle of view and its rate with interceptor | 100 T T T T T T op \u2014-\u2014\u2014\u2014-\u2014\u2014\u2014-. \u2014\u2014\u2014 angle of view \u00ab = = =rate of change 100) L 1 L 1 i L 0 2 4 6 8 10 12 14 16 18 100 angle of view and its rate with interceptor 2 T T T T T T T T Ome eee eer kre ee \u2014 angle of view s = = =rate of change -100 | 1 1 | 1 1 0 2 4 6 8 10 12 14 16 18 ts)",
        "type": "Image"
    },
    {
        "element_id": "da9f550772e3b4aae6e1c6390b9e042c",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.4,
                        2125.5
                    ],
                    [
                        461.4,
                        2150.8
                    ],
                    [
                        960.1,
                        2150.8
                    ],
                    [
                        960.1,
                        2125.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.67767,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 10
        },
        "text": "Figure 10. Line-of-sight angles and their rate.",
        "type": "FigureCaption"
    },
    {
        "element_id": "50aa46f61698801d2d73d2ce1e87d344",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1477.8,
                        153.7
                    ],
                    [
                        1477.8,
                        181.2
                    ],
                    [
                        1554.2,
                        181.2
                    ],
                    [
                        1554.2,
                        153.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.63312,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 10
        },
        "text": "10 of 17",
        "type": "NarrativeText"
    },
    {
        "element_id": "9d2d0305e93f2fbb51054ca491e5c5ee",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.4,
                        158.2
                    ],
                    [
                        98.4,
                        181.2
                    ],
                    [
                        291.0,
                        181.2
                    ],
                    [
                        291.0,
                        158.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.76298,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 11
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "f51b9bb1e727dcddd5c28f6daa6d3c1b",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        270.7
                    ],
                    [
                        462.2,
                        298.4
                    ],
                    [
                        909.1,
                        298.4
                    ],
                    [
                        909.1,
                        270.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.69535,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 11,
            "parent_id": "9d2d0305e93f2fbb51054ca491e5c5ee"
        },
        "text": "4.2. Simulations of Contrast Algorithm",
        "type": "NarrativeText"
    },
    {
        "element_id": "669aba06ff87c3c742f5736a3e82559f",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.4,
                        313.7
                    ],
                    [
                        461.4,
                        551.4
                    ],
                    [
                        1559.0,
                        551.4
                    ],
                    [
                        1559.0,
                        313.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94626,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 11,
            "parent_id": "9d2d0305e93f2fbb51054ca491e5c5ee"
        },
        "text": "To compare the effectiveness of the proposed algorithm, the APF-based path planning algorithm is adopted. Figures 11 and 12 show that APF is usable when facing static obstacles. However, when the interceptor is added, APF is no longer valid, or the parameters need to be tuned carefully. Figures 13 and 14 show that the penetrator is intercepted for its slow-change line-of-sight angle. However, the RL approach enables the intuitive setting of performance objectives, shifting the focus toward what should be achieved, rather than how, which simpli\ufb01es the design process [23].",
        "type": "NarrativeText"
    },
    {
        "element_id": "fca8e2b409b1aa36d357abde23c33c9d",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.4,
                        558.6
                    ],
                    [
                        460.4,
                        934.9
                    ],
                    [
                        1558.4,
                        934.9
                    ],
                    [
                        1558.4,
                        558.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95014,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 11,
            "parent_id": "9d2d0305e93f2fbb51054ca491e5c5ee"
        },
        "text": "Furthermore, when there is no reward compensation, Figure 15 illustrates that, although the network can still converge, the total rewards vary greatly based on the distances from the initial points to the target area. Even if the same policy is adopted, the total rewards obtained from different initial points are quite different, and it is difficult to effectively judge the convergence of the network, which increases the difficulty of training. On the other hand, when the initial point is closer to the target point, due to the high rewards, even if a suboptimal strategy is adopted, an acceptable reward can also be obtained, which makes it difficult to converge to the optimal strategy. When the reward function without compensation is used, agents only obtain the suboptimal strategy, and the selected route is not the optimal one. However, when the reward compensation is adopted, the total rewards are independent of the distances, which is more beneficial to train to find the shortest path, as shown in Figure 16.",
        "type": "NarrativeText"
    },
    {
        "element_id": "430c3677fa0f270384e653dd00c33bdc",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        415.8,
                        888.8
                    ],
                    [
                        415.8,
                        1482.5
                    ],
                    [
                        1207.5,
                        1482.5
                    ],
                    [
                        1207.5,
                        888.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-11-14.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 11
        },
        "text": "the distances, which is more beneficial to train to find the shortest EE artificial potential field motion trajectory 1000 * initial point \u00a9 target area",
        "type": "Image"
    },
    {
        "element_id": "a434889a759877be2f79753d259218d7",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.0,
                        1482.5
                    ],
                    [
                        461.0,
                        1507.8
                    ],
                    [
                        740.2,
                        1507.8
                    ],
                    [
                        740.2,
                        1482.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.60099,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 11
        },
        "text": "Figure 11. Arti\ufb01cial \ufb01eld.",
        "type": "FigureCaption"
    },
    {
        "element_id": "dec135ec1e825e0e24d7ca53b2abd209",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.4,
                        1565.5
                    ],
                    [
                        460.4,
                        2105.6
                    ],
                    [
                        1166.5,
                        2105.6
                    ],
                    [
                        1166.5,
                        1565.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.8586,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-11-15.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 11
        },
        "text": "g \u00a9 > ak ems .\u201d pi Va 2k / Sle \u00b0 ye \u00b0 Or yx initial point = = = motion trajectory (EX Itarget area 27 static obstacles -2 0 2 4 6 8 10 12 x(m)",
        "type": "Image"
    },
    {
        "element_id": "2fe9a05395f8451d6a6c12189be3ffff",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        459.2,
                        2132.9
                    ],
                    [
                        459.2,
                        2158.2
                    ],
                    [
                        877.1,
                        2158.2
                    ],
                    [
                        877.1,
                        2132.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73905,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 11
        },
        "text": "Figure 12. Motion trail based on APF.",
        "type": "FigureCaption"
    },
    {
        "element_id": "2e9dfd5743553a0be11dc5e59cb088b1",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1477.7,
                        153.6
                    ],
                    [
                        1477.7,
                        181.2
                    ],
                    [
                        1555.4,
                        181.2
                    ],
                    [
                        1555.4,
                        153.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.56945,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 11
        },
        "text": "11 of 17",
        "type": "Header"
    },
    {
        "element_id": "86517780cd0dc59b98519788eb2e6584",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.5,
                        158.5
                    ],
                    [
                        98.5,
                        181.2
                    ],
                    [
                        290.9,
                        181.2
                    ],
                    [
                        290.9,
                        158.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.71646,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 12
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "90957439d73e6be3ac6d5e51e766e13a",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        466.2,
                        275.4
                    ],
                    [
                        466.2,
                        827.5
                    ],
                    [
                        1135.3,
                        827.5
                    ],
                    [
                        1135.3,
                        275.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87922,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-12-16.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 12
        },
        "text": "127 10F cae a SI & Es \u2018| \u00a9 .\u201d: 4 \u2018 2k ra oF yx initil point = = = motion trajectory (XT earget area 25 . \u2014 static obstacles 1 1 1 1 1 1 1 -2 2 4 6 8 10 12 x(m)",
        "type": "Image"
    },
    {
        "element_id": "fa8ceab24e54a4877da86075d0356059",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        459.5,
                        851.8
                    ],
                    [
                        459.5,
                        877.1
                    ],
                    [
                        1063.4,
                        877.1
                    ],
                    [
                        1063.4,
                        851.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.78962,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 12
        },
        "text": "Figure 13. Motion trail with interceptor based on APF.",
        "type": "FigureCaption"
    },
    {
        "element_id": "74cf9f4759dc43491d8c137ec5faa290",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        617.7,
                        902.6
                    ],
                    [
                        617.7,
                        922.3
                    ],
                    [
                        1027.0,
                        922.3
                    ],
                    [
                        1027.0,
                        902.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.51084,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 12
        },
        "text": "penetrator distance between the interceptor and the",
        "type": "FigureCaption"
    },
    {
        "element_id": "ec335b8d1ceafd42b7117bbce9d6ff17",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        472.3,
                        917.8
                    ],
                    [
                        472.3,
                        1482.8
                    ],
                    [
                        1148.1,
                        1482.8
                    ],
                    [
                        1148.1,
                        917.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87175,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-12-17.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 12
        },
        "text": "T T T T T 100 line-of-sight angle and its rate with the i T T interceptor s0 60 40F 20- T line-of-sight angle | | \u2014 \u2014 = rate of change",
        "type": "Image"
    },
    {
        "element_id": "60da5e085aad62de0479f8620cc9b591",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1507.0
                    ],
                    [
                        462.2,
                        1532.4
                    ],
                    [
                        1080.5,
                        1532.4
                    ],
                    [
                        1080.5,
                        1507.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79572,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 12
        },
        "text": "Figure 14. Line-of-sight angle and its rate based on APF.",
        "type": "FigureCaption"
    },
    {
        "element_id": "b10d658d580b287f840a2141ae7f2592",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.7,
                        1563.2
                    ],
                    [
                        462.7,
                        2120.7
                    ],
                    [
                        1196.8,
                        2120.7
                    ],
                    [
                        1196.8,
                        1563.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93599,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-12-18.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 12
        },
        "text": "1100 1050 F 1000 F 950 900 k 850 7 800 k 750 > 700 \u2014#\u2014 with compensation \u20146\u2014 without compensation 1 1 1 11 11.5 12 Distance to target area(m) 12.5 13 -800 -1000 -1200 -1400 -1600 -1800 -2000",
        "type": "Image"
    },
    {
        "element_id": "3c61746e5cf0c7436cee41380a51d28c",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        2143.3
                    ],
                    [
                        462.2,
                        2168.6
                    ],
                    [
                        1097.8,
                        2168.6
                    ],
                    [
                        1097.8,
                        2143.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82465,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 12
        },
        "text": "Figure 15. Total rewards with and without compensation.",
        "type": "FigureCaption"
    },
    {
        "element_id": "acbebb2fe6bbba387ad9e7f4181a3ea7",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1477.0,
                        154.4
                    ],
                    [
                        1477.0,
                        181.2
                    ],
                    [
                        1555.2,
                        181.2
                    ],
                    [
                        1555.2,
                        154.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.67426,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 12
        },
        "text": "12 of 17",
        "type": "Header"
    },
    {
        "element_id": "2e81b4b5fc485d21a568f93ee93d38cf",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.5,
                        158.5
                    ],
                    [
                        98.5,
                        181.2
                    ],
                    [
                        291.3,
                        181.2
                    ],
                    [
                        291.3,
                        158.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.7551,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 13
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "9b5031666d42d4fe1d0d2c8be9182df4",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        472.3,
                        289.8
                    ],
                    [
                        472.3,
                        874.6
                    ],
                    [
                        1191.0,
                        874.6
                    ],
                    [
                        1191.0,
                        289.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91467,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-13-19.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 13
        },
        "text": "10 Pr si & \u201d or X initial point obstacle area target area \u2014\u2014 isil 1 without compensation \u2014 trail 1 with compensation = trail 2 without compensation = trail 2 with compensation 5 , , , , 1 1 1 1 -2 0 2 4 6 8 10 12 x(m)",
        "type": "Image"
    },
    {
        "element_id": "1711f3207e7d027be1ae954396f9e967",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.2,
                        899.4
                    ],
                    [
                        460.2,
                        925.1
                    ],
                    [
                        1088.8,
                        925.1
                    ],
                    [
                        1088.8,
                        899.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82763,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 13
        },
        "text": "Figure 16. Motion trails with and without compensation.",
        "type": "FigureCaption"
    },
    {
        "element_id": "09e75dc933746836145eee9315573fa6",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.1,
                        952.8
                    ],
                    [
                        460.1,
                        981.6
                    ],
                    [
                        808.8,
                        981.6
                    ],
                    [
                        808.8,
                        952.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.71357,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 13
        },
        "text": "4.3. Monte Carlo Experiments",
        "type": "NarrativeText"
    },
    {
        "element_id": "b1da2b2749bcc2970a3d1e300b4175bd",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.0,
                        993.9
                    ],
                    [
                        461.0,
                        1234.6
                    ],
                    [
                        1558.1,
                        1234.6
                    ],
                    [
                        1558.1,
                        993.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95223,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 13
        },
        "text": "To verify the stability and generalization of the algorithm, 100 Monte Carlo experi- ments were carried out. In all simulations, the initial point, target area, and obstacles were randomly initialized within a certain range. The results are shown in Figures 17 and 18, with a high success rate of 84%. It can be seen from the simulations that, in similar scenarios, agents are able to choose the learned optimal policy. That is, DRL converged to the optimal strategy through training. The simulation results also indicate that the method proposed has the generalization ability to a certain extent.",
        "type": "NarrativeText"
    },
    {
        "element_id": "551e8b77ef414c6539bf9891206fb973",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        454.6,
                        1241.8
                    ],
                    [
                        454.6,
                        1339.2
                    ],
                    [
                        1561.7,
                        1339.2
                    ],
                    [
                        1561.7,
                        1241.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92321,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 13
        },
        "text": "Through the analysis of failure cases, it is found that 50% of the cases are caused by a limited \ufb01eld of vision and low maneuverability, but the others are caused by wrong decision making.",
        "type": "NarrativeText"
    },
    {
        "element_id": "61d9331ff25738dde0a3582857ad4238",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.2,
                        1376.0
                    ],
                    [
                        461.2,
                        1947.5
                    ],
                    [
                        1163.5,
                        1947.5
                    ],
                    [
                        1163.5,
                        1376.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93345,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-13-20.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 13
        },
        "text": "12+ 10+ y(m) \u00a9 \u2014 initial area target area = = = intercepted trajectory = successful trajectory 0 2 4 6 8 10 12",
        "type": "Image"
    },
    {
        "element_id": "9a89ff87c62b33472b4dcee428f2e782",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.2,
                        1972.4
                    ],
                    [
                        460.2,
                        1997.7
                    ],
                    [
                        1073.3,
                        1997.7
                    ],
                    [
                        1073.3,
                        1972.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87199,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 13
        },
        "text": "Figure 17. Trajectories in the Monte Carlo experiments.",
        "type": "FigureCaption"
    },
    {
        "element_id": "889a2ecb87330269edbd29b295f91de6",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1477.1,
                        154.2
                    ],
                    [
                        1477.1,
                        181.2
                    ],
                    [
                        1555.2,
                        181.2
                    ],
                    [
                        1555.2,
                        154.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.60099,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 13
        },
        "text": "13 of 17",
        "type": "Header"
    },
    {
        "element_id": "f2ce825630bb02dd1a08118bfb21122e",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.2,
                        157.4
                    ],
                    [
                        98.2,
                        181.2
                    ],
                    [
                        291.0,
                        181.2
                    ],
                    [
                        291.0,
                        157.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.76361,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 14
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "8ec97b600d929903469d1ed389f40354",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        464.1,
                        267.6
                    ],
                    [
                        464.1,
                        867.5
                    ],
                    [
                        1200.5,
                        867.5
                    ],
                    [
                        1200.5,
                        267.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93717,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-14-21.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 14
        },
        "text": "vu distance to the target area(m) 0 5 10 15 20 25 ts)",
        "type": "Image"
    },
    {
        "element_id": "b08df48f6837a04cfb31d1b34de3aab1",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.5,
                        892.4
                    ],
                    [
                        461.5,
                        918.4
                    ],
                    [
                        963.3,
                        918.4
                    ],
                    [
                        963.3,
                        892.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73769,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 14
        },
        "text": "Figure 18. The 100 Monte Carlo experiments.",
        "type": "FigureCaption"
    },
    {
        "element_id": "e927cc6c38a2fa7fd2d6902bc35d38b9",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        457.1,
                        946.8
                    ],
                    [
                        457.1,
                        975.0
                    ],
                    [
                        1012.1,
                        975.0
                    ],
                    [
                        1012.1,
                        946.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.70201,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 14
        },
        "text": "4.4. Simulation Results in the Webots Simulator",
        "type": "NarrativeText"
    },
    {
        "element_id": "ac4fa9b9215cef928f52be12d3e5bd7f",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        455.8,
                        988.8
                    ],
                    [
                        455.8,
                        1158.2
                    ],
                    [
                        1564.2,
                        1158.2
                    ],
                    [
                        1564.2,
                        988.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94557,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 14
        },
        "text": "Unlike the mathematical model created in Matlab, which is simpli\ufb01ed to a second- order system, robots are more complex in the physical world. Webots is an open-source and multi-platform desktop application used to simulate robots. It provides a complete development environment to model, program and simulate robots. Hence, the Webots simulator is employed to verify the reliability of the algorithm proposed.",
        "type": "NarrativeText"
    },
    {
        "element_id": "5f0a2aba42abe9f197c4488c0ba9cc79",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.0,
                        1165.4
                    ],
                    [
                        461.0,
                        1367.4
                    ],
                    [
                        1562.1,
                        1367.4
                    ],
                    [
                        1562.1,
                        1165.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94473,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 14
        },
        "text": "The environment and the robots are modeled as Figure A1a illustrates. In Webots, a one-layer LiDAR with a range of up to 3.5 m and a \ufb01eld of view up to 360 degrees is used to sense the surrounding environment. Its standard deviation of the Gaussian depth noise is 0.0043 m. At the same time, motor models are also added to simulate robots in the real world. The detection results in different stages are shown in Figure A1a\u2013d, and the motion trails of the penetrator and the interceptor are shown in Figure 19.",
        "type": "NarrativeText"
    },
    {
        "element_id": "8e456677dafe9cbab3381cb14212dd43",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        473.9,
                        1408.0
                    ],
                    [
                        473.9,
                        2007.2
                    ],
                    [
                        1213.5,
                        2007.2
                    ],
                    [
                        1213.5,
                        1408.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92039,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-14-22.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 14
        },
        "text": "2k 10 fp gk => ch E a al ak se \u0130di sx initial point = = = motion trajectory ok target area \u2014 interceptor trajectory static obstacle | 27 static obstacle 2 , , , , , i i i -2 0 2 4 6 8 10 12 x(m)",
        "type": "Image"
    },
    {
        "element_id": "e78105c7b67a2186f59f0d7703ad95c1",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.9,
                        2032.7
                    ],
                    [
                        461.9,
                        2058.0
                    ],
                    [
                        901.2,
                        2058.0
                    ],
                    [
                        901.2,
                        2032.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.77548,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 14
        },
        "text": "Figure 19. Simulation results in Webots.",
        "type": "FigureCaption"
    },
    {
        "element_id": "af8da4b148d667ba7d1230ea1b7f0c98",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1478.0,
                        154.5
                    ],
                    [
                        1478.0,
                        181.2
                    ],
                    [
                        1554.3,
                        181.2
                    ],
                    [
                        1554.3,
                        154.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.59268,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 14
        },
        "text": "14 of 17",
        "type": "NarrativeText"
    },
    {
        "element_id": "8c279ae816dfcf913f2151a0937513d9",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.3,
                        158.0
                    ],
                    [
                        98.3,
                        181.2
                    ],
                    [
                        291.1,
                        181.2
                    ],
                    [
                        291.1,
                        158.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74376,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "7545f971ab02f3c08fb432677009e5e1",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.2,
                        267.5
                    ],
                    [
                        461.2,
                        368.7
                    ],
                    [
                        1562.1,
                        368.7
                    ],
                    [
                        1562.1,
                        267.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92693,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "8c279ae816dfcf913f2151a0937513d9"
        },
        "text": "It can be seen from the results above that the penetration algorithm proposed in this paper not only has a good performance in mathematical models, but also has feasibility in the Webots simulator.",
        "type": "NarrativeText"
    },
    {
        "element_id": "2dea0d5786ddac86aa04b6a5a03e08ba",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        402.9
                    ],
                    [
                        462.2,
                        430.5
                    ],
                    [
                        649.4,
                        430.5
                    ],
                    [
                        649.4,
                        402.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.85333,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "8c279ae816dfcf913f2151a0937513d9"
        },
        "text": "5. Conclusions",
        "type": "Title"
    },
    {
        "element_id": "aa63c581507681994ae0e4a3953bb3a7",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        443.6
                    ],
                    [
                        462.2,
                        892.6
                    ],
                    [
                        1563.7,
                        892.6
                    ],
                    [
                        1563.7,
                        443.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94977,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "2dea0d5786ddac86aa04b6a5a03e08ba"
        },
        "text": "In order to solve the problem that traditional methods-based robots cannot effectively break through the interception in a rejection environment, this paper proposes the DRL- based interception strategy. Aiming at addressing the issues of poor convergence of DRL, an incremental training method is proposed. The task is divided into three sub-tasks, and the agent is trained to gradually learn to survive, reach the target area, and break through the interception. Meanwhile, in order to reduce the dif\ufb01culty of training and improve the training effect, reward compensation is adopted. The simulation results show that the introduction of reward compensation can unify the total return, which is bene\ufb01cial for the agent to converge to the optimal policy. The simulation results in Webots also demonstrate the feasibility of the proposed algorithm in practical applications. In contrast, APF-based agents can only bypass static obstacles, but cannot break through the interception of interceptors. Navigation in the 3D environment is challenging, and we intend to re\ufb01ne this approach to make it applicable in our future work.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c2df92fbecadce079f9fe6669d6cc8e1",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.2,
                        930.1
                    ],
                    [
                        461.2,
                        1087.7
                    ],
                    [
                        1564.7,
                        1087.7
                    ],
                    [
                        1564.7,
                        930.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94129,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "2dea0d5786ddac86aa04b6a5a03e08ba"
        },
        "text": "Author Contributions: Conceptualization, J.S. and K.Z.; methodology, K.Z. and Y.L. (Yuxie Luo); soft- ware, K.Z.; validation, K.Z., Y.L. (Yuxie Luo), and Y.L. (Yang Liu); formal analysis, J.S.; investigation, K.Z.; resources, K.Z. and Y.L. (Yang Liu); data curation, J.S.; writing\u2014original draft preparation, K.Z.; writing\u2014review and editing, K.Z.; visualization, K.Z.; supervision, J.S.; project administration, J.S.; funding acquisition, J.S. All authors have read and agreed to the published version of the manuscript.",
        "type": "NarrativeText"
    },
    {
        "element_id": "0795619ffae6bca14d7279b9b585ba1f",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1111.6
                    ],
                    [
                        462.2,
                        1169.4
                    ],
                    [
                        1559.9,
                        1169.4
                    ],
                    [
                        1559.9,
                        1111.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92082,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "2dea0d5786ddac86aa04b6a5a03e08ba"
        },
        "text": "Funding: This work was supported by the National Natural Science Foundation of China under Grants 62073020, 91646108 and 61473015.",
        "type": "NarrativeText"
    },
    {
        "element_id": "67d540c9d3fe7d5d47af7be7e682eed6",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1193.3
                    ],
                    [
                        462.2,
                        1218.6
                    ],
                    [
                        1076.9,
                        1218.6
                    ],
                    [
                        1076.9,
                        1193.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72476,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "2dea0d5786ddac86aa04b6a5a03e08ba"
        },
        "text": "Institutional Review Board Statement: Not applicable.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9c5d33fd2e98da93981dcc6eb0b77630",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.4,
                        1242.4
                    ],
                    [
                        461.4,
                        1267.7
                    ],
                    [
                        974.8,
                        1267.7
                    ],
                    [
                        974.8,
                        1242.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87492,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "2dea0d5786ddac86aa04b6a5a03e08ba"
        },
        "text": "Informed Consent Statement: Not applicable.",
        "type": "NarrativeText"
    },
    {
        "element_id": "76188a3c316361b0d039576ed1beafe6",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1291.6
                    ],
                    [
                        462.2,
                        1316.9
                    ],
                    [
                        964.9,
                        1316.9
                    ],
                    [
                        964.9,
                        1291.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73256,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "8c279ae816dfcf913f2151a0937513d9"
        },
        "text": "Data Availability Statement: Not applicable.",
        "type": "Title"
    },
    {
        "element_id": "e5e11bd5097479f76f962c34273adc09",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        457.7,
                        1339.1
                    ],
                    [
                        457.7,
                        1431.1
                    ],
                    [
                        1564.6,
                        1431.1
                    ],
                    [
                        1564.6,
                        1339.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92669,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "76188a3c316361b0d039576ed1beafe6"
        },
        "text": "Acknowledgments: The authors thank the colleagues for their constructive suggestions and research assistance throughout this study. The authors also appreciate the associate editor and the reviewers for their valuable comments and suggestions.",
        "type": "NarrativeText"
    },
    {
        "element_id": "b95316e531ab28c34b37c60b4857a82f",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.1,
                        1454.0
                    ],
                    [
                        462.1,
                        1545.4
                    ],
                    [
                        1570.2,
                        1545.4
                    ],
                    [
                        1570.2,
                        1454.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9324,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "76188a3c316361b0d039576ed1beafe6"
        },
        "text": "Con\ufb02icts of Interest: The authors declare no con\ufb02ict of interest. The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript; or in the decision to publish the results.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a3ccb17c0bf298844edebfd14c1bb581",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        461.1,
                        1586.1
                    ],
                    [
                        461.1,
                        1613.8
                    ],
                    [
                        642.5,
                        1613.8
                    ],
                    [
                        642.5,
                        1586.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84542,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "8c279ae816dfcf913f2151a0937513d9"
        },
        "text": "Abbreviations",
        "type": "Title"
    },
    {
        "element_id": "a677e0379e34fc38982dcb95af3691cb",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        457.1,
                        1629.4
                    ],
                    [
                        457.1,
                        1654.3
                    ],
                    [
                        1086.6,
                        1654.3
                    ],
                    [
                        1086.6,
                        1629.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.86502,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "a3ccb17c0bf298844edebfd14c1bb581"
        },
        "text": "The following abbreviations are used in this manuscript:",
        "type": "NarrativeText"
    },
    {
        "element_id": "d134f87dcbfba80403fd4cc64109e9e3",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        459.5,
                        1686.4
                    ],
                    [
                        459.5,
                        1712.4
                    ],
                    [
                        842.6,
                        1712.4
                    ],
                    [
                        842.6,
                        1686.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.76712,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "a3ccb17c0bf298844edebfd14c1bb581"
        },
        "text": "RL Reinforcement Learning",
        "type": "ListItem"
    },
    {
        "element_id": "dac1218fcda828483ea4a3a43efdae7d",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        459.0,
                        1720.0
                    ],
                    [
                        459.0,
                        1744.9
                    ],
                    [
                        923.5,
                        1744.9
                    ],
                    [
                        923.5,
                        1720.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79434,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "a3ccb17c0bf298844edebfd14c1bb581"
        },
        "text": "DRL Deep Reinforcement Learning",
        "type": "ListItem"
    },
    {
        "element_id": "69d5443589f5a2740b100d0f3ca2ede5",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1752.6
                    ],
                    [
                        462.2,
                        1777.5
                    ],
                    [
                        962.0,
                        1777.5
                    ],
                    [
                        962.0,
                        1752.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.78485,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "a3ccb17c0bf298844edebfd14c1bb581"
        },
        "text": "DDPG Deep Deterministic Policy Gradient",
        "type": "ListItem"
    },
    {
        "element_id": "ccd85ca1aa832d53f596a5791439fd9f",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        455.0,
                        1785.1
                    ],
                    [
                        455.0,
                        1810.0
                    ],
                    [
                        860.0,
                        1810.0
                    ],
                    [
                        860.0,
                        1785.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72793,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "a3ccb17c0bf298844edebfd14c1bb581"
        },
        "text": "UAV Unmanned Aerial Vehicle",
        "type": "ListItem"
    },
    {
        "element_id": "9f6f961be46fc5bc040b093ccf50636a",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1817.6
                    ],
                    [
                        462.2,
                        1842.6
                    ],
                    [
                        856.6,
                        1842.6
                    ],
                    [
                        856.6,
                        1817.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.76135,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "a3ccb17c0bf298844edebfd14c1bb581"
        },
        "text": "LSTM Long Short-Term Memory",
        "type": "ListItem"
    },
    {
        "element_id": "ce8fd5c9d9566e4366a5fbd416805d90",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        462.2,
                        1850.2
                    ],
                    [
                        462.2,
                        1875.1
                    ],
                    [
                        845.4,
                        1875.1
                    ],
                    [
                        845.4,
                        1850.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.63251,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "a3ccb17c0bf298844edebfd14c1bb581"
        },
        "text": "MDP Markov Decision Process",
        "type": "ListItem"
    },
    {
        "element_id": "845e54d52fe86a6c92a827baf4a02223",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        451.2,
                        1881.6
                    ],
                    [
                        451.2,
                        1907.6
                    ],
                    [
                        778.5,
                        1907.6
                    ],
                    [
                        778.5,
                        1881.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.67766,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "a3ccb17c0bf298844edebfd14c1bb581"
        },
        "text": "DQN Deep Q Network",
        "type": "ListItem"
    },
    {
        "element_id": "bd4d512418f5098885f0588c1d4527fd",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.1,
                        1912.9
                    ],
                    [
                        460.1,
                        1940.2
                    ],
                    [
                        836.7,
                        1940.2
                    ],
                    [
                        836.7,
                        1912.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72047,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15,
            "parent_id": "a3ccb17c0bf298844edebfd14c1bb581"
        },
        "text": "APF Arti\ufb01cial Potential Field",
        "type": "ListItem"
    },
    {
        "element_id": "37d65024d13a0b0c05be53674983d6f0",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1478.0,
                        153.2
                    ],
                    [
                        1478.0,
                        181.2
                    ],
                    [
                        1555.2,
                        181.2
                    ],
                    [
                        1555.2,
                        153.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.61648,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 15
        },
        "text": "15 of 17",
        "type": "Header"
    },
    {
        "element_id": "9f99c0531ab80dd02ea9902e62d2ca61",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        97.6,
                        156.9
                    ],
                    [
                        97.6,
                        181.2
                    ],
                    [
                        291.1,
                        181.2
                    ],
                    [
                        291.1,
                        156.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.7558,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "Robotics 2022, 11, 35",
        "type": "Header"
    },
    {
        "element_id": "e0997953339ea8a5ed700e9dc1ff8cd1",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        460.6,
                        270.9
                    ],
                    [
                        460.6,
                        298.5
                    ],
                    [
                        1008.7,
                        298.5
                    ],
                    [
                        1008.7,
                        270.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.51855,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16,
            "parent_id": "9f99c0531ab80dd02ea9902e62d2ca61"
        },
        "text": "Appendix A. Simulation Results in Webots",
        "type": "FigureCaption"
    },
    {
        "element_id": "bf063698b2ffadb01c7f9e4f80337ddf",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        491.4,
                        345.9
                    ],
                    [
                        491.4,
                        708.6
                    ],
                    [
                        963.8,
                        708.6
                    ],
                    [
                        963.8,
                        345.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-16-23.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "fa8645fb704691c5a7ab28733ce6784b",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1056.9,
                        374.9
                    ],
                    [
                        1056.9,
                        713.6
                    ],
                    [
                        1457.5,
                        713.6
                    ],
                    [
                        1457.5,
                        374.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.77374,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-16-24.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "\u2018 1 f E fo | Bo b a \u00b0 | 1 o / / 2 o oY 4 \u201cs 4 3 2 4 o 1 2 3 4 5 xin)",
        "type": "Image"
    },
    {
        "element_id": "84fec570ba15718464a42c01b56314e7",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        975.5,
                        725.5
                    ],
                    [
                        975.5,
                        748.0
                    ],
                    [
                        1001.3,
                        748.0
                    ],
                    [
                        1001.3,
                        725.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "(a)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "fa435879681e8d53e4fa3954aca6c225",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        491.4,
                        776.9
                    ],
                    [
                        491.4,
                        1139.6
                    ],
                    [
                        963.8,
                        1139.6
                    ],
                    [
                        963.8,
                        776.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-16-25.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "8ccde6e1e2da02e89db24b3024f82d4a",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1054.0,
                        802.2
                    ],
                    [
                        1054.0,
                        1140.1
                    ],
                    [
                        1462.8,
                        1140.1
                    ],
                    [
                        1462.8,
                        802.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73386,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-16-26.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "5 \u2018 1 / Gi / | Zo \\ oO. } 1 \\ / \\ / a 4 4 \u201cs 4 3 1 o 1 3 4 5 xin)",
        "type": "Image"
    },
    {
        "element_id": "46d7669d61272484abecb29dd179279c",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        974.3,
                        1156.5
                    ],
                    [
                        974.3,
                        1179.0
                    ],
                    [
                        1002.5,
                        1179.0
                    ],
                    [
                        1002.5,
                        1156.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "(b)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "2d63c7c7d85a65ef2c87e301c3ef8490",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        491.4,
                        1207.8
                    ],
                    [
                        491.4,
                        1570.5
                    ],
                    [
                        963.8,
                        1570.5
                    ],
                    [
                        963.8,
                        1207.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-16-27.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "ded72293b3215b2c4c8ef375bdea7966",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1053.3,
                        1235.8
                    ],
                    [
                        1053.3,
                        1571.1
                    ],
                    [
                        1460.1,
                        1571.1
                    ],
                    [
                        1460.1,
                        1235.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.54963,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-16-28.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "5 \u2018 3 a o 2 ya o 1 / Gi / | ze \\ O j \\ o , \\ 4 \u201cs 4 3 2 4 o 1 2 3 4 5 xin)",
        "type": "Image"
    },
    {
        "element_id": "ff79c400bc19a51724685988562e2ac1",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        976.1,
                        1587.5
                    ],
                    [
                        976.1,
                        1610.0
                    ],
                    [
                        1000.7,
                        1610.0
                    ],
                    [
                        1000.7,
                        1587.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "(c)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "4a82039ceaf0c181979744c307dfcecc",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        491.4,
                        1638.8
                    ],
                    [
                        491.4,
                        2001.5
                    ],
                    [
                        963.8,
                        2001.5
                    ],
                    [
                        963.8,
                        1638.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-16-29.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "9678be0523192d374d855303f3587013",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1057.4,
                        1662.2
                    ],
                    [
                        1057.4,
                        2014.1
                    ],
                    [
                        1465.2,
                        2014.1
                    ],
                    [
                        1465.2,
                        1662.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.27417,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-16-30.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "5 \u2018 Ni fo 1 / Gi | | zh 6 a | 1 Ve 4 \u201cs 4 3 1 o 1 3 4 5",
        "type": "Image"
    },
    {
        "element_id": "b9890cf9a6ce2c73b36770f3f188ddb8",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        974.3,
                        2018.4
                    ],
                    [
                        974.3,
                        2040.9
                    ],
                    [
                        1002.5,
                        2040.9
                    ],
                    [
                        1002.5,
                        2018.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "(d)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "177650ab354aeecc9cc62cf4477a09f7",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        453.8,
                        2076.4
                    ],
                    [
                        453.8,
                        2137.3
                    ],
                    [
                        1556.7,
                        2137.3
                    ],
                    [
                        1556.7,
                        2076.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91246,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "Figure A1. Results in different stages in Webots. (a) The initial stage; (b) avoid the static obstacles; (c) break the interception; (d) reach the target area.",
        "type": "FigureCaption"
    },
    {
        "element_id": "24f05f49b947170b70886dcdc796b8d1",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1478.7,
                        155.1
                    ],
                    [
                        1478.7,
                        181.2
                    ],
                    [
                        1555.1,
                        181.2
                    ],
                    [
                        1555.1,
                        155.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.53917,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 16
        },
        "text": "16 of 17",
        "type": "Header"
    },
    {
        "element_id": "1f3bff2bd542acfb5026e142b6cb913f",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        98.5,
                        155.0
                    ],
                    [
                        98.5,
                        181.2
                    ],
                    [
                        291.0,
                        181.2
                    ],
                    [
                        291.0,
                        155.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.66475,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "24f05f49b947170b70886dcdc796b8d1"
        },
        "text": "Robotics 2022, 11, 35",
        "type": "NarrativeText"
    },
    {
        "element_id": "2a9197df9de53015af637c2561d1757d",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        269.4
                    ],
                    [
                        99.2,
                        298.5
                    ],
                    [
                        239.7,
                        298.5
                    ],
                    [
                        239.7,
                        269.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80624,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "24f05f49b947170b70886dcdc796b8d1"
        },
        "text": "References",
        "type": "Title"
    },
    {
        "element_id": "0c626f6b5f8b2f07ad224c5b9d759004",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        115.3,
                        310.6
                    ],
                    [
                        115.3,
                        402.4
                    ],
                    [
                        1556.7,
                        402.4
                    ],
                    [
                        1556.7,
                        310.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92433,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "Zhang, H.; Huang, C.; Zhang, Z.; Wang, X.; Han, B.; Wei, Z.; Li, Y.; Wang, L.; Zhu, W. The Trajectory Generation of UCAV Evading Missiles Based on Neural Networks. In Journal of Physics: Conference Series; IOP Publishing: Bristol, UK, 2020; Volume 1486, p. 022025.",
        "type": "ListItem"
    },
    {
        "element_id": "4089b24e2423e0096b63fd7321684d29",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        313.6
                    ],
                    [
                        99.2,
                        338.5
                    ],
                    [
                        117.9,
                        338.5
                    ],
                    [
                        117.9,
                        313.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "1.",
        "type": "UncategorizedText"
    },
    {
        "element_id": "0cf1ee89cb13df0f4353adeb8e11f051",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        115.4,
                        405.8
                    ],
                    [
                        115.4,
                        466.3
                    ],
                    [
                        1558.4,
                        466.3
                    ],
                    [
                        1558.4,
                        405.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.7823,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "Yang, C.; Wu, J.; Liu, G.; Zhang, Y. Ballistic Missile Maneuver Penetration Based on Reinforcement Learning. In Proceedings of the 2018 IEEE CSAA Guidance, Navigation and Control Conference (CGNCC), Xiamen, China, 10\u201312 August 2018; pp. 1\u20135.",
        "type": "ListItem"
    },
    {
        "element_id": "93fcbe5e8a54a0fc327c8fea6dc4d4b5",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        409.4
                    ],
                    [
                        99.2,
                        434.4
                    ],
                    [
                        117.9,
                        434.4
                    ],
                    [
                        117.9,
                        409.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "2.",
        "type": "UncategorizedText"
    },
    {
        "element_id": "2597a347f7a5106de800e7638425c8c3",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        110.7,
                        470.0
                    ],
                    [
                        110.7,
                        530.2
                    ],
                    [
                        1557.9,
                        530.2
                    ],
                    [
                        1557.9,
                        470.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.76835,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "Yan, T.; Cai, Y.; Bin, X. Evasion guidance algorithms for air-breathing hypersonic vehicles in three-player pursuit-evasion games. Chin. J. Aeronaut. 2020, 33, 3423\u20133436. [CrossRef]",
        "type": "ListItem"
    },
    {
        "element_id": "e0a7c9c35014a38895cdaadf0c7c1a6d",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        473.4
                    ],
                    [
                        99.2,
                        498.3
                    ],
                    [
                        117.9,
                        498.3
                    ],
                    [
                        117.9,
                        473.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "3.",
        "type": "UncategorizedText"
    },
    {
        "element_id": "4d89d476e81441b5f3804e99bb39ee56",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        535.2
                    ],
                    [
                        99.2,
                        594.2
                    ],
                    [
                        1553.5,
                        594.2
                    ],
                    [
                        1553.5,
                        535.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.86437,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "4. Nguyen, H.; La, H. Review of deep reinforcement learning for robot manipulation. In Proceedings of the 2019 Third IEEE International Conference on Robotic Computing (IRC), Naples, Italy, 25\u201327 February 2019; pp. 590\u2013595.",
        "type": "ListItem"
    },
    {
        "element_id": "bde4b4f6e8125140afa094616fcfee10",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        112.3,
                        596.9
                    ],
                    [
                        112.3,
                        627.0
                    ],
                    [
                        1036.5,
                        627.0
                    ],
                    [
                        1036.5,
                        596.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82563,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "Li, Y. Deep reinforcement learning: An overview. arXiv 2017, arXiv:1701.07274.",
        "type": "ListItem"
    },
    {
        "element_id": "49798acca0e21cfe423e61899517a913",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        601.2
                    ],
                    [
                        99.2,
                        626.1
                    ],
                    [
                        117.9,
                        626.1
                    ],
                    [
                        117.9,
                        601.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "5.",
        "type": "UncategorizedText"
    },
    {
        "element_id": "60d585afeb37b338999115e713a325a9",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        633.2
                    ],
                    [
                        99.2,
                        658.1
                    ],
                    [
                        117.9,
                        658.1
                    ],
                    [
                        117.9,
                        633.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "6.",
        "type": "UncategorizedText"
    },
    {
        "element_id": "ee3f3a927435255c4ff024d563267361",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        116.7,
                        630.3
                    ],
                    [
                        116.7,
                        690.1
                    ],
                    [
                        1554.3,
                        690.1
                    ],
                    [
                        1554.3,
                        630.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90119,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "Bu\u00b8soniu, L.; de Bruin, T.; Toli\u00b4c, D.; Kober, J.; Palunko, I. Reinforcement learning for control: Performance, stability, and deep approximators. Annu. Rev. Control. 2018, 46, 8\u201328. [CrossRef]",
        "type": "ListItem"
    },
    {
        "element_id": "6464ba8cc1f46e5dbab477ec4878c8c8",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        104.9,
                        693.5
                    ],
                    [
                        104.9,
                        722.0
                    ],
                    [
                        1515.9,
                        722.0
                    ],
                    [
                        1515.9,
                        693.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80136,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "Dulac-Arnold, G.; Mankowitz, D.; Hester, T. Challenges of real-world reinforcement learning. arXiv 2019, arXiv:1904.12901.",
        "type": "ListItem"
    },
    {
        "element_id": "270d0f74d8179ee79fb4db788e8ba12f",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        697.1
                    ],
                    [
                        99.2,
                        722.0
                    ],
                    [
                        117.9,
                        722.0
                    ],
                    [
                        117.9,
                        697.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "7.",
        "type": "UncategorizedText"
    },
    {
        "element_id": "3b4e275e951e0ec786d2012d8a565841",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        113.9,
                        724.3
                    ],
                    [
                        113.9,
                        786.0
                    ],
                    [
                        1554.3,
                        786.0
                    ],
                    [
                        1554.3,
                        724.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88682,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "Lillicrap, T.P.; Hunt, J.J.; Pritzel, A.; Heess, N.; Erez, T.; Tassa, Y.; Silver, D.; Wierstra, D. Continuous control with deep reinforcement learning. arXiv 2015, arXiv:1509.02971.",
        "type": "ListItem"
    },
    {
        "element_id": "60861f4b593b68e51eb01fb7e8f79875",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        729.1
                    ],
                    [
                        99.2,
                        754.0
                    ],
                    [
                        117.9,
                        754.0
                    ],
                    [
                        117.9,
                        729.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "8.",
        "type": "UncategorizedText"
    },
    {
        "element_id": "424097a2a89a882d40a2135fb9afde70",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        793.0
                    ],
                    [
                        99.2,
                        817.9
                    ],
                    [
                        117.9,
                        817.9
                    ],
                    [
                        117.9,
                        793.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "9.",
        "type": "UncategorizedText"
    },
    {
        "element_id": "6869dbe1a265bc9cec40a9b4678c4d11",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        116.9,
                        789.1
                    ],
                    [
                        116.9,
                        849.9
                    ],
                    [
                        1555.1,
                        849.9
                    ],
                    [
                        1555.1,
                        789.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89314,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "Zhang, C.; Song, W.; Cao, Z.; Zhang, J.; Tan, P.S.; Xu, C. Learning to dispatch for job shop scheduling via deep reinforcement learning. arXiv 2020, arXiv:2010.12367.",
        "type": "ListItem"
    },
    {
        "element_id": "e7f18434b3e34a5d59329784be79c06a",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        856.4
                    ],
                    [
                        99.2,
                        945.8
                    ],
                    [
                        1556.7,
                        945.8
                    ],
                    [
                        1556.7,
                        856.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88096,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "10. Kober, J.; Bagnell, J.A.; Peters, J. Reinforcement learning in robotics: A survey. Int. J. Robot. Res. 2013, 32, 1238\u20131274. [CrossRef] 11. Lei, X.; Zhang, Z.; Dong, P. Dynamic path planning of unknown environment based on deep reinforcement learning. J. Robot. 2018, 2018, 5781591. [CrossRef]",
        "type": "ListItem"
    },
    {
        "element_id": "933056aa69129c1e90602e972468ce52",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        947.9
                    ],
                    [
                        99.2,
                        1009.7
                    ],
                    [
                        1557.9,
                        1009.7
                    ],
                    [
                        1557.9,
                        947.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90143,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "12. Zhao, W.; Liu, H.; Lewis, F.L. Robust formation control for cooperative underactuated quadrotors via reinforcement learning. IEEE Trans. Neural Netw. Learn. Syst. 2020, 32, 4577\u20134587. [CrossRef] [PubMed]",
        "type": "ListItem"
    },
    {
        "element_id": "a41c6032f43ae6faf6e99f087fc6b1c7",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        1011.8
                    ],
                    [
                        99.2,
                        1073.6
                    ],
                    [
                        1557.9,
                        1073.6
                    ],
                    [
                        1557.9,
                        1011.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.8922,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "13. Gao, J.; Ye, W.; Guo, J.; Li, Z. Deep reinforcement learning for indoor mobile robot path planning. Sensors 2020, 20, 5493. [CrossRef] [PubMed]",
        "type": "ListItem"
    },
    {
        "element_id": "12aa5baa7c46b1806a5a6ea6cc7d6564",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        1077.4
                    ],
                    [
                        99.2,
                        1169.5
                    ],
                    [
                        1556.7,
                        1169.5
                    ],
                    [
                        1556.7,
                        1077.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9157,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "14. Choi, J.; Park, K.; Kim, M.; Seok, S. Deep reinforcement learning of navigation in a complex and crowded environment with a limited \ufb01eld of view. In Proceedings of the 2019 International Conference on Robotics and Automation (ICRA), Montreal, QC, Canada, 20\u201324 May 2019; pp. 5993\u20136000.",
        "type": "ListItem"
    },
    {
        "element_id": "c31addeaa04a578fd9ccaf59f13835d5",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        115.3,
                        1171.8
                    ],
                    [
                        115.3,
                        1265.4
                    ],
                    [
                        1554.5,
                        1265.4
                    ],
                    [
                        1554.5,
                        1171.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9254,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "Faust, A.; Oslund, K.; Ramirez, O.; Francis, A.; Tapia, L.; Fiser, M.; Davidson, J. Prm-rl: Long-range robotic navigation tasks by combining reinforcement learning and sampling-based planning. In Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, Australia, 21\u201325 May 2018; pp. 5113\u20135120.",
        "type": "ListItem"
    },
    {
        "element_id": "8235a414a1724d96c465320edfb47c15",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        1176.6
                    ],
                    [
                        99.2,
                        1201.5
                    ],
                    [
                        130.3,
                        1201.5
                    ],
                    [
                        130.3,
                        1176.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "15.",
        "type": "UncategorizedText"
    },
    {
        "element_id": "f9027ca08956904f3ae18a0c30da60a7",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        113.7,
                        1267.4
                    ],
                    [
                        113.7,
                        1329.3
                    ],
                    [
                        1557.9,
                        1329.3
                    ],
                    [
                        1557.9,
                        1267.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89287,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "Feng, S.; Sebastian, B.; Ben-Tzvi, P. A Collision Avoidance Method Based on Deep Reinforcement Learning. Robotics 2021, 10, 73. [CrossRef]",
        "type": "ListItem"
    },
    {
        "element_id": "c49074136dd5ef16d23d86d0754396bf",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        1272.5
                    ],
                    [
                        99.2,
                        1297.4
                    ],
                    [
                        130.3,
                        1297.4
                    ],
                    [
                        130.3,
                        1272.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "16.",
        "type": "UncategorizedText"
    },
    {
        "element_id": "98bbd6b6fae71d27aa14c2314274ba2f",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        1332.8
                    ],
                    [
                        99.2,
                        1393.3
                    ],
                    [
                        1553.5,
                        1393.3
                    ],
                    [
                        1553.5,
                        1332.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89316,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "17. Dai, P.; Yu, W.; Wen, G.; Baldi, S. Distributed reinforcement learning algorithm for dynamic economic dispatch with unknown generation cost functions. IEEE Trans. Ind. Inform. 2019, 16, 2258\u20132267. [CrossRef]",
        "type": "ListItem"
    },
    {
        "element_id": "1f1bd07fdbed3beb13ee3d2ad208f8f5",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        1397.2
                    ],
                    [
                        99.2,
                        1457.2
                    ],
                    [
                        1554.4,
                        1457.2
                    ],
                    [
                        1554.4,
                        1397.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89583,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "18. Wang, B.; Liu, Z.; Li, Q.; Prorok, A. Mobile robot path planning in dynamic environments through globally guided reinforcement learning. IEEE Robot. Autom. Lett. 2020, 5, 6932\u20136939. [CrossRef]",
        "type": "ListItem"
    },
    {
        "element_id": "6284df7a9963a36442c0b91bffc321d6",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        1460.4
                    ],
                    [
                        99.2,
                        1521.1
                    ],
                    [
                        1554.3,
                        1521.1
                    ],
                    [
                        1554.3,
                        1460.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90454,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "19. Busoniu, L.; Babuska, R.; De Schutter, B. A comprehensive survey of multiagent reinforcement learning. IEEE Trans. Syst. Man Cybern. Part C (Appl. Rev.) 2008, 38, 156\u2013172. [CrossRef]",
        "type": "ListItem"
    },
    {
        "element_id": "7adcc6f7c58006349987d884d706a45e",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        1524.5
                    ],
                    [
                        99.2,
                        1585.0
                    ],
                    [
                        1558.1,
                        1585.0
                    ],
                    [
                        1558.1,
                        1524.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90865,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "20. De Witt, C.S.; Peng, B.; Kamienny, P.A.; Torr, P.H.; B\u00f6hmer, W.; Whiteson, S. Deep multi-agent reinforcement learning for decentralized continuous cooperative control. arXiv 2020, arXiv:2003.06709.",
        "type": "ListItem"
    },
    {
        "element_id": "249c08f655f008aeba656ab154c0bbb5",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        115.8,
                        1586.8
                    ],
                    [
                        115.8,
                        1649.0
                    ],
                    [
                        1554.9,
                        1649.0
                    ],
                    [
                        1554.9,
                        1586.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90438,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "Silver, D.; Lever, G.; Heess, N.; Degris, T.; Wierstra, D.; Riedmiller, M. Deterministic policy gradient algorithms. In Proceedings of the 31st International Conference on Machine Learning, Beijing, China, 21\u201326 June 2014; pp. 387\u2013395.",
        "type": "ListItem"
    },
    {
        "element_id": "0023a2157d47b0c02184df0bddb42698",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        1592.1
                    ],
                    [
                        99.2,
                        1617.0
                    ],
                    [
                        130.3,
                        1617.0
                    ],
                    [
                        130.3,
                        1592.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "21.",
        "type": "UncategorizedText"
    },
    {
        "element_id": "d9c7a65b0d11c66523a76b500540ca04",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        1651.8
                    ],
                    [
                        99.2,
                        1712.9
                    ],
                    [
                        1554.4,
                        1712.9
                    ],
                    [
                        1554.4,
                        1651.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89688,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "22. Kumar, P.B.; Rawat, H.; Parhi, D.R. Path planning of humanoids based on arti\ufb01cial potential \ufb01eld method in unknown environments. Expert Syst. 2019, 36, e12360. [CrossRef]",
        "type": "ListItem"
    },
    {
        "element_id": "31203529cd70847fabc469d72db89ad9",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        99.2,
                        1716.2
                    ],
                    [
                        99.2,
                        1808.8
                    ],
                    [
                        1556.6,
                        1808.8
                    ],
                    [
                        1556.6,
                        1716.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92407,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17,
            "parent_id": "2a9197df9de53015af637c2561d1757d"
        },
        "text": "23. Degrave, J.; Felici, F.; Buchli, J.; Neunert, M.; Tracey, B.; Carpanese, F.; Ewalds, T.; Hafner, R.; Abdolmaleki, A.; de Las Casas, D.; et al. Magnetic control of tokamak plasmas through deep reinforcement learning. Nature 2022, 602, 414\u2013419. [CrossRef] [PubMed]",
        "type": "ListItem"
    },
    {
        "element_id": "e1219f57f354ac503658dfdb7e2fedf8",
        "metadata": {
            "coordinates": {
                "layout_height": 2339,
                "layout_width": 1654,
                "points": [
                    [
                        1476.5,
                        153.8
                    ],
                    [
                        1476.5,
                        181.2
                    ],
                    [
                        1555.6,
                        181.2
                    ],
                    [
                        1555.6,
                        153.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.70085,
            "file_directory": "./uol-docs",
            "filename": "robotics-11-00035.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T22:58:10",
            "page_number": 17
        },
        "text": "17 of 17",
        "type": "Header"
    }
]