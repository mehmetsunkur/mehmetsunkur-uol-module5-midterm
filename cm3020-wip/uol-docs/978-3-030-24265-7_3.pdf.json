[
    {
        "element_id": "e712a4f1de044c84eaf78907fd5201b4",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        278.6,
                        153.3
                    ],
                    [
                        278.6,
                        301.2
                    ],
                    [
                        977.1,
                        301.2
                    ],
                    [
                        977.1,
                        153.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.64186,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 1
        },
        "text": "On Human-Like Performance Arti\ufb01cial Intelligence \u2013 A Demonstration Using an Atari Game",
        "type": "Title"
    },
    {
        "element_id": "fa27761d888e8b01ee7fa15dde6797bb",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        352.2,
                        359.0
                    ],
                    [
                        352.2,
                        429.8
                    ],
                    [
                        907.4,
                        429.8
                    ],
                    [
                        907.4,
                        359.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.7412,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 1,
            "parent_id": "e712a4f1de044c84eaf78907fd5201b4"
        },
        "text": "Seng-Beng Ho(&), Xiwen Yang, Therese Quieta, Gangeshwar Krishnamurthy, and Fiona Liausvia",
        "type": "NarrativeText"
    },
    {
        "element_id": "913f0e8d23af8084e0bbe5a72efce29e",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        397.3,
                        458.1
                    ],
                    [
                        397.3,
                        484.3
                    ],
                    [
                        864.0,
                        484.3
                    ],
                    [
                        864.0,
                        458.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.55582,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 1,
            "parent_id": "e712a4f1de044c84eaf78907fd5201b4"
        },
        "text": "AI Progamme a*STAR, Singapore, Singapore",
        "type": "NarrativeText"
    },
    {
        "element_id": "78e2fe43eb7dfee80e31a549bbff0c03",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        242.2,
                        466.1
                    ],
                    [
                        242.2,
                        576.8
                    ],
                    [
                        1017.6,
                        576.8
                    ],
                    [
                        1017.6,
                        466.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.45674,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 1,
            "parent_id": "e712a4f1de044c84eaf78907fd5201b4"
        },
        "text": "hosengbeng@gmail.com, Yang_Xiwen@scei.a-star.edu.sg, {therese_quieta,gangeshwar_krishnamurthy, liausviaf}@ihpc.a-star.edu.sg",
        "type": "NarrativeText"
    },
    {
        "element_id": "321cae543c3d78baf1586daf5d4d314f",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        231.6,
                        644.0
                    ],
                    [
                        231.6,
                        1125.9
                    ],
                    [
                        1029.5,
                        1125.9
                    ],
                    [
                        1029.5,
                        644.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93992,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 1,
            "parent_id": "e712a4f1de044c84eaf78907fd5201b4"
        },
        "text": "Abstract. Despite the progress made in AI, especially in the successful deployment of deep learning for many useful tasks, the systems involved typ- ically require a huge number of training instances, and hence a long time for training. As a result, these systems are not able to rapidly adapt to changing rules and constraints in the environment. This is unlike humans, who are usually able to learn with only a handful of experiences. This hampers the deployment of, say, an adaptive robot that can learn and act rapidly in the ever-changing environment of a home, of\ufb01ce, factory, or disaster area. Thus, it is necessary for an AI or robotic system to achieve human performance not only in terms of the \u201clevel\u201d or \u201cscore\u201d (e.g., success rate in classi\ufb01cation, score in Atari game playing, etc.) but also in terms of the speed with which the level or score can be achieved. In contrast with earlier DeepMind\u2019s effort on Atari games, in which they demonstrated the ability of a deep reinforcement learning system to learn and play the games at human level in terms of score, we describe a system that is able to learn causal rules rapidly in an Atari game environment and achieve human-like performance in terms of both score and time.",
        "type": "NarrativeText"
    },
    {
        "element_id": "72a4d1365b256e211c2e575e59bccd9c",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        232.6,
                        1147.9
                    ],
                    [
                        232.6,
                        1186.5
                    ],
                    [
                        848.0,
                        1186.5
                    ],
                    [
                        848.0,
                        1147.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 1
        },
        "text": "Keywords: Causal learning * Human-like performance Al -",
        "type": "Title"
    },
    {
        "element_id": "e54a3daae9de79aaaaba54838fe6448e",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        232.6,
                        1162.3
                    ],
                    [
                        232.6,
                        1217.1
                    ],
                    [
                        950.1,
                        1217.1
                    ],
                    [
                        950.1,
                        1162.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.62287,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 1,
            "parent_id": "72a4d1365b256e211c2e575e59bccd9c"
        },
        "text": "Keywords: Causal learning * Human-like performance Al - Atari game playing - Space invaders game playing - Problem solving",
        "type": "NarrativeText"
    },
    {
        "element_id": "75e0d8536ce2e0efe4833842fbfd882f",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.6,
                        1277.9
                    ],
                    [
                        149.6,
                        1311.1
                    ],
                    [
                        376.0,
                        1311.1
                    ],
                    [
                        376.0,
                        1277.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.85145,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 1
        },
        "text": "1 Introduction",
        "type": "Title"
    },
    {
        "element_id": "313858b160894ad5cfaecbd214316d7e",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.2,
                        1343.0
                    ],
                    [
                        149.2,
                        1675.6
                    ],
                    [
                        1112.5,
                        1675.6
                    ],
                    [
                        1112.5,
                        1343.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95212,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 1,
            "parent_id": "75e0d8536ce2e0efe4833842fbfd882f"
        },
        "text": "Arti\ufb01cial intelligence (AI) has taken great strides in many domains of applications. However, there has been realization that even though many AI systems can perform certain tasks very well that normally require human intelligence, and sometimes even superseding human abilities in those tasks, their performance is not \u201chuman-like\u201d in some aspects. For example, when deep learning is applied to pattern classi\ufb01cation and recognition, the accuracy is very high and sometimes outstrips human performance. However, humans usually require only a few instances of training examples to learn to classify and recognize the objects involved with high accuracy, whereas deep learning systems typically require many orders of magnitude of the number of training examples needed by humans. Thus, we can distinguish two aspects of judging the capability of an",
        "type": "NarrativeText"
    },
    {
        "element_id": "bd71224b99bed934dcc9cfef205a6835",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.6,
                        1706.7
                    ],
                    [
                        149.6,
                        1735.3
                    ],
                    [
                        541.7,
                        1735.3
                    ],
                    [
                        541.7,
                        1706.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 1
        },
        "text": "\u00a9 Springer Nature Switzerland AG 2019",
        "type": "Title"
    },
    {
        "element_id": "944d036b1d5e32d93caece847a5e5887",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        148.8,
                        1715.5
                    ],
                    [
                        148.8,
                        1791.1
                    ],
                    [
                        792.2,
                        1791.1
                    ],
                    [
                        792.2,
                        1715.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.59394,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 1,
            "parent_id": "bd71224b99bed934dcc9cfef205a6835"
        },
        "text": "X. Sun et al. (Eds.): ICAIS 2019, LNCS 11633, pp. 25\u201337, 2019. https://doi.org/10.1007/978-3-030-24265-7_3",
        "type": "NarrativeText"
    },
    {
        "element_id": "57e787ded5b3ad4549b62541519220f1",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        1072.7,
                        59.3
                    ],
                    [
                        1072.7,
                        146.0
                    ],
                    [
                        1159.3,
                        146.0
                    ],
                    [
                        1159.3,
                        59.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-1-1.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 1
        },
        "text": "\u00ae Check for updates",
        "type": "Image"
    },
    {
        "element_id": "1787f2ff1af33a3552d45331c738591e",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        102.9,
                        93.6
                    ],
                    [
                        102.9,
                        118.5
                    ],
                    [
                        348.5,
                        118.5
                    ],
                    [
                        348.5,
                        93.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.64171,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 2
        },
        "text": "26 S.-B. Ho et al.",
        "type": "Header"
    },
    {
        "element_id": "534e1e89cb59f83c22e06e57179ee364",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        105.3,
                        157.2
                    ],
                    [
                        105.3,
                        290.6
                    ],
                    [
                        1070.7,
                        290.6
                    ],
                    [
                        1070.7,
                        157.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9446,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 2,
            "parent_id": "1787f2ff1af33a3552d45331c738591e"
        },
        "text": "intelligent system, human or arti\ufb01cial. There is the level of performance, which is often a percentage score on the success on some tasks, such as classi\ufb01cation, and the other is the time taken to learn. Human-like performance means the system must perform well on both measures. Currently AI systems largely satisfy only the \u201clevel\u201d aspect.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a2ef661b011383a3c656501286a3d5d9",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        151.8,
                        290.0
                    ],
                    [
                        151.8,
                        323.6
                    ],
                    [
                        1070.8,
                        323.6
                    ],
                    [
                        1070.8,
                        290.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 2,
            "parent_id": "1787f2ff1af33a3552d45331c738591e"
        },
        "text": "One notable example recently is the DeepMind\u2019s seemingly successful attempt in",
        "type": "NarrativeText"
    },
    {
        "element_id": "0b2fc428e3f5cbd1ce525a7b8eef5402",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        108.1,
                        299.9
                    ],
                    [
                        108.1,
                        755.4
                    ],
                    [
                        1075.1,
                        755.4
                    ],
                    [
                        1075.1,
                        299.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94992,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 2,
            "parent_id": "1787f2ff1af33a3552d45331c738591e"
        },
        "text": "using deep reinforcement learning to play Atari games, in which it was purported that the system is a general learning system that is applicable to a wide domain of appli- cations [1]. The claim of generality stems from the fact that the one same algorithm, namely the deep reinforcement learning algorithm, was used quite successfully (in some cases more successfully than others) to play a slew of more than 50 Atari games with a large variety of game scenarios. Their measure of success in playing these games focuses on the \u201cscore\u201d measure \u2013 i.e., is the system able to score well, at human (novice or expert) score levels? By that measure of score, they succeeded reasonably well - in more than 50% of the games involved, the system was able to score higher than that of humans. However, by the measure of time, DeepMind\u2019s system plays at a speed many orders of magnitudes slower than that of human players. Tsividis also pointed out this large discrepancy between the time performance of DeepMind\u2019s system and that of human players [2].",
        "type": "NarrativeText"
    },
    {
        "element_id": "a6c1162f53b0e8af2ea3a1313c6ed540",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        109.0,
                        755.0
                    ],
                    [
                        109.0,
                        1054.3
                    ],
                    [
                        1073.5,
                        1054.3
                    ],
                    [
                        1073.5,
                        755.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94958,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 2,
            "parent_id": "1787f2ff1af33a3552d45331c738591e"
        },
        "text": "As for DeepMind\u2019s approach and achievement vis-\u00e0-vis AlphaGO [3], we observe that a human Go (or for that matter chess) player only has the ability to search a vastly smaller state space compared to that searched by AlphaGo when playing the game, and yet is still able to perform at Grand Master level, despite the recent losses to AlphaGo. Relatively speaking, despite the fact that mechanisms are in place to reduce the search space (e.g., Monte Carlo search mechanisms), AlphaGo still employs basically rela- tively brute-force search with the aid of super powerful computers. Obviously, the mental processing mechanisms employed by human players on the one hand and AlphaGo on the other are vastly different.",
        "type": "NarrativeText"
    },
    {
        "element_id": "878b2af4580f992a28c0272d1d851318",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        105.5,
                        1059.9
                    ],
                    [
                        105.5,
                        1419.5
                    ],
                    [
                        1073.5,
                        1419.5
                    ],
                    [
                        1073.5,
                        1059.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95134,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 2,
            "parent_id": "1787f2ff1af33a3552d45331c738591e"
        },
        "text": "As Go and chess are relatively complicated in terms of the mental processing mechanisms in the human player\u2019s mind, which have not been fully understood, we believe human players use the learning and understanding of causality to learn how to play Atari games. Ho and Zhu\u2019s groups have developed a framework and method to learn causality from visual input [4\u201311]. We have applied the method to the Atari game, Space Invaders, and have been able to demonstrate that a framework based on learning of causal rules from the visual environment together with an AI problem solving framework can produce a system that achieves human-like performance both in terms of level (score) and time taken. Below we \ufb01rst describe the basic principles behind the causal learning and problem solving framework and then describe the application to Space Invaders.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a7f0447503105d67a488b02218be7bc4",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        106.7,
                        1425.1
                    ],
                    [
                        106.7,
                        1685.2
                    ],
                    [
                        1070.8,
                        1685.2
                    ],
                    [
                        1070.8,
                        1425.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94961,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 2,
            "parent_id": "1787f2ff1af33a3552d45331c738591e"
        },
        "text": "To understand why this is important for AI and robotics, imagine the situations typically faced by a robot if it is to learn and perform tasks on a day to day basis such as operating a toaster or a washing machine. To operate a toaster, a robot is expected to learn that there is a causal connection between the pressing down of the lever on the toaster and the heating up of the toaster, hence the toasting of the bread. If a robot is to function satisfactorily as a house-help, it has to learn this at most within a small handful of demonstrations. Similarly, for a washing machine, a robot is expected to observe the process of loading clothes into a washing machine and then turning it on to wash the",
        "type": "NarrativeText"
    },
    {
        "element_id": "1634d986fd9b8cb41ae08f4a8b4f18ed",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        498.6,
                        88.2
                    ],
                    [
                        498.6,
                        118.9
                    ],
                    [
                        1111.1,
                        118.9
                    ],
                    [
                        1111.1,
                        88.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.57516,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 3,
            "parent_id": "1787f2ff1af33a3552d45331c738591e"
        },
        "text": "On Human-Like Performance Arti\ufb01cial Intelligence 27",
        "type": "ListItem"
    },
    {
        "element_id": "cb8716a8510e91bdca85366eb94a9c2e",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        144.2,
                        161.8
                    ],
                    [
                        144.2,
                        356.9
                    ],
                    [
                        1112.3,
                        356.9
                    ],
                    [
                        1112.3,
                        161.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95121,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 3,
            "parent_id": "1787f2ff1af33a3552d45331c738591e"
        },
        "text": "clothes, and learning this process perhaps within one or two demonstrations. Similarly, there are many rapid learning scenarios such as these with the various machines nor- mally found in the of\ufb01ces, factories, disaster areas, and many other places in which a generally adaptive robot is expected to rapidly learn the causalities between actions and effects to be able to function effectively. Thus, human-like performance is indispens- able. Deep reinforcement learning is not able to handle this kind of demands.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c5c8dd75311734c68bd59750b04284eb",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        147.1,
                        356.4
                    ],
                    [
                        147.1,
                        489.8
                    ],
                    [
                        1124.0,
                        489.8
                    ],
                    [
                        1124.0,
                        356.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93011,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 3,
            "parent_id": "1787f2ff1af33a3552d45331c738591e"
        },
        "text": "This paper attempts to use the example of the Atari game, Space Invaders, to \ufb01rstly illustrate and de\ufb01ne what it really means to achieve human-like performance for AI, and secondly demonstrate the mechanisms that enable human-like performance for an AI system.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9ea4a1151abb0081ed62a0f84fad4a52",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        148.9,
                        550.7
                    ],
                    [
                        148.9,
                        584.6
                    ],
                    [
                        958.1,
                        584.6
                    ],
                    [
                        958.1,
                        550.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82959,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 3,
            "parent_id": "1787f2ff1af33a3552d45331c738591e"
        },
        "text": "2 A Causal Learning and Problem Solving Framework",
        "type": "Title"
    },
    {
        "element_id": "8213ef965f71ae3f183bf9e68c7306bb",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.6,
                        621.5
                    ],
                    [
                        149.6,
                        649.2
                    ],
                    [
                        769.1,
                        649.2
                    ],
                    [
                        769.1,
                        621.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84265,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 3,
            "parent_id": "1787f2ff1af33a3552d45331c738591e"
        },
        "text": "2.1 Basic Idea Behind Causal/Temporal Learning",
        "type": "Title"
    },
    {
        "element_id": "1593bd5b482001811cdfe40006672a62",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        145.5,
                        674.2
                    ],
                    [
                        145.5,
                        1133.6
                    ],
                    [
                        1112.3,
                        1133.6
                    ],
                    [
                        1112.3,
                        674.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94775,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 3,
            "parent_id": "8213ef965f71ae3f183bf9e68c7306bb"
        },
        "text": "Judea Pearl has recently announced in his book that causality is now a legitimate domain of study [12]. The reason why the study of causality and hence causal learning has been hampered in the past was that there has been an often chanted \u201cmantra\u201d that \u201ccorrelation is not causality.\u201d However, in the domain of statistics, a method for scienti\ufb01c cause-effect discovery has long been established, and it is basically to uncover the correlation between an intervention (such as the administering of a drug) and an effect (such as the curing of a disease) observed later, with other variables randomized (e.g., age, gender, nationality of the patients involved, etc.) [13\u201315]. Statistics takes a conservative stance with regards to correlations without intervention. E.g., if there is correlation in the data between smoking and lung cancer, one should not immediately conclude that smoking causes lung cancer because there could be a gene that predis- poses people to smoking and at the same time it predisposes people to develop lung cancer later in life (some tobacco companies have used this to their defense when facing lawsuits). This is the source of the mantra \u201ccorrelation is not causality.\u201d",
        "type": "NarrativeText"
    },
    {
        "element_id": "6cb0d57915ca763288d245bb492c8156",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.1,
                        1139.1
                    ],
                    [
                        149.1,
                        1565.4
                    ],
                    [
                        1114.1,
                        1565.4
                    ],
                    [
                        1114.1,
                        1139.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94848,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 3,
            "parent_id": "8213ef965f71ae3f183bf9e68c7306bb"
        },
        "text": "Yang and Ho [16] take the stance that both causality and temporal correlations are important for AI\u2019s purposes. If one can establish the correlation between an intervention/action and a subsequent effect, thus establishing the causality between the action and effect, one can use it for (i) prediction \u2013 if the action is taken, the effect is expected; and (ii) problem solving \u2013 to achieve the effect, one can take the action. On the other hand, if a temporal correlation is observed between two events, none of which is an intervention/action taken by the system/human, then the temporal correlation is useful only for prediction \u2013 if the \ufb01rst event is observed, the second event is likely to follow. Thus, whether there is a gene that causes both smoking and the subsequent lung cancer is not important for prediction \u2013 if there is indeed a correlation between the two events, then observing someone smoking is suf\ufb01cient to conclude that lung cancer may follow, notwithstanding whether there is an underlying gene that is ultimately causally responsible for both.",
        "type": "NarrativeText"
    },
    {
        "element_id": "6cc628e40b809226b8f68f7a4b371c5d",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.6,
                        1570.9
                    ],
                    [
                        149.6,
                        1698.1
                    ],
                    [
                        1110.1,
                        1698.1
                    ],
                    [
                        1110.1,
                        1570.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94726,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 3,
            "parent_id": "8213ef965f71ae3f183bf9e68c7306bb"
        },
        "text": "In the following discussion, most of the concepts and constructs are applicable to both causality and temporal correlation as de\ufb01ned above. In some cases where they differ, we will highlight it explicitly, otherwise it can be assumed that the mechanisms work for both situations.",
        "type": "NarrativeText"
    },
    {
        "element_id": "e5a36e9fcbf06a852a5b106b9dba7cb2",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        106.3,
                        92.9
                    ],
                    [
                        106.3,
                        118.5
                    ],
                    [
                        348.4,
                        118.5
                    ],
                    [
                        348.4,
                        92.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.35725,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 4
        },
        "text": "28 S.-B. Ho et al.",
        "type": "Header"
    },
    {
        "element_id": "11e83a34a1b6904f5b1ad9c9f41e0e60",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        108.3,
                        160.3
                    ],
                    [
                        108.3,
                        223.8
                    ],
                    [
                        966.8,
                        223.8
                    ],
                    [
                        966.8,
                        160.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84581,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 4,
            "parent_id": "e5a36e9fcbf06a852a5b106b9dba7cb2"
        },
        "text": "2.2 Diachronic vs Synchronic Causal Condition for Causal/Temporal Rule Learning",
        "type": "Title"
    },
    {
        "element_id": "141bd5f6e42e2847d25feb47e74919e1",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        105.6,
                        242.9
                    ],
                    [
                        105.6,
                        409.5
                    ],
                    [
                        1071.4,
                        409.5
                    ],
                    [
                        1071.4,
                        242.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94807,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 4,
            "parent_id": "11e83a34a1b6904f5b1ad9c9f41e0e60"
        },
        "text": "In the framework of causal/temporal learning set up by Ho\u2019s group [6, 7, 16], a distinction is made between diachronic vs synchronic causal/temporal conditions. (As mentioned above, as the following discussion is applicable to both causality and temporal correlation, we will omit the \u201ctemporal\u201d portion sometimes henceforth.) Figure 1 illustrates the distinction with an example.",
        "type": "NarrativeText"
    },
    {
        "element_id": "af38256a29403a4d0d4731490a9d71da",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        159.7,
                        471.2
                    ],
                    [
                        159.7,
                        750.6
                    ],
                    [
                        1021.4,
                        750.6
                    ],
                    [
                        1021.4,
                        471.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-4-2.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 4
        },
        "text": "m | Food Food Food LI \u00a9)",
        "type": "Image"
    },
    {
        "element_id": "979351c465c4191cb71a3414e02da40b",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        110.2,
                        781.0
                    ],
                    [
                        110.2,
                        836.6
                    ],
                    [
                        1071.0,
                        836.6
                    ],
                    [
                        1071.0,
                        781.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92149,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 4
        },
        "text": "Fig. 1. (a) An Agent wanders around in the environment and Touches a piece of Food and experiences Energy_Increase. (b) The Agent encounters another experience of Energy_Increase.",
        "type": "FigureCaption"
    },
    {
        "element_id": "45e1c7e16b9c1ab2e3cbeac1070c2991",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        104.7,
                        892.3
                    ],
                    [
                        104.7,
                        1086.0
                    ],
                    [
                        1071.9,
                        1086.0
                    ],
                    [
                        1071.9,
                        892.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95415,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 4
        },
        "text": "In Fig. 1(a) it is shown that an Agent explores around in an environment and accidentally Touches a piece of Food at time T1 and at location L1 and it \ufb01nds itself experiencing an increase in energy. A causal rule can be learned as such: At(Agent, L1, T1) & Touch(Agent, Food, L1, T1) ! Energy_Increase(Agent, L1, T1). This is a speci\ufb01c causal rule: it says as currently understood, the Energy_Increase can take place if the Agent Touches the Food at location L1 and time T1.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c2131e389f27e5fb3ab49e78c99cf965",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        102.4,
                        1091.3
                    ],
                    [
                        102.4,
                        1252.1
                    ],
                    [
                        1075.9,
                        1252.1
                    ],
                    [
                        1075.9,
                        1091.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 4
        },
        "text": "The action part of the causal rule, Touch(Agent, Food, L1, T1), is the diachronic causal condition. The \u201cbackground\u201d or \u201ccontext\u201d part of the rule, At(Agent, L1, T1), is the synchronic causal condition. The synchronic causal condition is an \u201cenabling\u201d condition \u2013 it enables the diachronic preconditional \u201ccause\u201d - Touch(Agent, Food, L1, T1) to give rise to the \u201ceffect\u201d - Energy_Increase(Agent, L1, T1).",
        "type": "NarrativeText"
    },
    {
        "element_id": "4d64471ba7b500ade629d231a5fe2aaf",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        103.6,
                        1257.4
                    ],
                    [
                        103.6,
                        1551.0
                    ],
                    [
                        1074.3,
                        1551.0
                    ],
                    [
                        1074.3,
                        1257.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95424,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 4
        },
        "text": "Now, suppose the Agent then wanders to another location L2 and Touches another piece of Food at time T2 and also experiences an increase in energy. Another speci\ufb01c causal rule can be learned: At(Agent, L2, T2) & Touch(Agent, Food, L2, T2) ! Energy_Increase(Agent, L2, T2). At this stage, a general causal rule can be induced from the two speci\ufb01c instances: At(Agent, Any L, Any T) & Touch(Agent, Food, Any same L, Any same T) ! Energy_Increase(Agent, Any same L, Any same T), meaning that the exact values of location and time are not important for the Touching action to give rise to Energy_Increase (but they must be the same in the three predicates), but the Touching action itself is necessary.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a62240c3b89ab909b9e194d3d77698a2",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        110.2,
                        1556.4
                    ],
                    [
                        110.2,
                        1683.8
                    ],
                    [
                        1070.8,
                        1683.8
                    ],
                    [
                        1070.8,
                        1556.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93911,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 4
        },
        "text": "We term this process of unsupervised learning in which the causal rules are picked up, learned, and encoded from observation carried out on the environment the process of causal learning (of causal rules). The process is similar for temporal correlation rule learning \u2013 as we mentioned above. If the \ufb01rst event is not an action effected by the",
        "type": "NarrativeText"
    },
    {
        "element_id": "c43dc1a542358536288fbdb9a5311740",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        497.8,
                        88.2
                    ],
                    [
                        497.8,
                        119.3
                    ],
                    [
                        1111.0,
                        119.3
                    ],
                    [
                        1111.0,
                        88.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.68716,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 5
        },
        "text": "On Human-Like Performance Arti\ufb01cial Intelligence 29",
        "type": "ListItem"
    },
    {
        "element_id": "42b0ed2757a8127551e3291f742452d8",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        144.6,
                        160.7
                    ],
                    [
                        144.6,
                        323.6
                    ],
                    [
                        1113.9,
                        323.6
                    ],
                    [
                        1113.9,
                        160.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95164,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 5
        },
        "text": "agent (in this case, Touch), and instead it is just an event observed in the environment, then it would be just a temporal correlation rule useful for prediction but not problem solving (because the \ufb01rst event, not being an action, cannot be effected by the agent). Similar concepts of diachronic vs synchronic preconditions apply to temporal corre- lation rules.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d89204a909b458fc782ffa233446479d",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        148.1,
                        371.2
                    ],
                    [
                        148.1,
                        399.4
                    ],
                    [
                        606.7,
                        399.4
                    ],
                    [
                        606.7,
                        371.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.86434,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 5
        },
        "text": "2.3 The Atari Game Space Invaders",
        "type": "Title"
    },
    {
        "element_id": "124b5f1d6080de71e037b5a112d3b3f7",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        147.7,
                        422.8
                    ],
                    [
                        147.7,
                        784.3
                    ],
                    [
                        1114.0,
                        784.3
                    ],
                    [
                        1114.0,
                        422.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95479,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 5,
            "parent_id": "d89204a909b458fc782ffa233446479d"
        },
        "text": "In this section, we describe the basic features of the Space Invaders game. Figure 2(a) shows a screen shot of the game. Basically, the game consists of a bunch of \u201cSpace Invaders\u201d coming from the top part of the screen, moving horizontally and then slowly downward, toward a Player at the bottom of the screen. Bullets are \ufb01red by the Space Invaders toward the Player. The Player has three actions available to her: move left, move right, or \ufb01re a bullet upward to destroy the Space Invaders. Every time an Invader gets hit, the Score for the Player will increase. The Player gets \u201cdestroyed\u201d when it is hit. It has three \u201clives\u201d and when those are expended, the game is over. If the Player can destroy all the Invaders before all three lives are expended, the game proceeds to the next level. There are barriers lined up near the bottom of the screen between the Invaders and Players that can shield the bullets from either side.",
        "type": "NarrativeText"
    },
    {
        "element_id": "7fc1614f208102d4a76c03f84d2f7f12",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        165.7,
                        848.2
                    ],
                    [
                        165.7,
                        1081.7
                    ],
                    [
                        1094.3,
                        1081.7
                    ],
                    [
                        1094.3,
                        848.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-5-3.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 5
        },
        "text": "676): Player(id(2),gid(P2),HP(0),LIVES(2),stat(10),loc_a(185),!oc_b(194),loc_c(116),loc_d(122)), Score, | mam a eee ES EEESESEZ Bullet(i(81),g'd(E36),RD(7)Joc_a(175),/0c_b(184),loc_\u00a2{116)loc_d(2116}),lavaders... RRR RRR t(677): Player(id(P1),gid(P1),HP(0),LIVES(2),stat(10),loc_a(185),loc_b(194),loc_c(116),loc_d(122)), Invaders\u2014\" 2 22222 Visual Bullet(id(81),gid(E36),RD(5),loc_a(177),loc_b(186),loc_c{116),loc_d(116)), Invaders... ...... P (678): Player(id(P1),gid(P1),HP(0),LIVES(2),stat(10),loc_a(185),loc_b(194),loc_c(116),loc_d(122)), Bullet aan2e2 e Bullet(id(81),gid(E36),RD(S),loc_a(2177),loc_b(186),loc_\u00a2(216),loc_d(116)), Invaders... 4(679), Player(id{P1),gid(P2),HP(0),LIVES(2),stat(10),loc_a(185),loc_b(194),loc_c(116),loc_d(122)), Bullet(id(B2),gid(\u20ac36), RO(3),loc_a(2179),loc_b(188),loc_c(116),loc_d(16)), Invaders. \u2014 \u2014 Visual predicates describing Location, Relative Distances, Live, etc. of various game entities (a) (6) Player \u2014 O\u00c2A A A \u2014 2 Space Invaders",
        "type": "Image"
    },
    {
        "element_id": "37179eb45d9276a98af8c74f210c3006",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        160.1,
                        1112.2
                    ],
                    [
                        160.1,
                        1137.4
                    ],
                    [
                        1099.0,
                        1137.4
                    ],
                    [
                        1099.0,
                        1112.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82993,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 5
        },
        "text": "(a) The Space Invaders game. (b) The symbolic predicates extracted from the scene.",
        "type": "FigureCaption"
    },
    {
        "element_id": "60211b6e7a27f67375d3c79dacca7db5",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        146.7,
                        1193.1
                    ],
                    [
                        146.7,
                        1519.7
                    ],
                    [
                        1111.6,
                        1519.7
                    ],
                    [
                        1111.6,
                        1193.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95366,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 5
        },
        "text": "In Fig. 2(b), we show the symbolic predicate description of the scene of the Space Invaders game. The data is organized in a temporal form: at each time frame, there is a description of every entity and their associated parameters, much like the predicate description associated with the discussion in Fig. 1. So, for example, the description of a few of the Space Invaders and the Player at time frame Time(t1) could be: Time(t1) - Invader(ID = 10, LocationX = x1, LocationY = y1), Invader(ID = 11, LocationX = x2, LocationY = y2)\u2026 Player(LocationX = x10)\u2026. If there are bullets in the corre- sponding time frames, they will be included. We encoded a \u201cvision module\u201d to extract this information from every time frame of the Space Invaders game scene generated by the Atari game engine.",
        "type": "NarrativeText"
    },
    {
        "element_id": "af2b41b1af29ee6536ba099b181862ce",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        102.7,
                        93.3
                    ],
                    [
                        102.7,
                        118.8
                    ],
                    [
                        348.4,
                        118.8
                    ],
                    [
                        348.4,
                        93.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.31133,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 6
        },
        "text": "30 S.-B. Ho et al.",
        "type": "Header"
    },
    {
        "element_id": "c81329935a4be472ed78f2c8c5d809be",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        110.2,
                        159.8
                    ],
                    [
                        110.2,
                        224.7
                    ],
                    [
                        979.6,
                        224.7
                    ],
                    [
                        979.6,
                        159.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88143,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 6,
            "parent_id": "af2b41b1af29ee6536ba099b181862ce"
        },
        "text": "2.4 A System for Causal/Temporal Learning, Reasoning, and Problem Solving",
        "type": "Title"
    },
    {
        "element_id": "34348c92e7cb9a7e44f576cfb64f6ed2",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        109.6,
                        246.7
                    ],
                    [
                        109.6,
                        509.0
                    ],
                    [
                        1070.8,
                        509.0
                    ],
                    [
                        1070.8,
                        246.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95353,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 6,
            "parent_id": "c81329935a4be472ed78f2c8c5d809be"
        },
        "text": "In traditional AI, there was a sub-domain of study on problem solving in which there was an attempt to formulate a General Problem Solver (GPS) that has general problem solving mechanisms for all situations. The GPS can act on the facts and knowledge involved in particular domains to derive solutions for particular situations [17]. Our approach is similar here, except that the knowledge, in the form of causal rules, is learned from causal/temporal learning, while in traditional AI research associated with GPS, the knowledge involved was typically hand-coded. Figure 3(a) shows this basic structure.",
        "type": "NarrativeText"
    },
    {
        "element_id": "1217720c331652308b3b7fefea7f8de5",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        138.0,
                        584.3
                    ],
                    [
                        138.0,
                        1211.3
                    ],
                    [
                        1043.2,
                        1211.3
                    ],
                    [
                        1043.2,
                        584.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-6-4.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 6
        },
        "text": "HLCLPSS (Human-like Causal Learning and Problem Solving System) Visual Processing (in Time-Based/Episodic Form) Symbolic description of Scene Learning of Causal Rules Learning of Scripts (in symbolic forms) (in symbolic forms) CRSB Learning of (Causal Rules and Scripts Base) Causal Rules (in symbolic Goal Reasoning (including Mental forms) Specification Simulation) and Problem Solving (Symbolic processing with the Al Planning Score learned causal rules and scripts) and Problem Solving using Solve Atari games and Learned Rules general AI problems (a) (b)",
        "type": "Image"
    },
    {
        "element_id": "ce2250d9f51ae335f1c00edf6ffcdeb8",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        107.7,
                        1241.8
                    ],
                    [
                        107.7,
                        1327.8
                    ],
                    [
                        1074.4,
                        1327.8
                    ],
                    [
                        1074.4,
                        1241.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88266,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 6
        },
        "text": "Fig. 3. (a) The basic overall causal learning and problem solving framework. (b) The detailed processing modules of the Human-like Causal Learning and Problem Solving System (HLCLPSSS).",
        "type": "FigureCaption"
    },
    {
        "element_id": "d43d0047f83caff3e4ef5a33cb9cc240",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        99.7,
                        1383.5
                    ],
                    [
                        99.7,
                        1510.9
                    ],
                    [
                        1070.8,
                        1510.9
                    ],
                    [
                        1070.8,
                        1383.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92906,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 6
        },
        "text": "In Fig. 3(b), we show the further detail on the various modules in the system. The processing begins with the Environment, which for Space Invaders would be the Space Invaders\u2019 visual scene. A Visual Processing module converts that to a time-based, episodic form as described above (Fig. 2(b)).",
        "type": "NarrativeText"
    },
    {
        "element_id": "13a277503dd30896ef8b2fccc2324184",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        106.9,
                        1516.4
                    ],
                    [
                        106.9,
                        1678.6
                    ],
                    [
                        1071.9,
                        1678.6
                    ],
                    [
                        1071.9,
                        1516.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94457,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 6
        },
        "text": "Next, causal rules, much like those discussed in connection with Fig. 1 are learned and encoded. A \u201cclean\u201d causal rule extracted could be something like: At(Player, Any Location, Any Time) & Contact(Player, Invader_Bullet, Any Same Location, Any Same Time) ! Destroyed(Player, Any Same Location, Any Same Time + 1). (In the system we implemented, typically, very \u201cclean\u201d rules \u2013 meaning rules that do not have",
        "type": "NarrativeText"
    },
    {
        "element_id": "b8f57990c4763c55a72614ae5be79625",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        498.5,
                        88.2
                    ],
                    [
                        498.5,
                        119.0
                    ],
                    [
                        1110.3,
                        119.0
                    ],
                    [
                        1110.3,
                        88.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.63782,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 7
        },
        "text": "On Human-Like Performance Arti\ufb01cial Intelligence 31",
        "type": "ListItem"
    },
    {
        "element_id": "cdf9b1b44300a21b3b678573494d22cf",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.0,
                        157.2
                    ],
                    [
                        149.0,
                        356.9
                    ],
                    [
                        1111.6,
                        356.9
                    ],
                    [
                        1111.6,
                        157.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95191,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 7
        },
        "text": "\u201cunwanted\u201d predicates - such as that above are not always easily obtained through the unsupervised causal learning process. However, the mechanism suf\ufb01ced for the sub- sequent problem solving processes that yielded the results that we could use to demonstrate the idea of human-like performance for AI). A small handful of visual predicates, such as Contact, Destroyed, etc. are built-in recognition mechanisms which we assume a typical visual system, natural or arti\ufb01cial, should provide.",
        "type": "NarrativeText"
    },
    {
        "element_id": "2068849db4d55976bee1069315828a2f",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        145.4,
                        362.4
                    ],
                    [
                        145.4,
                        556.2
                    ],
                    [
                        1114.0,
                        556.2
                    ],
                    [
                        1114.0,
                        362.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9485,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 7
        },
        "text": "In order to facilitate problem solving, the system also learns and encodes Scripts, as shown in Fig. 3(b). Scripts are basically longer chains of actions. E.g., a sequence of movements of a bullet from the starting point to the ending point could be a \u201cMove- ment Script\u201d. Currently, in this system, sequences of any 5 actions observed in the environment are stored as Scripts. This vastly cuts down the search space of the problem solving process.",
        "type": "NarrativeText"
    },
    {
        "element_id": "089a6a81030cb0d1fc0f62efdf8cb91a",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.6,
                        561.6
                    ],
                    [
                        149.6,
                        888.2
                    ],
                    [
                        1113.8,
                        888.2
                    ],
                    [
                        1113.8,
                        561.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95388,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 7
        },
        "text": "The Problem Solving process of the system (Fig. 3(b)) basically uses the traditional backward chaining process of AI \u2013 given a Goal speci\ufb01cation, what are the rules and scripts from the Causal Rules and Script Base (CRSB) that can be assembled to concoct a solution. As will be described below, there are two kinds of Goals \u2013 Goal to achieve a desired state (Increase of Score) and Goal to avoid an undesired state (Destruction of Player). As part of the Reasoning process, Mental Simulation is carried out to deter- mine if there is any undesired state \u2013 e.g., the movement rules and scripts of the Invader\u2019s bullet can be used to project into the future to see if they might hit the Player, much like a human mentally imagining the sequences of known event changes that lead to a certain consequence.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3ab6a08938e5262ff63bd5932e5f3a8a",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        148.2,
                        935.6
                    ],
                    [
                        148.2,
                        964.4
                    ],
                    [
                        591.6,
                        964.4
                    ],
                    [
                        591.6,
                        935.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.86371,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 7
        },
        "text": "2.5 Goal-Directed Problem Solving",
        "type": "Title"
    },
    {
        "element_id": "c7f0c8fb48f191450ca9da2bccb8009e",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        146.9,
                        988.2
                    ],
                    [
                        146.9,
                        1083.2
                    ],
                    [
                        1118.8,
                        1083.2
                    ],
                    [
                        1118.8,
                        988.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93474,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 7,
            "parent_id": "3ab6a08938e5262ff63bd5932e5f3a8a"
        },
        "text": "As mentioned above, there are two kinds of goals - Goal to achieve a desired state (Increase of Score) and Goal to avoid an undesired state (Destruction of Player). These are described as follows:",
        "type": "NarrativeText"
    },
    {
        "element_id": "624258e2b64bc9c3d50c8d224745c4e4",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.6,
                        1105.0
                    ],
                    [
                        149.6,
                        1132.7
                    ],
                    [
                        980.0,
                        1132.7
                    ],
                    [
                        980.0,
                        1105.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 7
        },
        "text": "Goal to Achieve a Desired State and the Associated Learning Process",
        "type": "Title"
    },
    {
        "element_id": "59ab4bc397aa3f3e30846b379b478d78",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.6,
                        1113.5
                    ],
                    [
                        149.6,
                        1199.4
                    ],
                    [
                        1118.4,
                        1199.4
                    ],
                    [
                        1118.4,
                        1113.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.8196,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 7,
            "parent_id": "624258e2b64bc9c3d50c8d224745c4e4"
        },
        "text": "Figure 4 illustrates a typical situation in Space Invaders in which there is a desired Goal to achieve.",
        "type": "NarrativeText"
    },
    {
        "element_id": "888c64dade6f458513d22924a6268c27",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.6,
                        1198.9
                    ],
                    [
                        149.6,
                        1332.1
                    ],
                    [
                        1117.3,
                        1332.1
                    ],
                    [
                        1117.3,
                        1198.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93619,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 7,
            "parent_id": "624258e2b64bc9c3d50c8d224745c4e4"
        },
        "text": "In Fig. 4(a), it is shown that the Player is not in a position to \ufb01re a bullet to destroy an Invader. The Player carries out a backward chained problem solving process and obtains a solution \u2013 move to a location at which the Invader is in the direct line of \ufb01re and \ufb01re a bullet to destroy the Invader.",
        "type": "NarrativeText"
    },
    {
        "element_id": "5fdd6a2ac3e145fcafdccbce9d2bef57",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.6,
                        1331.7
                    ],
                    [
                        149.6,
                        1631.3
                    ],
                    [
                        1110.9,
                        1631.3
                    ],
                    [
                        1110.9,
                        1331.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95181,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 7,
            "parent_id": "624258e2b64bc9c3d50c8d224745c4e4"
        },
        "text": "The learning process proceeds as follows. In an initial \u201cexploration phase\u201d (much like the exploration phase of reinforcement learning), the Player \ufb01res at random, and occasionally a bullet would hit an Invader and destroy the Invader. After a few instances of similar experience, a causal rule such as this is learned: At(Player_Bullet, Any Location, Any Time) & Contact(Player_Bullet, Invader(Any ID), Any Same Location, Any Same Time) ! Destroyed(Invader(Any Same ID), Any Same Location, Any Same Time + 1). (As mentioned above, in our implemented system, the learned rules may not look as \u201cclean\u201d, as there are other \u201cnoisy\u201d diachronic and synchronic conditions that \u201ccreep\u201d into the rule, but they suf\ufb01ce for problem solving purposes and",
        "type": "NarrativeText"
    },
    {
        "element_id": "b0063f4cc1bbc61cb0fd20ca2906133f",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        100.3,
                        93.6
                    ],
                    [
                        100.3,
                        118.5
                    ],
                    [
                        349.1,
                        118.5
                    ],
                    [
                        349.1,
                        93.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.70618,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 8
        },
        "text": "32 S.-B. Ho et al.",
        "type": "Header"
    },
    {
        "element_id": "bc88b0ac7ee2aa490c8dffb8d01730b6",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        279.1,
                        165.4
                    ],
                    [
                        279.1,
                        468.2
                    ],
                    [
                        902.2,
                        468.2
                    ],
                    [
                        902.2,
                        165.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-8-5.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 8
        },
        "text": "[sic AUR Vani | LALE Viet a aaa EZEN Ooo EEE coon >\u00bb sw EEE KEK \"nana AAAAA MA DHOHH HH Se Se oe be oe oe sase ARARAR ..\u00f6)a2 Re@Qeee Som + \u00bb\u00bb \u00bb A/ ANA Ayd &\u00e2 aE \u00e9 : | \u0131 > ener i Next Invader Player destroyed Bullet Player moves to picked an Invader earlier fired shoot at Invader (a) (b)",
        "type": "Image"
    },
    {
        "element_id": "1f9f1ee2836d4d5c647c6ea422c99d30",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        110.2,
                        493.4
                    ],
                    [
                        110.2,
                        523.7
                    ],
                    [
                        1070.9,
                        523.7
                    ],
                    [
                        1070.9,
                        493.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 8
        },
        "text": "Fig. 4. To achieve a desired goal in Space Invaders: Player \ufb01nds a solution to destroy an",
        "type": "NarrativeText"
    },
    {
        "element_id": "03d024ad12c36c9cea8ead24fc538d75",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        106.9,
                        502.5
                    ],
                    [
                        106.9,
                        584.6
                    ],
                    [
                        1077.2,
                        584.6
                    ],
                    [
                        1077.2,
                        502.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93825,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 8
        },
        "text": "Invader. (a) Player is not in the correct position to destroy the Invader. (b) Player moves to the correct position as directed by the solution of a problem solving process.",
        "type": "FigureCaption"
    },
    {
        "element_id": "93375f102270dc48244929fb04761e9c",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        105.1,
                        640.4
                    ],
                    [
                        105.1,
                        701.3
                    ],
                    [
                        1074.4,
                        701.3
                    ],
                    [
                        1074.4,
                        640.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91155,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 8
        },
        "text": "this clean rule is good for illustrating the basic idea.). When an Invader is destroyed, the Score goes up, and that is a desired Goal.",
        "type": "NarrativeText"
    },
    {
        "element_id": "bc30f251e83f721b7bda24122a5ba04c",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        101.2,
                        706.8
                    ],
                    [
                        101.2,
                        1066.5
                    ],
                    [
                        1074.6,
                        1066.5
                    ],
                    [
                        1074.6,
                        706.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95205,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 8
        },
        "text": "After all these causal rules have been learned, the system is ready to carry our backward chained problem solving. At all times, the system is in the mode of looking for ways to achieve a desired Goal, and in this case, it would be Increase_Score or Destroyed(Invader(Any ID, Any Location, Any Time)). So, the above rules are then used in a backward chained process \u2013 in order to achieve destruction of an (any) Invader, a Player_Bullet must be made in Contact with it. In order for a Player_Bullet to be made in Contact with it, the Player_Bullet must be \ufb01red from a certain position (encoded in the scripts learned earlier in an unsupervised learning process), in order for the Player_Bullet to be \ufb01red at a certain position the Player must Move to a certain location, etc. Thus, the solution shown in Fig. 4(b) is obtained. The Invader target can be selected at random or the nearest one to the Player is selected.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ef20c95736ac79e32a234ee284bdc2fd",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        104.4,
                        1072.0
                    ],
                    [
                        104.4,
                        1199.4
                    ],
                    [
                        1070.8,
                        1199.4
                    ],
                    [
                        1070.8,
                        1072.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94755,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 8
        },
        "text": "The above process closely simulates the problem solving processes carried out by a human player rapidly in her mind about what to do to achieve the Goal of increasing the Score, and also simulates the rapid learning process for a human player to reach some decent level of score performance.",
        "type": "NarrativeText"
    },
    {
        "element_id": "58488a087da8c5f382d5c5b104861d19",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        104.8,
                        1221.2
                    ],
                    [
                        104.8,
                        1315.6
                    ],
                    [
                        1070.7,
                        1315.6
                    ],
                    [
                        1070.7,
                        1221.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88537,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 8
        },
        "text": "Goal to Avoid an Undesired State and the Associated Learning Process Figure 5 illustrate a typical situation in Space Invaders in which there is an undesired Goal to avoid.",
        "type": "NarrativeText"
    },
    {
        "element_id": "5549bf9d195219b4b983803955b13426",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        107.2,
                        1315.0
                    ],
                    [
                        107.2,
                        1548.0
                    ],
                    [
                        1072.0,
                        1548.0
                    ],
                    [
                        1072.0,
                        1315.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95459,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 8
        },
        "text": "In Fig. 5(a), it is shown that an Invader \ufb01res a bullet at the Player. Using mental simulation based on the earlier learned, known rules of the bullet\u2019s behavior, the system knows that some time in the future the bullet will hit the Player (because it is in the bullet\u2019s path) and the Player will be destroyed. The system therefore concocts a plan to prevent this from happening. The solution is to move left a little bit as shown in Fig. 5(b). In Fig. 5(c) it is shown that the bullet and hence the destruction of the player is successfully avoided.",
        "type": "NarrativeText"
    },
    {
        "element_id": "0bbc65dcf0b955a52a5e271a0f03a0f0",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        500.2,
                        88.2
                    ],
                    [
                        500.2,
                        118.5
                    ],
                    [
                        1019.6,
                        118.5
                    ],
                    [
                        1019.6,
                        88.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "On Human-Like Performance Arti\ufb01cial Intelligence",
        "type": "Title"
    },
    {
        "element_id": "658b6d3a092cc178634242039a32b0e0",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        242.4,
                        165.4
                    ],
                    [
                        242.4,
                        413.1
                    ],
                    [
                        1017.5,
                        413.1
                    ],
                    [
                        1017.5,
                        165.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-9-6.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "Mei ooo ee eo00 doon KKK KKK RRR RK KE aanama ananem AARAAM Se Se ve vt vE Se RHRHHH Ree ee RRRAARR ...... RAARARA sanree snaanan aenerne Bullet Pa mm senna ed from Aha aca A a a aA Invader masumu \u2014 momen : a i Player moves left twice Bullet passes by Player (a) (b) (c)",
        "type": "Image"
    },
    {
        "element_id": "4ec5e1a83977731f6098f444c6841c96",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        147.7,
                        443.4
                    ],
                    [
                        147.7,
                        559.9
                    ],
                    [
                        1119.7,
                        559.9
                    ],
                    [
                        1119.7,
                        443.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93523,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "Fig. 5. Player avoids an undesired Goal of being destroyed by a bullet from an Invader. (a) A bullet is \ufb01red from an Invader toward the Player, and in mental simulation, the system knows that the Player will get hit. (b) The system concocts a plan after some problem solving process to avoid the bullet. (c) The bullet is avoided.",
        "type": "FigureCaption"
    },
    {
        "element_id": "db5c61aaaadebd91203103d04076130a",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        145.6,
                        615.7
                    ],
                    [
                        145.6,
                        676.9
                    ],
                    [
                        1120.2,
                        676.9
                    ],
                    [
                        1120.2,
                        615.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.925,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "The learning of this process capitalizes on the idea of contrapositivity in logic. Consider the following logical statement:",
        "type": "NarrativeText"
    },
    {
        "element_id": "c10e2ab6078da52827606df20f782c18",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        450.8,
                        705.1
                    ],
                    [
                        450.8,
                        744.8
                    ],
                    [
                        1110.2,
                        744.8
                    ],
                    [
                        1110.2,
                        705.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.60489,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "A and B and C and D. . .!E \u00f01\u00de",
        "type": "Formula"
    },
    {
        "element_id": "e7f31addae6621676d8ab5d8652cc41f",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        191.2,
                        776.0
                    ],
                    [
                        191.2,
                        803.6
                    ],
                    [
                        586.1,
                        803.6
                    ],
                    [
                        586.1,
                        776.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.86339,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "The contrapositive of the above is:",
        "type": "NarrativeText"
    },
    {
        "element_id": "78fb2a5bd1cd5efb7f5bfa146e03dd5d",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        386.0,
                        832.2
                    ],
                    [
                        386.0,
                        865.5
                    ],
                    [
                        873.9,
                        865.5
                    ],
                    [
                        873.9,
                        832.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "Not E ! Not A or Not B or Not C or Not D. . .",
        "type": "UncategorizedText"
    },
    {
        "element_id": "2cdd4ef9947696a576cd668f0a2d3e86",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        390.3,
                        838.6
                    ],
                    [
                        390.3,
                        863.7
                    ],
                    [
                        1105.6,
                        863.7
                    ],
                    [
                        1105.6,
                        838.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.57455,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "Not E \u2014 Not Aor Not Bor Not C or Not D... (2)",
        "type": "Formula"
    },
    {
        "element_id": "8d1dc8415c0a384fcc6b309ac56c8dbe",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.6,
                        903.1
                    ],
                    [
                        149.6,
                        1163.3
                    ],
                    [
                        1110.2,
                        1163.3
                    ],
                    [
                        1110.2,
                        903.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95172,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "This contrapositive reasoning process is built into the system and used in the process of reasoning out a way to avoid an unnecessary goal. For example, in the beginning of the Space Invaders game, the situation of experiencing the undesired goal is \ufb01rst learned in a few instances in which the Invaders \ufb01re bullets and they destroy the Player (this is not random \u2013 the game engine deliberately does that). The entire script containing the following sequence of events is learned: a bullet (i) appearing, (ii) moving step by step toward the Player, (iii) contacting the Player, and then (iv) destroying the Player:",
        "type": "NarrativeText"
    },
    {
        "element_id": "8ee7ae49b7b52c26708495a36f3ece9c",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        170.5,
                        1194.7
                    ],
                    [
                        170.5,
                        1269.8
                    ],
                    [
                        1111.5,
                        1269.8
                    ],
                    [
                        1111.5,
                        1194.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89838,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "Appear Bullet; Loc1 \u00f0 \u00de and Move Bullet; Loc2 \u00f0 \u00de and Move Bullet; Loc3 \u00f0 \u00de and. . . Contact Bullet; Player; Loc10 \u00f0 \u00de ! Destroyed Player; Loc10 \u00f0 \u00de \u00f03\u00de",
        "type": "NarrativeText"
    },
    {
        "element_id": "768a08660e75457e0b50fe16b406aef8",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        145.9,
                        1308.3
                    ],
                    [
                        145.9,
                        1404.0
                    ],
                    [
                        1121.3,
                        1404.0
                    ],
                    [
                        1121.3,
                        1308.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91711,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "This sequence is a conjunction of a series of events that must happen for the player to be destroyed. (After the system has encountered more instances of (3), a generalized version with \u201cany location\u201d in the location parameters will be learned.)",
        "type": "NarrativeText"
    },
    {
        "element_id": "db7082960479e7d9202220fd7b9cd92e",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        178.9,
                        1409.4
                    ],
                    [
                        178.9,
                        1437.8
                    ],
                    [
                        970.4,
                        1437.8
                    ],
                    [
                        970.4,
                        1409.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.30715,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "Applying the contrapositive reasoning process, this is converted into:",
        "type": "ListItem"
    },
    {
        "element_id": "be60c3ab0b6f95c7db7476f33f60328a",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        191.2,
                        1436.6
                    ],
                    [
                        191.2,
                        1469.9
                    ],
                    [
                        565.9,
                        1469.9
                    ],
                    [
                        565.9,
                        1436.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "Not(Destroyed(Player, Loc10) !",
        "type": "Title"
    },
    {
        "element_id": "c481f83e79e92aab4b5e719e8c46f3d8",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        191.2,
                        1469.8
                    ],
                    [
                        191.2,
                        1503.2
                    ],
                    [
                        654.3,
                        1503.2
                    ],
                    [
                        654.3,
                        1469.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "Not(Appear(Bull Appear(Bullet, Loc1) or",
        "type": "Title"
    },
    {
        "element_id": "56eb8bfb9132bc657034e89e0415a3ed",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        191.2,
                        1503.0
                    ],
                    [
                        191.2,
                        1536.4
                    ],
                    [
                        489.1,
                        1536.4
                    ],
                    [
                        489.1,
                        1503.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "Not(Move(Bullet, Loc2) or",
        "type": "Title"
    },
    {
        "element_id": "bacd85fab48f645c6b465930060eec02",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        191.2,
                        1536.3
                    ],
                    [
                        191.2,
                        1569.6
                    ],
                    [
                        489.1,
                        1569.6
                    ],
                    [
                        489.1,
                        1536.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "Not(Move(Bullet, Loc3) or",
        "type": "Title"
    },
    {
        "element_id": "71b2ba2f257e01d5a546f2795ee5738c",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        191.2,
                        1575.2
                    ],
                    [
                        191.2,
                        1602.9
                    ],
                    [
                        593.5,
                        1602.9
                    ],
                    [
                        593.5,
                        1575.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "Not(Contact(Bullet, Player, Loc10))",
        "type": "Title"
    },
    {
        "element_id": "6b5be5518afa2ded065cb2156f55afd9",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        1085.0,
                        93.6
                    ],
                    [
                        1085.0,
                        118.5
                    ],
                    [
                        1110.3,
                        118.5
                    ],
                    [
                        1110.3,
                        93.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.37006,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9
        },
        "text": "33",
        "type": "Header"
    },
    {
        "element_id": "1fa8bd55d0de7d706a3dceeaaa7a607e",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        1075.0,
                        832.2
                    ],
                    [
                        1075.0,
                        865.8
                    ],
                    [
                        1110.2,
                        865.8
                    ],
                    [
                        1110.2,
                        832.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 9,
            "parent_id": "6b5be5518afa2ded065cb2156f55afd9"
        },
        "text": "\u00f02\u00de",
        "type": "Title"
    },
    {
        "element_id": "7f5faa9d99be2059dc7322f163b2033e",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        101.7,
                        93.6
                    ],
                    [
                        101.7,
                        118.5
                    ],
                    [
                        348.4,
                        118.5
                    ],
                    [
                        348.4,
                        93.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.60819,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 10
        },
        "text": "34 S.-B. Ho et al.",
        "type": "Header"
    },
    {
        "element_id": "fc29f0444a95a06fc3e67a0a72e549b2",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        106.7,
                        162.9
                    ],
                    [
                        106.7,
                        257.3
                    ],
                    [
                        1074.8,
                        257.3
                    ],
                    [
                        1074.8,
                        162.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9312,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 10,
            "parent_id": "7f5faa9d99be2059dc7322f163b2033e"
        },
        "text": "which means that any of the actions taken to negate the original events in the sequence is suf\ufb01cient to achieve a negation of Destroyed(Player, Loc10), which is the desired Goal of avoiding an undesired state.",
        "type": "NarrativeText"
    },
    {
        "element_id": "7d7ad7775be7c3dade274f873c1f696c",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        106.0,
                        262.9
                    ],
                    [
                        106.0,
                        788.7
                    ],
                    [
                        1075.2,
                        788.7
                    ],
                    [
                        1075.2,
                        262.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94997,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 10,
            "parent_id": "7f5faa9d99be2059dc7322f163b2033e"
        },
        "text": "The system then queries its Causal Rule and Script Base (CRSB) in Fig. 3 to see if there is any solution to effect at least one of the negations. If the system can make the Bullet not Appear, at Loc1, where it Appears in the shooting situation, that will lead to the non-destruction (Not(Destroyed)) of the Player. Or, if the system can Stop the Movement (Not(Move)) of one of the Bullets in any one of the locations Loc2, Loc3, etc., it will also be able to prevent the destruction of the Player (it is like a super-hero being able to stop a bullet in mid-\ufb02ight). The last choice is to achieve a Not(Contact (Bullet, Player, Loc10)). It turns out for the Space Invaders game, the only action available is to move the Player right or left, or to \ufb01re a bullet from the Player, none of which actions can immediately achieve any of the above negations. When the system encounters this situation of no available solutions from the CRSB, it will nevertheless try to emit any action at its disposal (this is built-in as a general \u201ctry anything to see if there is a solution\u201d procedure). It turns out that in this case by randomly emitting a sequence of left and right movements of the Player, a Not(Contact(Bullet, Player, Loc10)) can be achieved \u2013 typically by moving left or right by a few pixels. This involves a search process with a small state space.",
        "type": "NarrativeText"
    },
    {
        "element_id": "cf85af24fea4a6953ff373ddca88587f",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        102.9,
                        794.2
                    ],
                    [
                        102.9,
                        954.7
                    ],
                    [
                        1073.1,
                        954.7
                    ],
                    [
                        1073.1,
                        794.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.952,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 10,
            "parent_id": "7f5faa9d99be2059dc7322f163b2033e"
        },
        "text": "Therefore, in general, causal learning, unlike the traditional AI search processes, when used in problem solving, can arrive at problem solutions very rapidly. Though there may still be some search processes involved like in our example above, the search space is miniscule compared to those typically effected by traditional AI search pro- cesses, such as the A* search process.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9d15105f5d5fe76c5ef59fb0d4533406",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        110.2,
                        1015.6
                    ],
                    [
                        110.2,
                        1087.5
                    ],
                    [
                        1000.3,
                        1087.5
                    ],
                    [
                        1000.3,
                        1015.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84534,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 10,
            "parent_id": "7f5faa9d99be2059dc7322f163b2033e"
        },
        "text": "3 Results of Human-Like Performance Space Invaders Game Playing System",
        "type": "Title"
    },
    {
        "element_id": "4fb74210acd5500939e7a927820087f3",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        101.3,
                        1125.4
                    ],
                    [
                        101.3,
                        1219.5
                    ],
                    [
                        1072.7,
                        1219.5
                    ],
                    [
                        1072.7,
                        1125.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9324,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 10,
            "parent_id": "9d15105f5d5fe76c5ef59fb0d4533406"
        },
        "text": "The various causal learning, reasoning, and problem solving processes, including internal mental simulations processes (Fig. 3(b)), have been implemented and tested on the Space Invaders game. The results are shown in Fig. 6.",
        "type": "NarrativeText"
    },
    {
        "element_id": "b2b9d5d40e55604fc0ebe5a84726cf0b",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        106.0,
                        1225.1
                    ],
                    [
                        106.0,
                        1518.4
                    ],
                    [
                        1073.5,
                        1518.4
                    ],
                    [
                        1073.5,
                        1225.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95136,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 10,
            "parent_id": "9d15105f5d5fe76c5ef59fb0d4533406"
        },
        "text": "In Fig. 6, the results from 3 trials, starting from the beginning of a typical Space Invaders game, are shown along with (i) human novice performance; and (ii) DeepMind\u2019s deep reinforcement learning results, as reported in their paper [1], time-scaled based on the total number of video frames needed before certain perfor- mance is achieved (video frame is 30 frames per second). We also executed Deep- Mind\u2019s publicly accessible code to obtain its performance in the early part of the game \u2013 up to 20 h of play time. There is a level of score, about 200, when the Player shoots at random with no goal-directed behavior, and it is shown as a line labeled \u201cAvg Random Play\u201d.",
        "type": "NarrativeText"
    },
    {
        "element_id": "311646ee5d9abd0a69737cafdad659c6",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        107.3,
                        1518.0
                    ],
                    [
                        107.3,
                        1684.4
                    ],
                    [
                        1071.6,
                        1684.4
                    ],
                    [
                        1071.6,
                        1518.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94312,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 10,
            "parent_id": "9d15105f5d5fe76c5ef59fb0d4533406"
        },
        "text": "In the \ufb01rst two rounds of the game for the HLCLPSS, the actions generated by the Player are turned off to facilitate the learning of the basic causal rules (like an \u201cob- servation phase\u201d), so meaningful score data for HLCLPSS begins at around the 6 min time point. For the next four rounds of the game, the HLCLPSS carries out Player actions at random (moving and shooting), corresponding to an \u201cexploration phase\u201d",
        "type": "NarrativeText"
    },
    {
        "element_id": "5b6416898dc9c64417604cf11eeb8f8b",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        496.6,
                        88.2
                    ],
                    [
                        496.6,
                        118.8
                    ],
                    [
                        1110.3,
                        118.8
                    ],
                    [
                        1110.3,
                        88.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.65307,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 11,
            "parent_id": "9d15105f5d5fe76c5ef59fb0d4533406"
        },
        "text": "On Human-Like Performance Arti\ufb01cial Intelligence 35",
        "type": "ListItem"
    },
    {
        "element_id": "8b4130f4776ebc4a0f3f30152c033654",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        164.3,
                        165.4
                    ],
                    [
                        164.3,
                        817.3
                    ],
                    [
                        1095.6,
                        817.3
                    ],
                    [
                        1095.6,
                        165.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-11-7.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 11
        },
        "text": "\u2014 After 50 million ,* video frames Expert Human Level poe Data from DeepMind\u2019s paper w HLCLPSS Play 6 20,000 video frames O WA Fi After 10 million on \u015fe video frames Avg Novice Human Play 500 DeepMind\u2019s public code Avg Random Play ~ ee VA o GN 2min 20min 30min 10hr 20hr 2days 20days TIME H HLCLPSS Play",
        "type": "Image"
    },
    {
        "element_id": "be968464102dd3ea5239bfe28e392097",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        147.3,
                        847.7
                    ],
                    [
                        147.3,
                        933.6
                    ],
                    [
                        1117.6,
                        933.6
                    ],
                    [
                        1117.6,
                        847.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91922,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 11
        },
        "text": "Fig. 6. The results of the Human-like Causal Learning and Problem Solving System (HLCLPSS) applied to the Space Invaders game (3 trials), along with DeepMind\u2019s results (as reported in their paper [1]) for comparison.",
        "type": "FigureCaption"
    },
    {
        "element_id": "2d9d0379a7439192bbbacb54d3522d1b",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        148.5,
                        989.4
                    ],
                    [
                        148.5,
                        1216.4
                    ],
                    [
                        1115.3,
                        1216.4
                    ],
                    [
                        1115.3,
                        989.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95385,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 11
        },
        "text": "(in the same spirit as the exploration phase in reinforcement learning). At the end of these four rounds, typically enough \u201cgood\u201d causal rules and scripts are learned to play a successful game. Therefore, from round seventh onward (typically around the 15 min time point), the random action process is turned off and the HLCLPSS begins the process of problem solving and planning using the learned causal rules and scripts (the \u201cexploitation\u201d phase), and it can be seen in Fig. 6 that the score levels reach that of the novice player quite rapidly after that.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3aec74cb4a5996001575184cfa8f57cd",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        144.0,
                        1215.8
                    ],
                    [
                        144.0,
                        1382.4
                    ],
                    [
                        1116.6,
                        1382.4
                    ],
                    [
                        1116.6,
                        1215.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94821,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 11
        },
        "text": "It can be seen that our system\u2019s speed of learning is close to the order of magnitude of that of the human novice. In contrast with human novice though, we began with no prior knowledge of the game. Humans typically would have some fundamental prior knowledge relevant to the game when they begin to play it, thus they are able to learn at an even faster rate \u2013 typically in fewer than a few minutes.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d142231e4c3307ab13ca90352d26b18a",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        148.7,
                        1381.9
                    ],
                    [
                        148.7,
                        1448.8
                    ],
                    [
                        1116.6,
                        1448.8
                    ],
                    [
                        1116.6,
                        1381.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90901,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 11
        },
        "text": "Compared to DeepMind\u2019s deep reinforcement learning though, the HLCLPSS\u2019s speed of learning is obviously faster by many orders of magnitude.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ed1c6298a9b4d52efe073c67d31741c0",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        148.7,
                        1509.7
                    ],
                    [
                        148.7,
                        1542.9
                    ],
                    [
                        356.2,
                        1542.9
                    ],
                    [
                        356.2,
                        1509.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.86088,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 11
        },
        "text": "4 Conclusion",
        "type": "Title"
    },
    {
        "element_id": "ecc87e76f2e45fb1284b22236f5cd725",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        143.8,
                        1574.8
                    ],
                    [
                        143.8,
                        1675.0
                    ],
                    [
                        1121.0,
                        1675.0
                    ],
                    [
                        1121.0,
                        1574.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93734,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 11,
            "parent_id": "ed1c6298a9b4d52efe073c67d31741c0"
        },
        "text": "In this paper, we \ufb01rst de\ufb01ne what we mean by human-like performance AI, which is a system that is not only able to achieve human performance in terms of \u201clevel\u201d or \u201cscore\u201d (like the percentage accuracy in classi\ufb01cation or the game score in a computer game),",
        "type": "NarrativeText"
    },
    {
        "element_id": "97fa4eb6f43602e8a24793599e513584",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        102.3,
                        93.6
                    ],
                    [
                        102.3,
                        118.5
                    ],
                    [
                        348.5,
                        118.5
                    ],
                    [
                        348.5,
                        93.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.61257,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12
        },
        "text": "36 S.-B. Ho et al.",
        "type": "Header"
    },
    {
        "element_id": "a3e9c2ce6693dff387482299f4ae5535",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        109.1,
                        161.4
                    ],
                    [
                        109.1,
                        390.1
                    ],
                    [
                        1073.4,
                        390.1
                    ],
                    [
                        1073.4,
                        161.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95338,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "97fa4eb6f43602e8a24793599e513584"
        },
        "text": "but must also achieve the level or score in reasonably short, human-like time frame. Then we describe a causal learning and problem solving framework to demonstrate how, when applied to an Atari game Space Invaders, it is able to achieve human-like per- formance accordingly \u2013 achieving human-like game score in human-like time frame. The key idea behind the framework is the learning of the causalities taking place between different events, with \u201ctrue understanding.\u201d Explainability is an inherent property of the system right from the beginning.",
        "type": "NarrativeText"
    },
    {
        "element_id": "47876ffdb6ff8c1149ceb3bbe5865755",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        104.1,
                        395.7
                    ],
                    [
                        104.1,
                        523.0
                    ],
                    [
                        1075.3,
                        523.0
                    ],
                    [
                        1075.3,
                        395.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9343,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "97fa4eb6f43602e8a24793599e513584"
        },
        "text": "We believe the general framework of causal learning and problem solving as depicted in Fig. 3 and demonstrated in this paper using Space Invaders has a general applicability to the situations that could be encountered by an AI or robotic system discussed in the Introduction section.",
        "type": "NarrativeText"
    },
    {
        "element_id": "b5fe616b4ee52089d4162a92a84a9601",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        110.2,
                        528.6
                    ],
                    [
                        110.2,
                        655.8
                    ],
                    [
                        1071.2,
                        655.8
                    ],
                    [
                        1071.2,
                        528.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94423,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "97fa4eb6f43602e8a24793599e513584"
        },
        "text": "What have demonstrated in this paper is the ability of the system to reach human- like performance at the human novice level. We are currently continuing to enrich the basic framework of Fig. 3 to allow the system to reach human expert level perfor- mance, within human-like learning time frames.",
        "type": "NarrativeText"
    },
    {
        "element_id": "17dcfe80cefe53e478348b26ec7e400c",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        100.8,
                        661.3
                    ],
                    [
                        100.8,
                        755.4
                    ],
                    [
                        1077.3,
                        755.4
                    ],
                    [
                        1077.3,
                        661.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93181,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "97fa4eb6f43602e8a24793599e513584"
        },
        "text": "Future research will apply the basic system to more Atari games to further explore some fundamental issues, as well as to apply the basic causal learning and problem solving framework to real world robotic situations.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c786ffd26e4d18b56b449383d0ecc4b1",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        107.8,
                        820.3
                    ],
                    [
                        107.8,
                        853.5
                    ],
                    [
                        266.1,
                        853.5
                    ],
                    [
                        266.1,
                        820.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.8726,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "97fa4eb6f43602e8a24793599e513584"
        },
        "text": "References",
        "type": "Title"
    },
    {
        "element_id": "caa9e39912f3b0fef195df978c78dd21",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        118.4,
                        887.9
                    ],
                    [
                        118.4,
                        948.7
                    ],
                    [
                        1073.7,
                        948.7
                    ],
                    [
                        1073.7,
                        887.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9039,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "c786ffd26e4d18b56b449383d0ecc4b1"
        },
        "text": "1. Mnih, V., et al.: Human-level control through deep reinforcement learning. Nature 518, 529\u2013 533 (2015)",
        "type": "ListItem"
    },
    {
        "element_id": "a8d6193be30d3524d8aaeb41b7ed8653",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        121.4,
                        953.6
                    ],
                    [
                        121.4,
                        1010.0
                    ],
                    [
                        1079.7,
                        1010.0
                    ],
                    [
                        1079.7,
                        953.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89758,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "c786ffd26e4d18b56b449383d0ecc4b1"
        },
        "text": "2. Tsividis, P.A., Pouncy, T., Xu, J.L., Tenenbaum, J.B., Gershman, S.J.: Human learning in Atari. In: AAAI Spring Symposium Technical Report, pp. 643\u2013646. AAAI, Palo Alto (2017)",
        "type": "ListItem"
    },
    {
        "element_id": "4b1d2e39271c41edf074a3744303c89f",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        123.0,
                        1014.4
                    ],
                    [
                        123.0,
                        1070.4
                    ],
                    [
                        1080.1,
                        1070.4
                    ],
                    [
                        1080.1,
                        1014.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.85866,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "c786ffd26e4d18b56b449383d0ecc4b1"
        },
        "text": "3. Silver, D., et al.: Mastering the game of Go with deep neural networks and tree search. Nature 529(28), 484\u2013489 (2016). https://doi.org/10.1038/nature16961",
        "type": "ListItem"
    },
    {
        "element_id": "644aa1675e2e92ed8d0079acd3763460",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        117.2,
                        1075.6
                    ],
                    [
                        117.2,
                        1131.4
                    ],
                    [
                        1082.6,
                        1131.4
                    ],
                    [
                        1082.6,
                        1075.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90353,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "c786ffd26e4d18b56b449383d0ecc4b1"
        },
        "text": "4. Fire, A., Zhu, S.-C.: Learning perceptual causality from video. ACM Trans. Intell. Syst. Technol. 7(2), 23 (2012)",
        "type": "ListItem"
    },
    {
        "element_id": "abc105b813d0ad8cad15bd72fd61526d",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        119.8,
                        1136.9
                    ],
                    [
                        119.8,
                        1222.6
                    ],
                    [
                        1083.5,
                        1222.6
                    ],
                    [
                        1083.5,
                        1136.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93513,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "c786ffd26e4d18b56b449383d0ecc4b1"
        },
        "text": "5. Fire, A., Zhu, S.-C.: Inferring hidden statuses and actions in video by causal reasoning. In: IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 9\u201316. IEEE Press, Piscataway, New Jersey (2017)",
        "type": "ListItem"
    },
    {
        "element_id": "9b1f3f3016304d5206ccab40013955b3",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        119.5,
                        1227.9
                    ],
                    [
                        119.5,
                        1313.9
                    ],
                    [
                        1080.3,
                        1313.9
                    ],
                    [
                        1080.3,
                        1227.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93023,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "c786ffd26e4d18b56b449383d0ecc4b1"
        },
        "text": "6. Ho, S.-B.: On effective causal learning. In: Goertzel, B., Orseau, L., Snaider, J. (eds.) AGI 2014. LNCS (LNAI), vol. 8598, pp. 43\u201352. Springer, Cham (2014). https://doi.org/10.1007/ 978-3-319-09274-4_5",
        "type": "ListItem"
    },
    {
        "element_id": "345a90eddc7d6c3e3895b4008e93bcc3",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        116.2,
                        1319.5
                    ],
                    [
                        116.2,
                        1374.8
                    ],
                    [
                        1082.0,
                        1374.8
                    ],
                    [
                        1082.0,
                        1319.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90723,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "c786ffd26e4d18b56b449383d0ecc4b1"
        },
        "text": "7. Ho, S.-B.: Principles of Noology: Toward a Theory and Science of Intelligence. SC, vol. 3. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-32113-4",
        "type": "ListItem"
    },
    {
        "element_id": "7dd1a265715eb3a9ed7e1297d8cf2fd0",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        116.4,
                        1378.9
                    ],
                    [
                        116.4,
                        1435.8
                    ],
                    [
                        1082.5,
                        1435.8
                    ],
                    [
                        1082.5,
                        1378.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90898,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "c786ffd26e4d18b56b449383d0ecc4b1"
        },
        "text": "8. Ho, S.-B.: Deep thinking and quick learning for viable AI. In: Proceedings of the Future Technologies Conference, pp. 156\u2013164. IEEE Press, Piscataway (2016)",
        "type": "ListItem"
    },
    {
        "element_id": "00c25f058c93226ca1672e6f36fe6e80",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        117.5,
                        1441.3
                    ],
                    [
                        117.5,
                        1527.1
                    ],
                    [
                        1080.6,
                        1527.1
                    ],
                    [
                        1080.6,
                        1441.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93323,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "c786ffd26e4d18b56b449383d0ecc4b1"
        },
        "text": "9. Ho, S.-B.: The role of synchronic causal conditions in visual knowledge learning. In: IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 9\u201316. IEEE Press, Piscataway (2017)",
        "type": "ListItem"
    },
    {
        "element_id": "eeae1e27936cf6e935fd2dec4cf22d16",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        110.6,
                        1532.6
                    ],
                    [
                        110.6,
                        1618.3
                    ],
                    [
                        1083.4,
                        1618.3
                    ],
                    [
                        1083.4,
                        1532.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93236,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 12,
            "parent_id": "c786ffd26e4d18b56b449383d0ecc4b1"
        },
        "text": "10. Ho, S.-B., Liausvia, F.: A ground level causal learning algorithm. In: Proceedings of the IEEE Symposium Series on Computational Intelligence for Human-like Intelligence, pp. 110\u2013117. IEEE Press, Piscataway (2016)",
        "type": "ListItem"
    },
    {
        "element_id": "d60ba5111ceff8370379f24e36bca40a",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        500.2,
                        88.2
                    ],
                    [
                        500.2,
                        118.5
                    ],
                    [
                        1019.6,
                        118.5
                    ],
                    [
                        1019.6,
                        88.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 13,
            "parent_id": "97fa4eb6f43602e8a24793599e513584"
        },
        "text": "On Human-Like Performance Arti\ufb01cial Intelligence",
        "type": "Title"
    },
    {
        "element_id": "b6f4ee8931a3941a66f2383e55f84a70",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        147.3,
                        161.7
                    ],
                    [
                        147.3,
                        249.2
                    ],
                    [
                        1116.3,
                        249.2
                    ],
                    [
                        1116.3,
                        161.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92885,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 13,
            "parent_id": "d60ba5111ceff8370379f24e36bca40a"
        },
        "text": "11. Ho, S.-B., Liausvia, F.: On inductive learning of causal knowledge for problem solving. In: Technical Reports of the Workshops of the 31st AAAI Conference on Arti\ufb01cial Intelligence, pp. 735\u2013742. AAAI, Palo Alto, California (2017)",
        "type": "ListItem"
    },
    {
        "element_id": "0d08c1568c00754eb3811aca5790880d",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        147.7,
                        254.4
                    ],
                    [
                        147.7,
                        310.1
                    ],
                    [
                        1114.8,
                        310.1
                    ],
                    [
                        1114.8,
                        254.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90517,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 13,
            "parent_id": "d60ba5111ceff8370379f24e36bca40a"
        },
        "text": "12. Pearl, J.: The Book of Why: The New Science of Cause and Effect. Basic Books, New York (2018)",
        "type": "ListItem"
    },
    {
        "element_id": "255de86a68860785b5195b70a55bbed0",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.9,
                        315.6
                    ],
                    [
                        149.9,
                        401.5
                    ],
                    [
                        1121.0,
                        401.5
                    ],
                    [
                        1121.0,
                        315.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92356,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 13,
            "parent_id": "d60ba5111ceff8370379f24e36bca40a"
        },
        "text": "13. Neyman, J.: Sur les applications de la theorie des probabilites aux experiences agricoles: Essai des principes. Master\u2019s Thesis. Excerpts reprinted in English, Statistical Science, vol. 5, pp. 463\u2013472 (1923). (D. M. Dabrowska, and T. P. Speed, Translators.)",
        "type": "ListItem"
    },
    {
        "element_id": "847fc8e6b39f0fd4346c5381c1570bcb",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        148.1,
                        401.5
                    ],
                    [
                        148.1,
                        462.3
                    ],
                    [
                        1116.1,
                        462.3
                    ],
                    [
                        1116.1,
                        401.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90452,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 13,
            "parent_id": "d60ba5111ceff8370379f24e36bca40a"
        },
        "text": "14. Rubin, D.: Causal inference using potential outcomees. J. Am. Stat. Assoc. 100(496), 321\u2013 322 (2005). https://doi.org/10.1198/016214504000001880",
        "type": "ListItem"
    },
    {
        "element_id": "0e1f2c839e5b602c8ca67f9cd08201ce",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.2,
                        467.9
                    ],
                    [
                        149.2,
                        584.0
                    ],
                    [
                        1118.4,
                        584.0
                    ],
                    [
                        1118.4,
                        467.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93015,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 13,
            "parent_id": "d60ba5111ceff8370379f24e36bca40a"
        },
        "text": "15. Ho, S.-B., Edmonds, M., Zhu, S.-C.: Actional-perceptual causality: concepts and inductive learning for ai and robotics. Presented at the workshop on perspectives on robot learning: imitation and causality, robotics: science and systems conference, Carnegie Mellon University, Pittsburgh, Pennsylvania (2018)",
        "type": "ListItem"
    },
    {
        "element_id": "491c6f6addb91d374a9fbaab302c2160",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        149.1,
                        589.6
                    ],
                    [
                        149.1,
                        675.3
                    ],
                    [
                        1116.8,
                        675.3
                    ],
                    [
                        1116.8,
                        589.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9297,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 13,
            "parent_id": "d60ba5111ceff8370379f24e36bca40a"
        },
        "text": "16. Yang, X., Ho, S.-B.: Learning correlations and causality through an inductive bootstrapping process. In: IEEE Symposium on Computational Intelligence. IEEE Press, Piscataway, (2018)",
        "type": "ListItem"
    },
    {
        "element_id": "d17aec136c04878a728e7e604cd6ecde",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        146.9,
                        681.0
                    ],
                    [
                        146.9,
                        736.3
                    ],
                    [
                        1113.9,
                        736.3
                    ],
                    [
                        1113.9,
                        681.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92027,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 13,
            "parent_id": "d60ba5111ceff8370379f24e36bca40a"
        },
        "text": "17. Newell, A., Shaw, J.C., Simon, H.A.: Report on a general problem-solving program. In: Proceedings of the International Conference on Information Processing, pp. 256\u2013264 (1959)",
        "type": "ListItem"
    },
    {
        "element_id": "34b8e5907db4f40ead81ecf9b285cddf",
        "metadata": {
            "coordinates": {
                "layout_height": 1851,
                "layout_width": 1221,
                "points": [
                    [
                        1084.8,
                        93.6
                    ],
                    [
                        1084.8,
                        118.5
                    ],
                    [
                        1110.3,
                        118.5
                    ],
                    [
                        1110.3,
                        93.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.36023,
            "file_directory": "./uol-docs",
            "filename": "978-3-030-24265-7_3.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:10:54",
            "page_number": 13
        },
        "text": "37",
        "type": "Header"
    }
]