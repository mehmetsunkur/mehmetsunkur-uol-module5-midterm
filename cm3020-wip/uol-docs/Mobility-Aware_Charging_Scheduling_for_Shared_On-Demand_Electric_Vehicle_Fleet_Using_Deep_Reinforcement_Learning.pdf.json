[
    {
        "element_id": "6ddfba804f4e3aacd1d38125c243f296",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        131.4,
                        79.3
                    ],
                    [
                        131.4,
                        103.7
                    ],
                    [
                        178.7,
                        103.7
                    ],
                    [
                        178.7,
                        79.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80698,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1
        },
        "text": "1380",
        "type": "Header"
    },
    {
        "element_id": "13ed321ba2bb921642c5477f0834fb25",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        933.1,
                        82.5
                    ],
                    [
                        933.1,
                        102.2
                    ],
                    [
                        1564.0,
                        102.2
                    ],
                    [
                        1564.0,
                        82.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87422,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1
        },
        "text": "IEEE TRANSACTIONS ON SMART GRID, VOL. 12, NO. 2, MARCH 2021",
        "type": "Header"
    },
    {
        "element_id": "e8cf9502d27a68d7ecb4e00fcded1c13",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        162.5,
                        162.9
                    ],
                    [
                        162.5,
                        385.0
                    ],
                    [
                        1513.8,
                        385.0
                    ],
                    [
                        1513.8,
                        162.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73753,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "Mobility-Aware Charging Scheduling for Shared On-Demand Electric Vehicle Fleet Using Deep Reinforcement Learning",
        "type": "Title"
    },
    {
        "element_id": "5f148528ae4839c3d01d8fc75181a4d1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        323.4,
                        410.3
                    ],
                    [
                        323.4,
                        486.2
                    ],
                    [
                        1380.7,
                        486.2
                    ],
                    [
                        1380.7,
                        410.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.62978,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "e8cf9502d27a68d7ecb4e00fcded1c13"
        },
        "text": "Yanchang Liang , Student Member, IEEE, Zhaohao Ding , Senior Member, IEEE, Tao Ding , Senior Member, IEEE, and Wei-Jen Lee , Fellow, IEEE",
        "type": "NarrativeText"
    },
    {
        "element_id": "ce5f108454b0fc8ebea886f1dd6c29af",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        133.7,
                        583.2
                    ],
                    [
                        133.7,
                        1161.6
                    ],
                    [
                        836.6,
                        1161.6
                    ],
                    [
                        836.6,
                        583.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94946,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "e8cf9502d27a68d7ecb4e00fcded1c13"
        },
        "text": "Abstract\u2014With the emerging concept of sharing-economy, shared electric vehicles (EVs) are playing a more and more important role in future mobility-on-demand traf\ufb01c system. This article considers joint charging scheduling, order dispatching, and vehicle rebalancing for large-scale shared EV \ufb02eet operator. To maximize the welfare of \ufb02eet operator, we model the joint decision making as a partially observable Markov decision pro- cess (POMDP) and apply deep reinforcement learning (DRL) combined with binary linear programming (BLP) to develop a near-optimal solution. The neural network is used to evaluate the state value of EVs at different times, locations, and states of charge. Based on the state value, dynamic electricity prices and order information, the online scheduling is modeled as a BLP problem where the decision variables representing whether an EV will 1) take an order, 2) rebalance to a position, or 3) charge. We also propose a constrained rebalancing method to improve the exploration ef\ufb01ciency of training. Moreover, we provide a tabular method with proved convergence as a fallback option to demon- strate the near-optimal characteristics of the proposed approach. Simulation experiments with real-world data from Haikou City verify the effectiveness of the proposed method.",
        "type": "NarrativeText"
    },
    {
        "element_id": "5a7346f2072233417914f6d2e95523b8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1179.8
                    ],
                    [
                        136.0,
                        1232.4
                    ],
                    [
                        833.4,
                        1232.4
                    ],
                    [
                        833.4,
                        1179.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91482,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "e8cf9502d27a68d7ecb4e00fcded1c13"
        },
        "text": "Index Terms\u2014Electric vehicle, deep reinforcement learning, order dispatching, rebalancing, charging scheduling.",
        "type": "NarrativeText"
    },
    {
        "element_id": "0f920bea6a4b65b49e8d8f3143baeff8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        580.8
                    ],
                    [
                        894.3,
                        608.7
                    ],
                    [
                        1300.2,
                        608.7
                    ],
                    [
                        1300.2,
                        580.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.59199,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "e8cf9502d27a68d7ecb4e00fcded1c13"
        },
        "text": "MDP Markov decision process",
        "type": "ListItem"
    },
    {
        "element_id": "f336203fd68ff4fad0d76478234cb6cb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        614.3
                    ],
                    [
                        894.3,
                        641.9
                    ],
                    [
                        1524.3,
                        641.9
                    ],
                    [
                        1524.3,
                        614.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74247,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "e8cf9502d27a68d7ecb4e00fcded1c13"
        },
        "text": "POMDP Partially observable Markov decision process",
        "type": "ListItem"
    },
    {
        "element_id": "64584edd0785c950966c3058638cd247",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        647.4
                    ],
                    [
                        894.3,
                        675.1
                    ],
                    [
                        1277.3,
                        675.1
                    ],
                    [
                        1277.3,
                        647.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.68259,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "e8cf9502d27a68d7ecb4e00fcded1c13"
        },
        "text": "REV Revenue-based method",
        "type": "ListItem"
    },
    {
        "element_id": "c93f5b03d0d2f954d84e7e7f549ef160",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        887.9,
                        680.7
                    ],
                    [
                        887.9,
                        708.4
                    ],
                    [
                        1276.4,
                        708.4
                    ],
                    [
                        1276.4,
                        680.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73882,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "e8cf9502d27a68d7ecb4e00fcded1c13"
        },
        "text": "RL Reinforcement learning",
        "type": "ListItem"
    },
    {
        "element_id": "3ac2d8170bddaa72f3a6a740b205aaa7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        891.1,
                        713.3
                    ],
                    [
                        891.1,
                        741.6
                    ],
                    [
                        1188.8,
                        741.6
                    ],
                    [
                        1188.8,
                        713.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.56667,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "e8cf9502d27a68d7ecb4e00fcded1c13"
        },
        "text": "SOC State of charge",
        "type": "ListItem"
    },
    {
        "element_id": "dd418c4344880557c1438bba90db3c95",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        887.9,
                        747.1
                    ],
                    [
                        887.9,
                        774.8
                    ],
                    [
                        1247.8,
                        774.8
                    ],
                    [
                        1247.8,
                        747.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.66851,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "e8cf9502d27a68d7ecb4e00fcded1c13"
        },
        "text": "TD Temporal-difference.",
        "type": "ListItem"
    },
    {
        "element_id": "14f21b714d0912768bb048f4d6baf612",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        814.4
                    ],
                    [
                        866.6,
                        842.6
                    ],
                    [
                        1053.5,
                        842.6
                    ],
                    [
                        1053.5,
                        814.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73292,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "e8cf9502d27a68d7ecb4e00fcded1c13"
        },
        "text": "Sets and Indices",
        "type": "NarrativeText"
    },
    {
        "element_id": "4646441fc78dfe0d355f68916096b5a9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        850.8
                    ],
                    [
                        894.3,
                        887.2
                    ],
                    [
                        939.7,
                        887.2
                    ],
                    [
                        939.7,
                        850.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "Ag,t",
        "type": "Title"
    },
    {
        "element_id": "e37ea247820a0a45ce98ec0155867d9b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        903.1,
                        856.8
                    ],
                    [
                        903.1,
                        884.5
                    ],
                    [
                        1439.0,
                        884.5
                    ],
                    [
                        1439.0,
                        856.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.65475,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "4646441fc78dfe0d355f68916096b5a9"
        },
        "text": "Action space in grid g at time step t",
        "type": "ListItem"
    },
    {
        "element_id": "2ef373de64571b50db88c68f51dc13d3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        890.8,
                        884.1
                    ],
                    [
                        890.8,
                        917.7
                    ],
                    [
                        1525.6,
                        917.7
                    ],
                    [
                        1525.6,
                        884.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.66579,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "4646441fc78dfe0d355f68916096b5a9"
        },
        "text": "G Set of grids {1, 2, . . . , G} indexed by g, h",
        "type": "ListItem"
    },
    {
        "element_id": "c382b47194e1240bc503f80ad333614b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        889.3,
                        917.3
                    ],
                    [
                        889.3,
                        950.9
                    ],
                    [
                        1543.8,
                        950.9
                    ],
                    [
                        1543.8,
                        917.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.71562,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "4646441fc78dfe0d355f68916096b5a9"
        },
        "text": "Set of grids equipped with chargers, Gch \u2286 G",
        "type": "ListItem"
    },
    {
        "element_id": "b84dccb942a50c3ba5f4154f528c8dfa",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        880.4,
                        950.5
                    ],
                    [
                        880.4,
                        1017.4
                    ],
                    [
                        1564.0,
                        1017.4
                    ],
                    [
                        1564.0,
                        950.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84111,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "4646441fc78dfe0d355f68916096b5a9"
        },
        "text": "Ig,t Set of available EVs {1, 2, . . . , Ig,t} indexed by j in grid g at time step t",
        "type": "ListItem"
    },
    {
        "element_id": "709381b4a1860e5975746ad5b86f0f6a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        878.5,
                        1016.9
                    ],
                    [
                        878.5,
                        1083.8
                    ],
                    [
                        1564.0,
                        1083.8
                    ],
                    [
                        1564.0,
                        1016.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72551,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "4646441fc78dfe0d355f68916096b5a9"
        },
        "text": "Jg,t Set of available dispatches {1, 2, . . . , Jg,t} indexed by j in grid g at time step t",
        "type": "ListItem"
    },
    {
        "element_id": "a28b8da581fc4bc5ed0deb016defee39",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        1083.3
                    ],
                    [
                        894.3,
                        1111.0
                    ],
                    [
                        938.0,
                        1111.0
                    ],
                    [
                        938.0,
                        1083.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "J ch",
        "type": "Title"
    },
    {
        "element_id": "872218c00afa98434aaba91a766074a7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        896.0,
                        1086.0
                    ],
                    [
                        896.0,
                        1122.0
                    ],
                    [
                        937.0,
                        1122.0
                    ],
                    [
                        937.0,
                        1086.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "If",
        "type": "Title"
    },
    {
        "element_id": "2d668e2b081330493483846693ed6458",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        913.0,
                        1097.4
                    ],
                    [
                        913.0,
                        1123.0
                    ],
                    [
                        936.3,
                        1123.0
                    ],
                    [
                        936.3,
                        1097.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "g,t",
        "type": "Title"
    },
    {
        "element_id": "85e72c6707f0ca110bee02e88916f0d7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        1116.5
                    ],
                    [
                        894.3,
                        1144.2
                    ],
                    [
                        935.7,
                        1144.2
                    ],
                    [
                        935.7,
                        1116.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "J or",
        "type": "Title"
    },
    {
        "element_id": "1285b4f63942518f2f50b031b029f259",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        913.0,
                        1130.6
                    ],
                    [
                        913.0,
                        1156.2
                    ],
                    [
                        936.3,
                        1156.2
                    ],
                    [
                        936.3,
                        1130.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "g,t",
        "type": "Title"
    },
    {
        "element_id": "7c2c0527d031ef77f7c724d91f394d3d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        1149.7
                    ],
                    [
                        894.3,
                        1177.4
                    ],
                    [
                        934.5,
                        1177.4
                    ],
                    [
                        934.5,
                        1149.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "J re",
        "type": "Title"
    },
    {
        "element_id": "4aaf36cb2457758f4147f817f4fdd2d7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        913.0,
                        1163.8
                    ],
                    [
                        913.0,
                        1189.4
                    ],
                    [
                        936.3,
                        1189.4
                    ],
                    [
                        936.3,
                        1163.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "g,t",
        "type": "Title"
    },
    {
        "element_id": "6dac3acb4dce3f71db60937279b1ee58",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1010.9,
                        1083.3
                    ],
                    [
                        1010.9,
                        1117.0
                    ],
                    [
                        1370.3,
                        1117.0
                    ],
                    [
                        1370.3,
                        1083.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "4aaf36cb2457758f4147f817f4fdd2d7"
        },
        "text": "Set of charging dispatches, J ch",
        "type": "NarrativeText"
    },
    {
        "element_id": "17c89ec1c38a7b423a3e34d39daab2dd",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1379.4,
                        1083.3
                    ],
                    [
                        1379.4,
                        1119.7
                    ],
                    [
                        1450.7,
                        1119.7
                    ],
                    [
                        1450.7,
                        1083.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "\u2286 Jg,t",
        "type": "Title"
    },
    {
        "element_id": "4978e9fd0087142f6c4f5b070971d9d1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1345.3,
                        1097.4
                    ],
                    [
                        1345.3,
                        1123.0
                    ],
                    [
                        1368.6,
                        1123.0
                    ],
                    [
                        1368.6,
                        1097.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "g,t",
        "type": "Title"
    },
    {
        "element_id": "1ac7417ebe6f5e09877bb8f655922a8b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1010.9,
                        1116.5
                    ],
                    [
                        1010.9,
                        1150.2
                    ],
                    [
                        1330.0,
                        1150.2
                    ],
                    [
                        1330.0,
                        1116.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "Set of order dispatches, J or",
        "type": "Title"
    },
    {
        "element_id": "0cb3f3a47f54f54b19ef2a8bc6e38b4c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1340.2,
                        1116.5
                    ],
                    [
                        1340.2,
                        1152.9
                    ],
                    [
                        1411.5,
                        1152.9
                    ],
                    [
                        1411.5,
                        1116.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "\u2286 Jg,t",
        "type": "Title"
    },
    {
        "element_id": "49ae8d64b2e52c56be76a0c7f481224b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1307.4,
                        1130.6
                    ],
                    [
                        1307.4,
                        1156.2
                    ],
                    [
                        1330.7,
                        1156.2
                    ],
                    [
                        1330.7,
                        1130.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "g,t",
        "type": "Title"
    },
    {
        "element_id": "897d6ef4b4f8b9706889a1e92224920b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1010.9,
                        1149.7
                    ],
                    [
                        1010.9,
                        1183.4
                    ],
                    [
                        1399.5,
                        1183.4
                    ],
                    [
                        1399.5,
                        1149.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "49ae8d64b2e52c56be76a0c7f481224b"
        },
        "text": "Set of rebalancing dispatches, J re",
        "type": "NarrativeText"
    },
    {
        "element_id": "a4f1d1f77f8e2081b5a51404bdca4c6f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1410.9,
                        1149.7
                    ],
                    [
                        1410.9,
                        1186.1
                    ],
                    [
                        1482.2,
                        1186.1
                    ],
                    [
                        1482.2,
                        1149.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "\u2286 Jg,t",
        "type": "Title"
    },
    {
        "element_id": "105bb4294cdef1ed4265ded706034ed9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1378.1,
                        1163.8
                    ],
                    [
                        1378.1,
                        1189.4
                    ],
                    [
                        1401.4,
                        1189.4
                    ],
                    [
                        1401.4,
                        1163.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "g,t",
        "type": "Title"
    },
    {
        "element_id": "74493f4672d27ddd44644f92258b88b2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        1188.9
                    ],
                    [
                        894.3,
                        1216.6
                    ],
                    [
                        902.0,
                        1216.6
                    ],
                    [
                        902.0,
                        1188.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "t",
        "type": "Title"
    },
    {
        "element_id": "2fa61ca2fce650cc0c70d1b683275ff9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1010.9,
                        1188.9
                    ],
                    [
                        1010.9,
                        1216.6
                    ],
                    [
                        1246.3,
                        1216.6
                    ],
                    [
                        1246.3,
                        1188.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "Index for time steps.",
        "type": "Title"
    },
    {
        "element_id": "b2387cd0288d2bb9761f01723edc704a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        865.3,
                        1255.6
                    ],
                    [
                        865.3,
                        1284.4
                    ],
                    [
                        995.7,
                        1284.4
                    ],
                    [
                        995.7,
                        1255.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.56043,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "Parameters",
        "type": "Title"
    },
    {
        "element_id": "6e5d64f0dc426b2eb1cfb8dcc7ec9013",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        382.0,
                        1322.0
                    ],
                    [
                        382.0,
                        1349.7
                    ],
                    [
                        590.5,
                        1349.7
                    ],
                    [
                        590.5,
                        1322.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.55833,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b2387cd0288d2bb9761f01723edc704a"
        },
        "text": "NOMENCLATURE",
        "type": "NarrativeText"
    },
    {
        "element_id": "fcb01c5c89b62cf2cee8b74c2b62399f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1363.9
                    ],
                    [
                        136.0,
                        1391.6
                    ],
                    [
                        246.2,
                        1391.6
                    ],
                    [
                        246.2,
                        1363.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.67442,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b2387cd0288d2bb9761f01723edc704a"
        },
        "text": "Acronyms",
        "type": "NarrativeText"
    },
    {
        "element_id": "eb9c1ebfaba5d3cfead6776705ada086",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        1405.8
                    ],
                    [
                        163.7,
                        1433.5
                    ],
                    [
                        214.4,
                        1433.5
                    ],
                    [
                        214.4,
                        1405.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "BLP",
        "type": "Title"
    },
    {
        "element_id": "883a8432b71d7e27b7e591beb4b9794d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        174.7,
                        1405.6
                    ],
                    [
                        174.7,
                        1433.5
                    ],
                    [
                        588.6,
                        1433.5
                    ],
                    [
                        588.6,
                        1405.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.29537,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "eb9c1ebfaba5d3cfead6776705ada086"
        },
        "text": "Binary linear programming",
        "type": "ListItem"
    },
    {
        "element_id": "a97bddd68293cc755f9052e6f454713c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        160.4,
                        1439.0
                    ],
                    [
                        160.4,
                        1466.7
                    ],
                    [
                        564.1,
                        1466.7
                    ],
                    [
                        564.1,
                        1439.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.35893,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "eb9c1ebfaba5d3cfead6776705ada086"
        },
        "text": "CR Constrained rebalancing",
        "type": "ListItem"
    },
    {
        "element_id": "c83a36577564eecf661a4390c42dc499",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        1472.2
                    ],
                    [
                        163.7,
                        1499.9
                    ],
                    [
                        603.9,
                        1499.9
                    ],
                    [
                        603.9,
                        1472.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.41416,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "eb9c1ebfaba5d3cfead6776705ada086"
        },
        "text": "DRL Deep reinforcement learning",
        "type": "ListItem"
    },
    {
        "element_id": "8c4e1aabc89185920f5ccc04932a1849",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        153.3,
                        1505.5
                    ],
                    [
                        153.3,
                        1533.1
                    ],
                    [
                        462.8,
                        1533.1
                    ],
                    [
                        462.8,
                        1505.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.35346,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "eb9c1ebfaba5d3cfead6776705ada086"
        },
        "text": "EV Electric vehicle",
        "type": "NarrativeText"
    },
    {
        "element_id": "64d4f14b807b1f9121f07daa8264f3d5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        1293.5
                    ],
                    [
                        894.3,
                        1326.4
                    ],
                    [
                        921.2,
                        1326.4
                    ],
                    [
                        921.2,
                        1293.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "Ire",
        "type": "Title"
    },
    {
        "element_id": "048be77fe2d8aafe4262aba9a95d9eb7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        893.8,
                        1297.7
                    ],
                    [
                        893.8,
                        1562.7
                    ],
                    [
                        1565.0,
                        1562.7
                    ],
                    [
                        1565.0,
                        1297.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.42759,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-1-1.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "64d4f14b807b1f9121f07daa8264f3d5",
            "text_as_html": "<table><tbody><tr><td>Number of step /</td><td>EVs rebalanced</td><td>from g to h at time</td></tr></tbody></table>"
        },
        "text": "g\u2192h,t Number of EVs rebalanced from g to h at time step t Iin-ch g,t Jor g,t Number of EVs being charged in g at time step t Number of order dispatches in g at time step t lj Nch g pch g,t por Destination of dispatch j Total number of chargers in grid g Charging price of grid g at time step t Price of order dispatch j.",
        "type": "Table"
    },
    {
        "element_id": "b1f04691b4f3cb341528a98f5834e2db",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1564.4
                    ],
                    [
                        136.0,
                        1761.5
                    ],
                    [
                        834.2,
                        1761.5
                    ],
                    [
                        834.2,
                        1564.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94794,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "64d4f14b807b1f9121f07daa8264f3d5"
        },
        "text": "Manuscript received April 10, 2020; revised August 1, 2020; accepted September 9, 2020. Date of publication September 21, 2020; date of cur- rent version February 26, 2021. This work was supported in part by the National Natural Science Foundation of China under Grant 51907063; in part by the Fundamental Research Funds for the Central Universities under Grant 2019MS054; and in part by the Support Program for the Excellent Talents in Beijing City under Grant X19048. Paper no. TSG-00531-2020. (Corresponding author: Zhaohao Ding.)",
        "type": "NarrativeText"
    },
    {
        "element_id": "ad752fc412fe5f832b1c5d7cf4f46690",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1764.3
                    ],
                    [
                        136.0,
                        1861.2
                    ],
                    [
                        834.4,
                        1861.2
                    ],
                    [
                        834.4,
                        1764.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93699,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "64d4f14b807b1f9121f07daa8264f3d5"
        },
        "text": "Yanchang Liang and Zhaohao Ding are with the School Electrical and Electronic Engineering, North China Electric Power University, Beijing 102206, China (e-mail: liangyancang@gmail.com; zhaohao.ding@ncepu.edu.cn). of",
        "type": "NarrativeText"
    },
    {
        "element_id": "dea005f36f1c789db5fd3a3213ce6be2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1863.9
                    ],
                    [
                        136.0,
                        1911.0
                    ],
                    [
                        834.8,
                        1911.0
                    ],
                    [
                        834.8,
                        1863.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90362,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "64d4f14b807b1f9121f07daa8264f3d5"
        },
        "text": "Tao Ding is with the Department of Electrical Engineering, Xi\u2019an Jiaotong University, Xi\u2019an 710049, China (e-mail: tding15@xjtu.edu.cn).",
        "type": "NarrativeText"
    },
    {
        "element_id": "b3340798e34c9a04ef3e3b9548eab317",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        908.1,
                        1547.6
                    ],
                    [
                        908.1,
                        1568.7
                    ],
                    [
                        913.9,
                        1568.7
                    ],
                    [
                        913.9,
                        1547.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "j",
        "type": "Title"
    },
    {
        "element_id": "7a81d3a1408748711e7decd084b43431",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1599.5
                    ],
                    [
                        866.6,
                        1629.5
                    ],
                    [
                        972.4,
                        1629.5
                    ],
                    [
                        972.4,
                        1599.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.58762,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b3340798e34c9a04ef3e3b9548eab317"
        },
        "text": "Variables",
        "type": "NarrativeText"
    },
    {
        "element_id": "91073454ab75867aba518defaae6f827",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        884.5,
                        1642.7
                    ],
                    [
                        884.5,
                        1704.6
                    ],
                    [
                        1564.0,
                        1704.6
                    ],
                    [
                        1564.0,
                        1642.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.70521,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b3340798e34c9a04ef3e3b9548eab317"
        },
        "text": "ag,t Joint action of all available EVs in g at time step t",
        "type": "ListItem"
    },
    {
        "element_id": "6b706f4c6df97318c0424b8a4dcc553a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        888.9,
                        1708.0
                    ],
                    [
                        888.9,
                        1740.6
                    ],
                    [
                        1563.5,
                        1740.6
                    ],
                    [
                        1563.5,
                        1708.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.59718,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b3340798e34c9a04ef3e3b9548eab317"
        },
        "text": "sg,t Joint state of all available EVs in g at time step t",
        "type": "ListItem"
    },
    {
        "element_id": "4bdffe1684e6ce70ef016c088d4576f1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        885.1,
                        1737.4
                    ],
                    [
                        885.1,
                        1773.8
                    ],
                    [
                        1564.0,
                        1773.8
                    ],
                    [
                        1564.0,
                        1737.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.67618,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b3340798e34c9a04ef3e3b9548eab317"
        },
        "text": "AE; Change in SOC during EV i execution dispatch j",
        "type": "ListItem"
    },
    {
        "element_id": "fe8f6a72418044760b879a8459de34ea",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        891.8,
                        1770.6
                    ],
                    [
                        891.8,
                        1807.0
                    ],
                    [
                        1484.2,
                        1807.0
                    ],
                    [
                        1484.2,
                        1770.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.67655,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b3340798e34c9a04ef3e3b9548eab317"
        },
        "text": "Ati Duration for EV i to complete dispatch j",
        "type": "ListItem"
    },
    {
        "element_id": "b81811db7ccd8d19c061f55bb229173b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        893.2,
                        1808.4
                    ],
                    [
                        893.2,
                        1840.2
                    ],
                    [
                        1347.5,
                        1840.2
                    ],
                    [
                        1347.5,
                        1808.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.63431,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b3340798e34c9a04ef3e3b9548eab317"
        },
        "text": "ai,t Action of EV i at time step t",
        "type": "ListItem"
    },
    {
        "element_id": "c330f1ac04b12136709b68e2fc63c647",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        885.6,
                        1837.0
                    ],
                    [
                        885.6,
                        1903.9
                    ],
                    [
                        1563.9,
                        1903.9
                    ],
                    [
                        1563.9,
                        1837.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.65997,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b3340798e34c9a04ef3e3b9548eab317"
        },
        "text": "bij Binary decision variable (bij = 1 if EV i matches dispatch j, else 0)",
        "type": "ListItem"
    },
    {
        "element_id": "039db86cf801895cec542a6c91fe42f6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1913.8
                    ],
                    [
                        136.0,
                        1960.8
                    ],
                    [
                        837.9,
                        1960.8
                    ],
                    [
                        837.9,
                        1913.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81628,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b3340798e34c9a04ef3e3b9548eab317"
        },
        "text": "Wei-Jen Lee is with the Energy Systems Research Center, University of Texas at Arlington, Arlington, TX 76019 USA (e-mail: wlee@uta.edu).",
        "type": "NarrativeText"
    },
    {
        "element_id": "b7c7f7ff2f2cdf56838b7aeb5475fc17",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1963.6
                    ],
                    [
                        136.0,
                        2010.6
                    ],
                    [
                        835.4,
                        2010.6
                    ],
                    [
                        835.4,
                        1963.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.68901,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b3340798e34c9a04ef3e3b9548eab317"
        },
        "text": "Color versions of one or more of the \ufb01gures in this article are available online at https://ieeexplore.ieee.org.",
        "type": "NarrativeText"
    },
    {
        "element_id": "131da3b56a25f154910ef93efad2322a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        893.0,
                        1908.7
                    ],
                    [
                        893.0,
                        1939.8
                    ],
                    [
                        1323.7,
                        1939.8
                    ],
                    [
                        1323.7,
                        1908.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.63364,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b3340798e34c9a04ef3e3b9548eab317"
        },
        "text": "Ei,t SOC of EV i at time step t",
        "type": "ListItem"
    },
    {
        "element_id": "c2b87db0911d28415027862426a402c8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        1942.1
                    ],
                    [
                        894.3,
                        1973.0
                    ],
                    [
                        1388.7,
                        1973.0
                    ],
                    [
                        1388.7,
                        1942.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.59294,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b3340798e34c9a04ef3e3b9548eab317"
        },
        "text": "li,t Location of EV i at time step t",
        "type": "ListItem"
    },
    {
        "element_id": "c7d424b770ac7072e1d9c73907d7d3af",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        901.7,
                        1974.3
                    ],
                    [
                        901.7,
                        2003.5
                    ],
                    [
                        1436.3,
                        2003.5
                    ],
                    [
                        1436.3,
                        1974.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.50671,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b3340798e34c9a04ef3e3b9548eab317"
        },
        "text": "Return of EV i following time step t",
        "type": "ListItem"
    },
    {
        "element_id": "b04f89dcf27368f1783ca04e8e478c0e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        1975.8
                    ],
                    [
                        894.3,
                        2006.2
                    ],
                    [
                        929.8,
                        2006.2
                    ],
                    [
                        929.8,
                        1975.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "13ed321ba2bb921642c5477f0834fb25"
        },
        "text": "Ri,t",
        "type": "Title"
    },
    {
        "element_id": "34a381c7496ef92ba9f7c20935471c0f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        150.9,
                        2012.8
                    ],
                    [
                        150.9,
                        2035.5
                    ],
                    [
                        642.8,
                        2035.5
                    ],
                    [
                        642.8,
                        2012.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.67798,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b04f89dcf27368f1783ca04e8e478c0e"
        },
        "text": "Digital Object Identi\ufb01er 10.1109/TSG.2020.3025082",
        "type": "NarrativeText"
    },
    {
        "element_id": "eeee550900e460a17cf03d62785c19da",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        884.5,
                        2008.4
                    ],
                    [
                        884.5,
                        2039.4
                    ],
                    [
                        1365.2,
                        2039.4
                    ],
                    [
                        1365.2,
                        2008.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.47055,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b04f89dcf27368f1783ca04e8e478c0e"
        },
        "text": "ri,t Reward of EV i at time step t",
        "type": "ListItem"
    },
    {
        "element_id": "176f483e063fe4b718e3a3748c2692ad",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        330.1,
                        2052.8
                    ],
                    [
                        330.1,
                        2104.6
                    ],
                    [
                        1372.2,
                        2104.6
                    ],
                    [
                        1372.2,
                        2052.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.52057,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b04f89dcf27368f1783ca04e8e478c0e"
        },
        "text": "1949-3053 \u00a9 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c15fb100280565845f2edef5c476acf2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.5
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74808,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 1,
            "parent_id": "b04f89dcf27368f1783ca04e8e478c0e"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d2ceaf1622b67d574f90d654bc149c10",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        79.9
                    ],
                    [
                        136.0,
                        102.0
                    ],
                    [
                        1127.5,
                        102.0
                    ],
                    [
                        1127.5,
                        79.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.62607,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2
        },
        "text": "LIANG et al.: MOBILITY-AWARE CHARGING SCHEDULING FOR SHARED ON-DEMAND EV FLEET USING DRL",
        "type": "Header"
    },
    {
        "element_id": "8ff6dbaae9193bcc75b57d92e691c0da",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        160.3,
                        158.7
                    ],
                    [
                        160.3,
                        189.7
                    ],
                    [
                        833.3,
                        189.7
                    ],
                    [
                        833.3,
                        158.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.3785,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "d2ceaf1622b67d574f90d654bc149c10"
        },
        "text": "rij Cumulative discounted reward during EV i exe-",
        "type": "ListItem"
    },
    {
        "element_id": "c86e4c62e1d3c7a600fd189e3ce9bc1c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        161.7,
                        191.8
                    ],
                    [
                        161.7,
                        221.8
                    ],
                    [
                        493.7,
                        221.8
                    ],
                    [
                        493.7,
                        191.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.52032,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "d2ceaf1622b67d574f90d654bc149c10"
        },
        "text": "cution dispatch j",
        "type": "ListItem"
    },
    {
        "element_id": "20f28398e4689d14fbcf4a6bbf50ffc5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.6,
                        224.8
                    ],
                    [
                        144.6,
                        256.1
                    ],
                    [
                        609.0,
                        256.1
                    ],
                    [
                        609.0,
                        224.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.70986,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "d2ceaf1622b67d574f90d654bc149c10"
        },
        "text": "si,t State of EV i at time step t",
        "type": "ListItem"
    },
    {
        "element_id": "320eebf30c0a83b23ca7ee2e961a1c3c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        158.7,
                        257.9
                    ],
                    [
                        158.7,
                        289.3
                    ],
                    [
                        753.1,
                        289.3
                    ],
                    [
                        753.1,
                        257.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.78729,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "d2ceaf1622b67d574f90d654bc149c10"
        },
        "text": "sij State of EV i after completing dispatch j.",
        "type": "ListItem"
    },
    {
        "element_id": "8e4d62a6a583354262d8166939ae38be",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        332.5
                    ],
                    [
                        136.0,
                        361.3
                    ],
                    [
                        246.9,
                        361.3
                    ],
                    [
                        246.9,
                        332.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.68992,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "d2ceaf1622b67d574f90d654bc149c10"
        },
        "text": "Functions",
        "type": "NarrativeText"
    },
    {
        "element_id": "6406fd70d86e9a084d239aa986b08724",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        368.4
                    ],
                    [
                        163.7,
                        402.5
                    ],
                    [
                        620.4,
                        402.5
                    ],
                    [
                        620.4,
                        368.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.6615,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "d2ceaf1622b67d574f90d654bc149c10"
        },
        "text": "\u03c0(s) Deterministic policy function",
        "type": "ListItem"
    },
    {
        "element_id": "822984732c2a0e96a09ed2a286205dce",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        401.6
                    ],
                    [
                        163.7,
                        435.3
                    ],
                    [
                        243.5,
                        435.3
                    ],
                    [
                        243.5,
                        401.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "d2ceaf1622b67d574f90d654bc149c10"
        },
        "text": "V(s; \u03b8 )",
        "type": "Title"
    },
    {
        "element_id": "81aa5b03da37c463b18efd85377c7a18",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        173.2,
                        407.6
                    ],
                    [
                        173.2,
                        468.5
                    ],
                    [
                        833.3,
                        468.5
                    ],
                    [
                        833.3,
                        407.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74584,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "822984732c2a0e96a09ed2a286205dce"
        },
        "text": "State value function approximated by the neural network with parameters \u03b8 .",
        "type": "ListItem"
    },
    {
        "element_id": "56e7ae99593bd980282987cec17e9910",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        180.6,
                        468.0
                    ],
                    [
                        180.6,
                        503.2
                    ],
                    [
                        228.1,
                        503.2
                    ],
                    [
                        228.1,
                        468.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "d2ceaf1622b67d574f90d654bc149c10"
        },
        "text": "\u03c0 (s)",
        "type": "Title"
    },
    {
        "element_id": "4a905bf463aa700d975266336789b8a3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        469.2
                    ],
                    [
                        163.7,
                        501.7
                    ],
                    [
                        188.5,
                        501.7
                    ],
                    [
                        188.5,
                        469.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "d2ceaf1622b67d574f90d654bc149c10"
        },
        "text": "V i",
        "type": "Title"
    },
    {
        "element_id": "dbaea8773cb04377e818d1ab1615002f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        280.3,
                        468.0
                    ],
                    [
                        280.3,
                        501.7
                    ],
                    [
                        790.3,
                        501.7
                    ],
                    [
                        790.3,
                        468.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "d2ceaf1622b67d574f90d654bc149c10"
        },
        "text": "State value function of EV i under policy \u03c0 .",
        "type": "Title"
    },
    {
        "element_id": "ac76eb24c793922f35f5cb3ed9743e9b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        159.3
                    ],
                    [
                        866.6,
                        585.5
                    ],
                    [
                        1567.6,
                        585.5
                    ],
                    [
                        1567.6,
                        159.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94641,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "dbaea8773cb04377e818d1ab1615002f"
        },
        "text": "makes RL more suitable for real-time scheduling of large- scale \ufb02eet [8]. As a model-free method, the training process of RL is based on historical experience (e.g., historical order data [9]) without the need to model transportation networks. In addition, RL is a commonly used method for sequential decision-making problems, which can well balance the \ufb02eet\u2019s immediate and future revenue. For example, greedily matching vehicles with long-distance orders can receive high immediate gain at a single order dispatching stage, but it might jeopardize future revenue because of its long drive time and unpopular destination [10]. However, one of the basic concepts of RL\u2014 state value\u2014can naturally evaluate the future revenue of the vehicle in a certain spatiotemporal state.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a184bff9f2dfc0715ddb246ae8cc2f00",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        370.1,
                        549.1
                    ],
                    [
                        370.1,
                        576.8
                    ],
                    [
                        595.2,
                        576.8
                    ],
                    [
                        595.2,
                        549.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.75891,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "d2ceaf1622b67d574f90d654bc149c10"
        },
        "text": "I. INTRODUCTION",
        "type": "Title"
    },
    {
        "element_id": "71795cf5bce871fbbaec1fc74ab97f09",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        587.2
                    ],
                    [
                        136.0,
                        1150.1
                    ],
                    [
                        836.3,
                        1150.1
                    ],
                    [
                        836.3,
                        587.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94988,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "a184bff9f2dfc0715ddb246ae8cc2f00"
        },
        "text": "I N RECENT years, the advent of large-scale shared on- demand ride-hailing platforms such as Uber and Didi Chuxing has greatly transformed the way people travel. At the same time, electric vehicles (EVs) have received widespread attention due to their lower pollution emissions and lower energy costs compared to gasoline vehicles, but the limited range and availability of charging infrastructure has hin- dered the application of EVs in private mobility. However, in combination with shared mobility-on-demand technology, managing EVs in the form of a \ufb02eet can ensure that there are suf\ufb01cient number of vehicles with adequate energy to sat- isfy customers\u2019 travel demands through intelligent charging scheduling, order dispatching and vehicle rebalancing, thereby eliminating \u201crange anxiety\u201d. Moreover, the development of such shared mobility-on-demand \ufb02eets in large cities also has positive effects on mitigating parking and traf\ufb01c congestion problems [1].",
        "type": "NarrativeText"
    },
    {
        "element_id": "500d0aa557bc2f663126609383747c16",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        591.1
                    ],
                    [
                        866.6,
                        1150.1
                    ],
                    [
                        1567.9,
                        1150.1
                    ],
                    [
                        1567.9,
                        591.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94755,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "a184bff9f2dfc0715ddb246ae8cc2f00"
        },
        "text": "Recently, RL has been applied to order dispatch of ride- hailing platforms [8], [10]\u2013[13]. In [8], a learning and planning method was proposed and successfully deployed in Didi Chuxing\u2019s production system, where the of\ufb02ine learning step applies dynamic programming to update the state value stored in a table, and the online planning step uses the state value to compute real-time matching through the Kuhn-Munkres (KM) algorithm [14]. Since tabular methods are severely limited by the curse of dimensionality, Shi et al. [11] used neural networks to replace the tabular method in [8] to represent state value function. For the same purpose, Tang et al. [12] proposed a new neural network structure, Cerebellum Value Network, to represent the state value function. RL combined with neural networks is often called deep RL (DRL). To cap- ture dynamic demand-supply variations, mean \ufb01eld DRL [15] was used to approximate the interaction between the vehicle and its surrounding area [13].",
        "type": "NarrativeText"
    },
    {
        "element_id": "240546affc3bb51c0e3fbb157c893a91",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1155.6
                    ],
                    [
                        136.0,
                        1880.7
                    ],
                    [
                        837.1,
                        1880.7
                    ],
                    [
                        837.1,
                        1155.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94397,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "a184bff9f2dfc0715ddb246ae8cc2f00"
        },
        "text": "In this article, we consider the welfare maximization problem for a shared on-demand EV \ufb02eet operator. In gen- eral, there are three main scheduling tasks for operating an EV \ufb02eet, namely (i) order dispatching, i.e., to match the orders and vehicles in real time to directly deliver the service to the users, (ii) vehicle rebalancing, to reposition some idle vehi- cles to other locations, and (iii) charging scheduling, i.e., to determine the charging location and time for each EV. These three types of scheduling are closely related to each other, e.g., EVs can choose appropriate order dispatching or rebal- ancing to transfer to a location with greater demand to increase future revenue, or to a charging station with low electric- ity prices to reduce charging costs. Some recent work has jointly optimized different types of scheduling. Zhang et al. [2] proposed a model predictive control (MPC) approach that opti- mizes order dispatching and rebalancing of the \ufb02eet subject to energy constraints. Duan et al. [3] optimized order dispatch- ing and rebalancing based on network \ufb02ow model. In addition, Tsao et al. [4] proposed a stochastic MPC algorithm focusing on vehicle rebalancing. These methods have shown promising results. However, the detailed transportation network model may result in scalability issue.",
        "type": "NarrativeText"
    },
    {
        "element_id": "b21ee13868f8ba86ddc1721898b154a7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1886.2
                    ],
                    [
                        136.0,
                        2079.9
                    ],
                    [
                        834.8,
                        2079.9
                    ],
                    [
                        834.8,
                        1886.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94244,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "a184bff9f2dfc0715ddb246ae8cc2f00"
        },
        "text": "Recent years witnessed tremendous success in reinforce- ment learning (RL) in modeling computational challeng- ing decision-making problems [5]\u2013[7] that were previously intractable. The computational overhead required by RL to solve the multi-agent resource management problem is usually much smaller than that of operations research methods, which",
        "type": "NarrativeText"
    },
    {
        "element_id": "cc75df9c3b3573a8c744a52d3cb53e30",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1155.6
                    ],
                    [
                        866.6,
                        1449.0
                    ],
                    [
                        1567.0,
                        1449.0
                    ],
                    [
                        1567.0,
                        1155.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95622,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "a184bff9f2dfc0715ddb246ae8cc2f00"
        },
        "text": "RL was also applied to \ufb02eet rebalancing [16] and charging scheduling [17], [18]. Lin et al. [16] proposed a contextual multi-agent DRL framework for rebalancing large-scale \ufb02eet. Vandael et al. [17] used RL to solve the charging scheduling problem of EV \ufb02eet. Ding et al. [18] proposed a DRL- based EV charging strategy to maximize the pro\ufb01t of the distribution system operators while satisfying all the physi- cal constraints. In addition, Wan et al. [19] applied DRL to optimize charging/discharging scheduling for private EV.",
        "type": "NarrativeText"
    },
    {
        "element_id": "fc9338ae9bb4013465c42da25d9a05cb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1454.5
                    ],
                    [
                        866.6,
                        2079.9
                    ],
                    [
                        1564.5,
                        2079.9
                    ],
                    [
                        1564.5,
                        1454.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94551,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "a184bff9f2dfc0715ddb246ae8cc2f00"
        },
        "text": "Few works [10], [11], [20] used RL method to jointly optimize different types of scheduling for EV \ufb02eet. Jin et al. [10] optimized joint order dispatching and rebal- ancing, but due to the limited stability of the hierarchical DRL used, its application in the real world is very chal- lenging [10]. In addition, they did not consider charging scheduling. Shi et al. [11] considered charging scheduling while optimizing order dispatching, but they used a positive constant reward to guide EV charging, which could not re\ufb02ect the impact of locational electricity prices on charging behavior. The adopted KM algorithm presents challenges on incorpo- rating constraints for charging behavior (e.g., the number of available chargers should be limited). In addition, they did not consider the rebalancing of EV \ufb02eet. Turan et al. [20] used DRL to solve the joint routing, charging and pricing problem of EV \ufb02eet, where the input of neural network is the state of entire study area, and the output is the scheduling result of all EVs. But the state and action space of such a completely cen- tralized scheduling would be immensely huge. For instance,",
        "type": "NarrativeText"
    },
    {
        "element_id": "c3d5a666aad17a35c00be8f1cf6b4164",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.3
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79859,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2,
            "parent_id": "a184bff9f2dfc0715ddb246ae8cc2f00"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "8a3730eb655387ca6808fbcd7ad237bb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1521.8,
                        79.9
                    ],
                    [
                        1521.8,
                        103.9
                    ],
                    [
                        1566.1,
                        103.9
                    ],
                    [
                        1566.1,
                        79.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80864,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 2
        },
        "text": "1381",
        "type": "Header"
    },
    {
        "element_id": "f0f6ee4f17cc31d7ce510edecdadf8dc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        133.0,
                        80.3
                    ],
                    [
                        133.0,
                        103.9
                    ],
                    [
                        176.7,
                        103.9
                    ],
                    [
                        176.7,
                        80.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79701,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3
        },
        "text": "1382",
        "type": "Header"
    },
    {
        "element_id": "b6a03e788bd357a5463acba8b60702c3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        935.7,
                        82.6
                    ],
                    [
                        935.7,
                        102.3
                    ],
                    [
                        1564.0,
                        102.3
                    ],
                    [
                        1564.0,
                        82.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.85368,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3
        },
        "text": "IEEE TRANSACTIONS ON SMART GRID, VOL. 12, NO. 2, MARCH 2021",
        "type": "Header"
    },
    {
        "element_id": "f66ea0da96b81c95bc8bf5e8fbdbd3b8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        159.3
                    ],
                    [
                        136.0,
                        253.4
                    ],
                    [
                        833.4,
                        253.4
                    ],
                    [
                        833.4,
                        159.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93187,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3,
            "parent_id": "b6a03e788bd357a5463acba8b60702c3"
        },
        "text": "when the study area is divided into 10 nodes and the state of charge (SOC) is discrete to 6 levels, the dimension of state space has reached 1240 [20].",
        "type": "NarrativeText"
    },
    {
        "element_id": "51fa7b6cbb9f04d7c85fa13adcfc857d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        241.0
                    ],
                    [
                        136.0,
                        1295.6
                    ],
                    [
                        833.5,
                        1295.6
                    ],
                    [
                        833.5,
                        241.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91222,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3,
            "parent_id": "b6a03e788bd357a5463acba8b60702c3"
        },
        "text": "In order to facilitate joint optimization of different types of scheduling decisions, we treat each rebalancing or charging behavior as an order and assign it to EVs in the form of dis- patch. The difference is that one order dispatch is assigned to at most one EV, but one rebalancing or charging dis- patch can be assigned to multiple EVs. For large-scale EV \ufb02eet, the state and decision space of the joint optimization problem is huge and dynamically changing, and cannot be solved directly using existing DRL algorithms (e.g., DQN [5], DDPG [21], SAC [22]). To this end, we model the joint optimization problem as a partially observable Markov deci- sion process (POMDP) [23], in which we evaluate the state value of each EV rather than the entire area to reduce the state space (i.e., policy evaluation). In order to reduce the decision space, we divide the study area into hexagonal grids for decentralized scheduling. We argue that this scheduling problem is different from the conventional Markov decision process (MDP) in that the state transition can be determined in advance. With this feature, we transform the collabora- tive scheduling of EVs in each grid into a binary linear programming (BLP) problem (i.e., policy improvement). We interactively perform policy evaluation and policy improve- ment (a common form of RL) [24] to develop a near-optimal scheduling policy. In policy evaluation, we use techniques such as neural network approximation and empirical replay mechanisms to improve computational and data ef\ufb01ciency [5], but lose the theoretical guarantee of convergence. We thus provide a convergent tabular method as a fallback option. An experimental comparison with the tabular method demon- strates that the proposed method has achieved near-optimal performance.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a464c09ef1ece1afaeb3955c6c1c4267",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        1288.1
                    ],
                    [
                        163.7,
                        1316.1
                    ],
                    [
                        685.4,
                        1316.1
                    ],
                    [
                        685.4,
                        1288.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83565,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3,
            "parent_id": "b6a03e788bd357a5463acba8b60702c3"
        },
        "text": "Our major contributions are listed as follows:",
        "type": "NarrativeText"
    },
    {
        "element_id": "a5f43d4a69167bee83bd6ceaff8dd632",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        1321.6
                    ],
                    [
                        163.7,
                        1482.1
                    ],
                    [
                        842.0,
                        1482.1
                    ],
                    [
                        842.0,
                        1321.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92893,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3,
            "parent_id": "b6a03e788bd357a5463acba8b60702c3"
        },
        "text": "1) We propose a joint optimization framework for a large-scale shared on-demand EV \ufb02eet operator as a POMDP which simultaneously considers charging scheduling, order dispatching and vehicle rebalancing decisions.",
        "type": "ListItem"
    },
    {
        "element_id": "1b39476334dc45c115ee730de4dad586",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        1487.7
                    ],
                    [
                        163.7,
                        1681.4
                    ],
                    [
                        840.2,
                        1681.4
                    ],
                    [
                        840.2,
                        1487.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95084,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3,
            "parent_id": "b6a03e788bd357a5463acba8b60702c3"
        },
        "text": "2) We develop a solution method utilizing DRL combined with BLP to obtain a near-optimal scheduling policy. The proposed method is tested with city-scale real-world data to illustrate its effectiveness. We also provide a con- vergent tabular method as a fallback option and give a proof of its convergence.",
        "type": "ListItem"
    },
    {
        "element_id": "4ac82920139394d60aa39230426ff321",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.0,
                        1686.9
                    ],
                    [
                        163.0,
                        1814.2
                    ],
                    [
                        841.8,
                        1814.2
                    ],
                    [
                        841.8,
                        1686.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92777,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3,
            "parent_id": "b6a03e788bd357a5463acba8b60702c3"
        },
        "text": "3) We propose a constraint method for vehicle rebalancing to reduce the exploration space in DRL training process, which can also be used to improve the performance of conventional scheduling methods.",
        "type": "ListItem"
    },
    {
        "element_id": "7a936789baf687d1362addf15d37729e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1819.8
                    ],
                    [
                        136.0,
                        2079.9
                    ],
                    [
                        836.9,
                        2079.9
                    ],
                    [
                        836.9,
                        1819.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94531,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3,
            "parent_id": "b6a03e788bd357a5463acba8b60702c3"
        },
        "text": "The rest of this article is organized as follows. We for- mulate the joint optimization problem as a POMDP in Section II. Section III describes the speci\ufb01c implementa- tion methods of policy improvement and policy evaluation. In Section IV, simulation experiments based on real-world data from Haikou City are used to verify the effectiveness of the proposed method. Finally, we conclude the paper in Section V.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a7cf3aad7860d8beac180bf884a27323",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        869.5,
                        148.1
                    ],
                    [
                        869.5,
                        372.8
                    ],
                    [
                        1560.8,
                        372.8
                    ],
                    [
                        1560.8,
                        148.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-3-1.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3
        },
        "text": "Wi Charging Ev \u00a9 dvailbie EV > Rebalance > Charge 5 (a)",
        "type": "Image"
    },
    {
        "element_id": "9001b35db24ab71d966b2dc505d58859",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        405.3
                    ],
                    [
                        866.6,
                        477.2
                    ],
                    [
                        1564.8,
                        477.2
                    ],
                    [
                        1564.8,
                        405.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93538,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3
        },
        "text": "Fig. 1. Illustration of joint order dispatching, rebalancing, and charging scheduling in grid g at time step t. (a) All available dispatches; (b) Dispatches assigned to EVs.",
        "type": "FigureCaption"
    },
    {
        "element_id": "b4ef69a740edcc8f52fbcb21d02e37f8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1037.2,
                        579.5
                    ],
                    [
                        1037.2,
                        607.1
                    ],
                    [
                        1393.6,
                        607.1
                    ],
                    [
                        1393.6,
                        579.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3
        },
        "text": "II. A POMDP FORMULATION",
        "type": "Title"
    },
    {
        "element_id": "ec6591e0103e8e68fb3b469d42d9efd5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        621.4
                    ],
                    [
                        866.6,
                        1114.0
                    ],
                    [
                        1565.4,
                        1114.0
                    ],
                    [
                        1565.4,
                        621.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95026,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3,
            "parent_id": "b4ef69a740edcc8f52fbcb21d02e37f8"
        },
        "text": "This article considers joint order dispatching, vehicle rebal- ancing, and charging scheduling for shared on-demand EV \ufb02eet operator. As shown in Fig. 1, the study area is divided into hexagonal grids, denoted as G = {1, 2, . . . , G}, and each grid can serve as a trip origin or destination. The hexagonal grid has been widely used for \ufb02eet scheduling problems [10], [12], [16] and its advantages are discussed in [25], [26]. We perform scheduling for EV \ufb02eet at a series of discrete time steps, t = 0, 1, . . . , T\u22121 (T is the termination time of episode). The objective of scheduling optimization is to maximize the operator\u2019s pro\ufb01t, i.e., to increase the total order revenue and reduce the total charging cost. We consider each EV as an agent and model the joint scheduling problem as a POMDP in a fully cooperative setting, where the major components are de\ufb01ned as follows.",
        "type": "NarrativeText"
    },
    {
        "element_id": "51fa7a0aa46723fb2ee1786719f28738",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.1,
                        1119.5
                    ],
                    [
                        866.1,
                        1545.7
                    ],
                    [
                        1567.7,
                        1545.7
                    ],
                    [
                        1567.7,
                        1119.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94887,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3,
            "parent_id": "b4ef69a740edcc8f52fbcb21d02e37f8"
        },
        "text": "1) State: We maintain a set of available EVs (not in ser- vice or charging) for each grid g \u2208 G, denoted as Ig,t = {1, 2, . . . , Ig,t}. For example, the available EVs set for grid g in Fig. 1 is Ig,t = {1, 2, 3}. Since EVs are moving and entering/exiting available status at any time, set Ig,t changes over time. For each available EV i \u2208 Ig,t, its state variable si,t consists of the current time step t, its location li,t and SOC Ei,t, i.e., si,t = [t, li,t, Ei,t]. The location li,t is repre- sented by the index of the grid where EV i is located, i.e., li,t = g \u2200i \u2208 Ig,t. Note that when an EV is not avail- able, we ignore its state. In addition, we use the state vector sg,t = [si,t]i\u2208Ig,t to represent the states of all available EVs in grid g.",
        "type": "NarrativeText"
    },
    {
        "element_id": "b76ce1c555d749d013a584b82d2df5bf",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1551.2
                    ],
                    [
                        866.6,
                        2013.5
                    ],
                    [
                        1568.5,
                        2013.5
                    ],
                    [
                        1568.5,
                        1551.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94833,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3,
            "parent_id": "b4ef69a740edcc8f52fbcb21d02e37f8"
        },
        "text": "2) Action: To facilitate joint optimization, we model each rebalancing or charging decision as an order and assign it to EVs in the form of dispatch. Speci\ufb01cally, we maintain a time-varying available dispatch set Jg,t = {1, 2, . . . , Jg,t} for each grid g, which includes order set J or g,t, rebalancing set J re g,t, and charging set J ch g,t , i.e., Jg,t = J or \u222a J re \u222a J ch g,t . For g,t g,t example, the available dispatch set for grid g in Fig. 1 includes J or = {1, 2}, J re = {3, 4, 5, 6, 7, 8, 9}, and J ch = {10}. At g,t g,t g,t each time step t, a dispatch decision from set Jg,t will be assigned to EV i, and this action is represented as a vector ai,t = [bij]j\u2208Jg,t , where element bij is a binary variable (bij = 1 if EV i matches dispatch j, else 0). For example, in Fig. 1(b), the action of EV 3 matching dispatch 7 is denoted as a3,t = [0 0 0 0 0 0 1 0 0 0].",
        "type": "NarrativeText"
    },
    {
        "element_id": "9b416d3e131844650febba7a11c06b23",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        2013.0
                    ],
                    [
                        866.6,
                        2079.9
                    ],
                    [
                        1564.0,
                        2079.9
                    ],
                    [
                        1564.0,
                        2013.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89474,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3,
            "parent_id": "b4ef69a740edcc8f52fbcb21d02e37f8"
        },
        "text": "We utilize matrix ag,t = [bij]i\u2208Ig,t,j\u2208Jg,t to represent the joint action of all available EVs in grid g. For the example shown",
        "type": "NarrativeText"
    },
    {
        "element_id": "27a61ff5ddc705a4f99c1977215daab1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.3
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.78856,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 3,
            "parent_id": "b4ef69a740edcc8f52fbcb21d02e37f8"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a0ac75332c4017f4f0b7e34797051d1f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        82.6
                    ],
                    [
                        136.0,
                        102.2
                    ],
                    [
                        1126.3,
                        102.2
                    ],
                    [
                        1126.3,
                        82.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.76483,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "LIANG et al.: MOBILITY-AWARE CHARGING SCHEDULING FOR SHARED ON-DEMAND EV FLEET USING DRL",
        "type": "Header"
    },
    {
        "element_id": "84e69235614b915696f4eefe6307941d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        186.1,
                        147.4
                    ],
                    [
                        186.1,
                        356.1
                    ],
                    [
                        784.1,
                        356.1
                    ],
                    [
                        784.1,
                        147.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-4-2.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "56edb9fb3312be0402c056c170cd25a6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.8,
                        388.6
                    ],
                    [
                        135.8,
                        410.7
                    ],
                    [
                        544.3,
                        410.7
                    ],
                    [
                        544.3,
                        388.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.77385,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "Fig. 2. State transition process of each EV.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3f761f8f840be5aec3b8cab496f10eba",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        153.3
                    ],
                    [
                        894.3,
                        187.0
                    ],
                    [
                        1016.4,
                        187.0
                    ],
                    [
                        1016.4,
                        153.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "j \u2208 J re",
        "type": "ListItem"
    },
    {
        "element_id": "8583e890164cebc416090a225a51f6fd",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        895.5,
                        159.3
                    ],
                    [
                        895.5,
                        488.6
                    ],
                    [
                        1566.6,
                        488.6
                    ],
                    [
                        1566.6,
                        159.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93535,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "*j \u20ac J: In this article, staying in the current hexag- onal grid is modeled as a special kind of rebalancing. Therefore, the destination /; of rebalancing dispatch j is the current grid or an adjacent grid. The time steps required to complete the rebalancing dispatch (Afj;) can be calculated in real time based on traffic conditions. For simplicity, in this paper we set Az = 1 [10], [16]. The change in SOC AE; can also be calculated from the mileage (AEj < 0). Since rebalancing is not gainable or payable, we set rj = 0.",
        "type": "ListItem"
    },
    {
        "element_id": "0062f4df755d8f401ad6030f6ac6cb40",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.1,
                        477.5
                    ],
                    [
                        135.1,
                        505.2
                    ],
                    [
                        274.3,
                        505.2
                    ],
                    [
                        274.3,
                        477.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.76266,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "in Fig. 1(b),",
        "type": "NarrativeText"
    },
    {
        "element_id": "6d2c307ffa8c47a00f196aaa3fa4d204",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        228.5,
                        496.9
                    ],
                    [
                        228.5,
                        524.6
                    ],
                    [
                        248.7,
                        524.6
                    ],
                    [
                        248.7,
                        496.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "\u23a1",
        "type": "UncategorizedText"
    },
    {
        "element_id": "c1a1eb3ebd63e70ebf3101688bd0fd94",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        287.6,
                        496.9
                    ],
                    [
                        287.6,
                        524.6
                    ],
                    [
                        307.7,
                        524.6
                    ],
                    [
                        307.7,
                        496.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "\u23a4",
        "type": "UncategorizedText"
    },
    {
        "element_id": "584f8365a91eebf6284ef7cf6fb20686",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        344.7,
                        496.9
                    ],
                    [
                        344.7,
                        524.6
                    ],
                    [
                        364.9,
                        524.6
                    ],
                    [
                        364.9,
                        496.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "\u23a1",
        "type": "UncategorizedText"
    },
    {
        "element_id": "7df128f0ac0e0a9bdeed4027fc2556e7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        752.3,
                        496.9
                    ],
                    [
                        752.3,
                        524.6
                    ],
                    [
                        772.5,
                        524.6
                    ],
                    [
                        772.5,
                        496.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "\u23a4",
        "type": "UncategorizedText"
    },
    {
        "element_id": "da11477745166e368fbfbbd0a47816c6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        150.7,
                        522.9
                    ],
                    [
                        150.7,
                        621.7
                    ],
                    [
                        833.5,
                        621.7
                    ],
                    [
                        833.5,
                        522.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.68398,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "ag,t = \u23a3 a1,t a2,t \u23a6 = \u23a3 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \u23a6 (1) a3,t 0 0 0 0 0 0 1 0 0 0",
        "type": "Formula"
    },
    {
        "element_id": "364baf13c2bc72fe36a0514013480a0d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        638.2
                    ],
                    [
                        136.0,
                        831.9
                    ],
                    [
                        838.7,
                        831.9
                    ],
                    [
                        838.7,
                        638.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94772,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "The generation of joint action needs to meet certain dispatch constraints, which we will discuss in Section III-A. We denote the action space that satis\ufb01es the dispatch constraints as Ag,t. Note that unlike the standard MDP, the action space Ag,t changes over time as it is affected by available EVs and available dispatches.",
        "type": "NarrativeText"
    },
    {
        "element_id": "bdf44cb229192ed678af4c9444c4e061",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        837.5
                    ],
                    [
                        136.0,
                        964.8
                    ],
                    [
                        833.4,
                        964.8
                    ],
                    [
                        833.4,
                        837.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93682,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "3) Reward and Return: Reward ri,t is de\ufb01ned as the rev- enue (cost is treated as negative revenue) obtained by EV i in time step t. Return Ri,t is de\ufb01ned as the cumulative discounted rewards of EV i from time step t until the end of the episode:",
        "type": "NarrativeText"
    },
    {
        "element_id": "a36c2a789543ba816853e9271ba07995",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        244.6,
                        977.7
                    ],
                    [
                        244.6,
                        1018.9
                    ],
                    [
                        833.4,
                        1018.9
                    ],
                    [
                        833.4,
                        977.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.69712,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "Ri,t = ri,t + \u03b3 ri,t+1 + \u00b7 \u00b7 \u00b7 + \u03b3 T\u2212t\u22121ri,T\u22121 (2)",
        "type": "Formula"
    },
    {
        "element_id": "cddc7eaf12a6ac79a981760d859e1083",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1033.9
                    ],
                    [
                        136.0,
                        1067.5
                    ],
                    [
                        833.4,
                        1067.5
                    ],
                    [
                        833.4,
                        1033.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "where \u03b3 \u2208 [0, 1] is the discount factor that is used to trade",
        "type": "NarrativeText"
    },
    {
        "element_id": "9541fa9ceac2e05a6c79408a321a37ec",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1042.3
                    ],
                    [
                        136.0,
                        1100.7
                    ],
                    [
                        833.9,
                        1100.7
                    ],
                    [
                        833.9,
                        1042.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91291,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "off the importance between immediate and future rewards.",
        "type": "NarrativeText"
    },
    {
        "element_id": "e01967f5eaa6c13f173e8584c82edd5b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1106.3
                    ],
                    [
                        136.0,
                        1300.0
                    ],
                    [
                        835.8,
                        1300.0
                    ],
                    [
                        835.8,
                        1106.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95072,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "As shown in Fig. 2, the number of time steps EV i takes to complete dispatch j, denoted as Az, may sometimes be greater than 1, i.e., EV i requires multiple time steps to reach the next state, which is also called semi-MDP [27]. Similar to the standard MDP, there is a recursive relationship between returns in adjacent states:",
        "type": "NarrativeText"
    },
    {
        "element_id": "1b061e05ad919776285afa84b2b84cab",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        200.4,
                        1312.9
                    ],
                    [
                        200.4,
                        1459.6
                    ],
                    [
                        820.1,
                        1459.6
                    ],
                    [
                        820.1,
                        1312.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88618,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "Rig = Tir 4 Yaaa be Fy \u0130ri\u015f ay + V9 (rics kek yi Atty 7) \u2014 ryt OUR ary (3)",
        "type": "Formula"
    },
    {
        "element_id": "228fba3c99921b65ccd5e0103b9b4a52",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1477.5
                    ],
                    [
                        136.0,
                        1607.5
                    ],
                    [
                        833.4,
                        1607.5
                    ],
                    [
                        833.4,
                        1477.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93565,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "where ri; is the cumulative discounted reward during EV i execution dispatch j. For example, if EV i matches the dispatch J that starts at t= 1 and has a duration Az; = 3 (as shown in Fig. 2), then rj = ri,.1 + 77,2 +7723, and Rj.) = r+ y>Ria-",
        "type": "NarrativeText"
    },
    {
        "element_id": "99eca73c86c50533aac423b632aec44e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        801.1,
                        1426.1
                    ],
                    [
                        801.1,
                        1453.8
                    ],
                    [
                        833.4,
                        1453.8
                    ],
                    [
                        833.4,
                        1426.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "(3)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "a24a6bb81fcf54b5ce8517c130677900",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        485.4
                    ],
                    [
                        894.3,
                        519.1
                    ],
                    [
                        1008.8,
                        519.1
                    ],
                    [
                        1008.8,
                        485.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "j \u2208 J ch",
        "type": "ListItem"
    },
    {
        "element_id": "fedc7e04638dcce71ce7c20424de981a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        898.1,
                        491.4
                    ],
                    [
                        898.1,
                        751.5
                    ],
                    [
                        1572.1,
                        751.5
                    ],
                    [
                        1572.1,
                        491.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93891,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": ".jE Ji The charging dispatch destination /; is still the current grid g. It is assumed that once each EV i is dis- patched to charge, it will not leave until it is fully charged. Therefore, the change in SOC AE; = 1 \u2014 E;,, and the charging duration At = [AE;;/Pcy]. The charging cost per time step is the product of the electricity price and the change in SOC. The cumulative discounted reward during charging is the inverse of the total charging cost:",
        "type": "ListItem"
    },
    {
        "element_id": "7bf04a20f468b8d80424407280d06212",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1062.6,
                        772.5
                    ],
                    [
                        1062.6,
                        868.7
                    ],
                    [
                        1564.0,
                        868.7
                    ],
                    [
                        1564.0,
                        772.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82903,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "t+Atj\u20141 rm=\u2014 Yo vp AE: (5) t=",
        "type": "Formula"
    },
    {
        "element_id": "5ef17227eb3248d3ef6bb6dac6d39c61",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        904.2,
                        889.9
                    ],
                    [
                        904.2,
                        1058.0
                    ],
                    [
                        1569.3,
                        1058.0
                    ],
                    [
                        1569.3,
                        889.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92388,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "where Pee is the dynamic charging price of grid g in time step T, which is assumed to be obtainable or predictable. AE; is the change in SOC of EV i in time step t, which is equal to the charging power Pcp if SOC Ej, is not greater than 1, ie., AE;; = min(Pen, | \u2014 Ej,r).",
        "type": "NarrativeText"
    },
    {
        "element_id": "584c6cef934c2e31dffcc3bb5a360195",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1054.8
                    ],
                    [
                        866.6,
                        1254.5
                    ],
                    [
                        1564.3,
                        1254.5
                    ],
                    [
                        1564.3,
                        1054.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94804,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "In short, each EV i whose state is sj, = [t, Ji, Ej,;] at time step \u00a3 will transition to state Sirk = Ut + Ati, ii, Eig + AEjl (abbreviated as sj) at time step \u00a2+ At after completing dispatch j, and obtain a cumulative discounted reward of rij during this period. Both the reward rj and the new state sj can be determined before dispatch j is executed.",
        "type": "NarrativeText"
    },
    {
        "element_id": "6720bfef32403e88e9e8549d34ab1d42",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1260.0
                    ],
                    [
                        866.6,
                        1619.8
                    ],
                    [
                        1565.2,
                        1619.8
                    ],
                    [
                        1565.2,
                        1260.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95317,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "5) Policy and State Value Function: From the perspective of EV \ufb02eet operator, the goal of the joint optimization problem should be to maximize the expected return of the entire \ufb02eet. However, the state and action space of scheduling all EVs completely centrally is too large [20]. A common solution is to use a partially observable setting that ignores the states of other EVs when scheduling for each EV [8], [11]. Considering that there are mutual constraints on the actions of EVs in a grid, e.g., the number of available orders and chargers is limited, we jointly schedule EVs in each grid to facilitate their cooperation. The scheduling objective for each grid can be formulated as",
        "type": "NarrativeText"
    },
    {
        "element_id": "0c4dfa830542c5b47ddca20636cdc99d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1610.3
                    ],
                    [
                        136.0,
                        1740.4
                    ],
                    [
                        837.1,
                        1740.4
                    ],
                    [
                        837.1,
                        1610.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92389,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "4) State Transition In the fleet operation platform, if EV i matches dispatch j, the relevant information\u2014dispatch des- tination /;, dispatch duration Afjj, change in SOC AE, and reward r;\u2014can be calculated before the dispatch is performed:",
        "type": "NarrativeText"
    },
    {
        "element_id": "b48a408c418ed6eebf0ba689cc5c9606",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        972.2,
                        1645.3
                    ],
                    [
                        972.2,
                        1716.1
                    ],
                    [
                        1565.1,
                        1716.1
                    ],
                    [
                        1565.1,
                        1645.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84206,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "max \u03c0 i\u2208Ig,t E\u03c0 Ri,t|si,t = max \u03c0 i\u2208Ig,t V i \u03c0 si,t (6)",
        "type": "Formula"
    },
    {
        "element_id": "a9ddfc56582bdb9c564d6d703cf5b994",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        161.2,
                        1737.2
                    ],
                    [
                        161.2,
                        1970.1
                    ],
                    [
                        836.4,
                        1970.1
                    ],
                    [
                        836.4,
                        1737.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90568,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "\u00bb J \u00a9 Jey: The destination /;, duration Af, price Pi\" and mileage of order dispatch j can be obtained by the fleet operation platform. The change in SOC AEj can be cal- culated from the mileage (AEj < 0). For an order with a price of Pe and a duration of Azj, the reward equally allocated to each time step is Pe / Afij, and the cumulative discounted reward for this order is",
        "type": "ListItem"
    },
    {
        "element_id": "9ac274f4f80f90d74d2e2eeee3c11a99",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1734.1
                    ],
                    [
                        866.6,
                        1967.0
                    ],
                    [
                        1565.6,
                        1967.0
                    ],
                    [
                        1565.6,
                        1734.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95236,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "where \u03c0 is a deterministic policy that maps from the state of each grid to a joint scheduling action, i.e., ag,t = \u03c0(sg,t) \u2200g \u2208 G. The expected return when EV i starts in si,t and follows \u03c0 thereafter, i.e., E\u03c0 [Ri,t|si,t], is de\ufb01ned as the value function of \u03c0 (si,t). According to (3), the relationship state si,t, denoted as V i between the value functions of adjacent states (i.e., Bellman equation for semi-MDP [27]) is",
        "type": "NarrativeText"
    },
    {
        "element_id": "cf4da332937f9f195664041aa7146407",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        438.6,
                        1978.9
                    ],
                    [
                        438.6,
                        2012.4
                    ],
                    [
                        521.5,
                        2012.4
                    ],
                    [
                        521.5,
                        1978.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "t+Atj\u20141",
        "type": "Title"
    },
    {
        "element_id": "8b226494ed57634c693abfd52ccffd8f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        369.2,
                        1987.6
                    ],
                    [
                        369.2,
                        2067.2
                    ],
                    [
                        833.4,
                        2067.2
                    ],
                    [
                        833.4,
                        1987.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74751,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "t+Atj\u20141 Ti \u2014 > t= or rt Pi A 4)",
        "type": "Formula"
    },
    {
        "element_id": "487f2af260c55d690243791189c6b59f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        462.9,
                        2049.5
                    ],
                    [
                        462.9,
                        2075.1
                    ],
                    [
                        496.8,
                        2075.1
                    ],
                    [
                        496.8,
                        2049.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "\u03c4 =t",
        "type": "Title"
    },
    {
        "element_id": "e170120a467a2eabc978215e0a5d938f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        931.2,
                        1986.4
                    ],
                    [
                        931.2,
                        2077.9
                    ],
                    [
                        1552.0,
                        2077.9
                    ],
                    [
                        1552.0,
                        1986.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84978,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "V\u0130 (Si) = Ex [Riclsie] = Ex [rg + Ri als) = Erlrij + yV4 (siyasi). (0)",
        "type": "Formula"
    },
    {
        "element_id": "6c1293823b2d01852320c5e0f61fc1bd",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        921.4,
                        1991.0
                    ],
                    [
                        921.4,
                        2024.9
                    ],
                    [
                        946.2,
                        2024.9
                    ],
                    [
                        946.2,
                        1991.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "V i",
        "type": "Title"
    },
    {
        "element_id": "f15a585e913b37596cac15101b040f25",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.2
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81039,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4,
            "parent_id": "6c1293823b2d01852320c5e0f61fc1bd"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f7cdd4dda7f36a1a37f116a4be89b097",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1521.8,
                        80.1
                    ],
                    [
                        1521.8,
                        103.7
                    ],
                    [
                        1566.3,
                        103.7
                    ],
                    [
                        1566.3,
                        80.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79618,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4
        },
        "text": "1383",
        "type": "Header"
    },
    {
        "element_id": "1cd751bddd1f6374d9d83cbf01ca7292",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1531.7,
                        2041.5
                    ],
                    [
                        1531.7,
                        2069.2
                    ],
                    [
                        1564.0,
                        2069.2
                    ],
                    [
                        1564.0,
                        2041.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 4,
            "parent_id": "f7cdd4dda7f36a1a37f116a4be89b097"
        },
        "text": "(7)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "0b5394c4fbec4d3b14a1da8934e39e73",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        133.1,
                        79.9
                    ],
                    [
                        133.1,
                        103.9
                    ],
                    [
                        177.4,
                        103.9
                    ],
                    [
                        177.4,
                        79.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79995,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "1384",
        "type": "Header"
    },
    {
        "element_id": "a0be0f3f657e7b6f42af3df53d384428",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        935.1,
                        82.6
                    ],
                    [
                        935.1,
                        102.3
                    ],
                    [
                        1564.0,
                        102.3
                    ],
                    [
                        1564.0,
                        82.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84274,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "IEEE TRANSACTIONS ON SMART GRID, VOL. 12, NO. 2, MARCH 2021",
        "type": "Header"
    },
    {
        "element_id": "ec675c604502fe94c70bad45ec68a425",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        330.2,
                        159.3
                    ],
                    [
                        330.2,
                        187.0
                    ],
                    [
                        639.3,
                        187.0
                    ],
                    [
                        639.3,
                        159.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5,
            "parent_id": "a0be0f3f657e7b6f42af3df53d384428"
        },
        "text": "III. SCHEDULING POLICY",
        "type": "Title"
    },
    {
        "element_id": "c961d004729ea6efe17c9a6e0537e7df",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        201.2
                    ],
                    [
                        136.0,
                        461.4
                    ],
                    [
                        833.7,
                        461.4
                    ],
                    [
                        833.7,
                        201.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95141,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5,
            "parent_id": "ec675c604502fe94c70bad45ec68a425"
        },
        "text": "Policy evaluation and policy improvement are performed interactively to develop a near-optimal scheduling policy. Policy evaluation refers to the computation of the value func- tions for a given policy. Policy improvement refers to the computation of an improved policy given the value function for that policy. We will elaborate the implementation of these two processes in the proposed scheduling problem. For simplicity, we omit the subscript t for all variables in this section.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c730398362bbd2158d9f31cef810f8ba",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        897.2,
                        148.6
                    ],
                    [
                        897.2,
                        403.3
                    ],
                    [
                        1534.6,
                        403.3
                    ],
                    [
                        1534.6,
                        148.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-5-3.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "Grid a Grid g (6)",
        "type": "Image"
    },
    {
        "element_id": "0ffd758c691b0be31281883d7ee50491",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        435.8
                    ],
                    [
                        866.6,
                        483.1
                    ],
                    [
                        1565.7,
                        483.1
                    ],
                    [
                        1565.7,
                        435.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90639,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "Fig. 3. EVs rebalance from grid g to h. (a) Unconstrained rebalancing; (b) Constrained rebalancing.",
        "type": "FigureCaption"
    },
    {
        "element_id": "e2e0c50a87e0492f8138328dd4ebb988",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        508.2
                    ],
                    [
                        136.0,
                        535.8
                    ],
                    [
                        788.2,
                        535.8
                    ],
                    [
                        788.2,
                        508.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.58734,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "A. Policy Improvement With Binary Linear Programming",
        "type": "Title"
    },
    {
        "element_id": "a24c4fcb1adcf7ce0b08582219dca0a7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        550.1
                    ],
                    [
                        136.0,
                        677.4
                    ],
                    [
                        834.3,
                        677.4
                    ],
                    [
                        834.3,
                        550.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9394,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5,
            "parent_id": "e2e0c50a87e0492f8138328dd4ebb988"
        },
        "text": "Policy improvement is done by making the policy greedy with respect to the current value function [24]. We can formu- late an improved greedy policy based on the sum of the state values of all available EVs in a grid:",
        "type": "NarrativeText"
    },
    {
        "element_id": "3761cc0e71980ce17e0604861440f253",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        231.0,
                        694.0
                    ],
                    [
                        231.0,
                        855.3
                    ],
                    [
                        833.4,
                        855.3
                    ],
                    [
                        833.4,
                        694.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82031,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "(Sg) = arg max EL ry + yA4Vi (sy)|si,ai] (8a) agcAy icT, = argmax Y | rg -y\u00fcvi (si) | (8b) agcAy icL,",
        "type": "Formula"
    },
    {
        "element_id": "8dbca5929e9b38b030b19cde859ccb5d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        214.0,
                        701.0
                    ],
                    [
                        214.0,
                        742.0
                    ],
                    [
                        234.0,
                        742.0
                    ],
                    [
                        234.0,
                        701.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "1\u2019",
        "type": "UncategorizedText"
    },
    {
        "element_id": "2058aa53e2a54139884d593a43419414",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        874.9
                    ],
                    [
                        136.0,
                        1234.7
                    ],
                    [
                        834.6,
                        1234.7
                    ],
                    [
                        834.6,
                        874.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95451,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "The reason why (8a) is equal to (8b) is that the reward rj and the new state sj; obtained after taking the action a; are determinable in the current scheduling problem (Section II-D). In (8b), rj is the instant reward of EV i execution dispatch j, and V\u0130 (sj) reflects the future rewards of EV i after executing dispatch j to reach a new state. Therefore, Eq. (8b) aims to take the action that maximizes the sum of short-term and long-term rewards of all EVs. The reward of EVs after episode ends is not considered, so when sj is the termination state of episode (corresponding time step f+ Ary > T), vi (sij) = 0. Therefore, we rewrite (8b) as",
        "type": "NarrativeText"
    },
    {
        "element_id": "a57fe10f05986fb1fedacacbbf0ab33e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1104.2,
                        528.6
                    ],
                    [
                        1104.2,
                        556.2
                    ],
                    [
                        1126.3,
                        556.2
                    ],
                    [
                        1126.3,
                        528.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "\u239b",
        "type": "UncategorizedText"
    },
    {
        "element_id": "450bb165cbe848a9fc2241058ac25e28",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1153.8,
                        528.6
                    ],
                    [
                        1153.8,
                        556.2
                    ],
                    [
                        1174.0,
                        556.2
                    ],
                    [
                        1174.0,
                        528.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "\u23a1",
        "type": "UncategorizedText"
    },
    {
        "element_id": "a20fcb5fb7ac664d7bafba02d577cd39",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1451.2,
                        528.6
                    ],
                    [
                        1451.2,
                        556.2
                    ],
                    [
                        1471.4,
                        556.2
                    ],
                    [
                        1471.4,
                        528.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "\u23a4",
        "type": "UncategorizedText"
    },
    {
        "element_id": "47eda757916be1d484a2b2cce02dc154",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1471.4,
                        528.6
                    ],
                    [
                        1471.4,
                        556.2
                    ],
                    [
                        1493.5,
                        556.2
                    ],
                    [
                        1493.5,
                        528.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "\u239e",
        "type": "UncategorizedText"
    },
    {
        "element_id": "9e27af036d810b376ed6872f664717e8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        884.9,
                        549.5
                    ],
                    [
                        884.9,
                        672.6
                    ],
                    [
                        1565.0,
                        672.6
                    ],
                    [
                        1565.0,
                        549.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83839,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "(a =4) - (4) X > bi; < max | 0, \u2014 \u015f \u2014 iel, je Tg #8 (118",
        "type": "Formula"
    },
    {
        "element_id": "0df452b36dd2abd7ad70b3cb00b0c7e0",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        935.3,
                        652.3
                    ],
                    [
                        935.3,
                        680.0
                    ],
                    [
                        974.7,
                        680.0
                    ],
                    [
                        974.7,
                        652.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "#8",
        "type": "UncategorizedText"
    },
    {
        "element_id": "1dc8c52457366e278abfbcccd6288a7c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        717.4
                    ],
                    [
                        866.6,
                        1248.6
                    ],
                    [
                        1568.3,
                        1248.6
                    ],
                    [
                        1568.3,
                        717.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94633,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "where Eg. (11a) constrains each bi; to a binary variable: If dispatch j is assigned to EV i, then bj = 1, otherwise bj = 0. Eq. (11b) indicates that each EV must be assigned with one dispatch. Eq. (11c) indicates that each order dispatch is assigned to at most one EV. In (11d), Ne is the total number of chargers in grid g (Neb > > 0), and yi \u201cch is the number of EVs being charged in grid g. This means that the number of EVs dispatched to charge in grid g cannot be greater than the number of available chargers. In (1le), A AES represents the change in SOC during the journey from \"grid J; to the nearest charger (ap < 0), which ensures that each EV has a sufficient charge level to reach the nearest charger after completing an order or rebalancing. Eq. (11f) is a constraint on the number of rebalanced EVs, which is used to reduce the action space to improve the efficiency of exploration in policy evaluation, which will be described in detail next.",
        "type": "NarrativeText"
    },
    {
        "element_id": "766f11e20c7b1d1f6b9e566f760f7a9c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        337.1,
                        1252.4
                    ],
                    [
                        337.1,
                        1326.9
                    ],
                    [
                        835.8,
                        1326.9
                    ],
                    [
                        835.8,
                        1252.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83312,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "n' (sg) = arg max X Yi (9) a.cAy ; ET,",
        "type": "Formula"
    },
    {
        "element_id": "09f53307979b932bb74ca323b5ab6351",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1348.9
                    ],
                    [
                        136.0,
                        1376.6
                    ],
                    [
                        203.8,
                        1376.6
                    ],
                    [
                        203.8,
                        1348.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.85817,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "where",
        "type": "NarrativeText"
    },
    {
        "element_id": "0e7a2f02a5dd758a8528c01d7caff6d9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        220.0,
                        1388.6
                    ],
                    [
                        220.0,
                        1460.8
                    ],
                    [
                        798.4,
                        1460.8
                    ],
                    [
                        798.4,
                        1388.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.8157,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "Sij is terminal . . Sij is non-terminal yy a ; vive (5H),",
        "type": "Formula"
    },
    {
        "element_id": "5ea879c7649e2850c64a8b3e4d04051d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        787.3,
                        1411.8
                    ],
                    [
                        787.3,
                        1439.5
                    ],
                    [
                        833.4,
                        1439.5
                    ],
                    [
                        833.4,
                        1411.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "(10)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "6aebcdf3feba8fd3025175224fe0952f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.0,
                        1473.5
                    ],
                    [
                        134.0,
                        1612.5
                    ],
                    [
                        833.8,
                        1612.5
                    ],
                    [
                        833.8,
                        1473.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93735,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "We use dispatch constraints to represent action space Ag, and use binary variable bij to directly represent the choice of dispatch. Then Eq. (9) can be rewritten as a BLP problem with decision variable ag = [bij]i\u2208Ig,j\u2208Jg :",
        "type": "NarrativeText"
    },
    {
        "element_id": "822cdc746ec43240eb0957041e2e7af3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        319.8,
                        1632.3
                    ],
                    [
                        319.8,
                        1675.5
                    ],
                    [
                        839.5,
                        1675.5
                    ],
                    [
                        839.5,
                        1632.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.71366,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "arg maxbij i\u2208Ig j\u2208Jg yijbij (11)",
        "type": "Formula"
    },
    {
        "element_id": "72a05e54f08a5e31ed4321f1649859ec",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        162.6,
                        1689.9
                    ],
                    [
                        162.6,
                        1717.6
                    ],
                    [
                        282.0,
                        1717.6
                    ],
                    [
                        282.0,
                        1689.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83753,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "subject to:",
        "type": "NarrativeText"
    },
    {
        "element_id": "65bc1317e04aa5b96087db863c320b5e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        158.4,
                        1738.9
                    ],
                    [
                        158.4,
                        1779.2
                    ],
                    [
                        841.2,
                        1779.2
                    ],
                    [
                        841.2,
                        1738.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.64139,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "bij \u2208 {0, 1} \u2200i \u2208 Ig, \u2200j \u2208 Jg (11a)",
        "type": "Formula"
    },
    {
        "element_id": "913f962a44fc5d4827216875fa68fbf6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        161.2,
                        1758.8
                    ],
                    [
                        161.2,
                        1786.4
                    ],
                    [
                        200.3,
                        1786.4
                    ],
                    [
                        200.3,
                        1758.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "by",
        "type": "Title"
    },
    {
        "element_id": "4310cd79a6bd8bbee3d984c3a679016c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        865.8,
                        1254.1
                    ],
                    [
                        865.8,
                        1814.2
                    ],
                    [
                        1569.3,
                        1814.2
                    ],
                    [
                        1569.3,
                        1254.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9429,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5,
            "parent_id": "913f962a44fc5d4827216875fa68fbf6"
        },
        "text": "For the two grids g and h as shown in Fig. 3, the destination of rebalancing dispatch in grid g is the original grid g or the adjacent grid h. If grid h has more incoming orders than g for a period of time in the future, rebalancing EV i to h is more likely to obtain higher return than g (as the energy cost due to moving to an adjacent grid is relatively small compared with service revenue), i.e., V i \u03c0 (sij)|lj=h > V i \u03c0 (sij)|lj=g \u2200i \u2208 Ig. In addition, the rewards for all rebalancing dispatches are 0, i.e., rij|lj=h = rij|lj=g = 0. Therefore, according to (10) and (11), each EV (except assigned to an order or a charging dispatch) will be rebalanced to grid h to increase the objective function, which will make the order demand in grid g unsatisfactory (as shown in Fig. 3(a)). In addition, during the evaluation of value \u03c0 (sij)|lj=h is sometimes larger function, some errors, such as V i \u03c0 (sij)|lj=g, will make some than, and sometimes smaller than V i EVs repeatedly rebalance in the two grids, which results in a waste of energy.",
        "type": "NarrativeText"
    },
    {
        "element_id": "6ae66c5018eb117d387f0c6b87b3678f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        159.5,
                        1785.0
                    ],
                    [
                        159.5,
                        1845.2
                    ],
                    [
                        833.4,
                        1845.2
                    ],
                    [
                        833.4,
                        1785.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.77757,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "bij = 1 \u2200i \u2208 Ig (11b)",
        "type": "Formula"
    },
    {
        "element_id": "069e28d51cae09b663906d59beea5fcd",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        158.4,
                        1825.9
                    ],
                    [
                        158.4,
                        1854.7
                    ],
                    [
                        201.7,
                        1854.7
                    ],
                    [
                        201.7,
                        1825.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "j\u2208Jg",
        "type": "Title"
    },
    {
        "element_id": "9d33a2ec74b7a78a1b8b3b8adeaa7552",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        158.4,
                        1866.4
                    ],
                    [
                        158.4,
                        1937.0
                    ],
                    [
                        833.4,
                        1937.0
                    ],
                    [
                        833.4,
                        1866.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79985,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "bij \u2264 1 \u2200j \u2208 J or g i\u2208Ig (11c)",
        "type": "Formula"
    },
    {
        "element_id": "ee2709accb5d5a6aab70724de191fb3b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        159.7,
                        1923.3
                    ],
                    [
                        159.7,
                        1950.9
                    ],
                    [
                        198.8,
                        1950.9
                    ],
                    [
                        198.8,
                        1923.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "ieT,",
        "type": "UncategorizedText"
    },
    {
        "element_id": "ad1ba23e4a0a92dd5af84e5523abe0c3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        158.4,
                        1946.6
                    ],
                    [
                        158.4,
                        2024.0
                    ],
                    [
                        833.4,
                        2024.0
                    ],
                    [
                        833.4,
                        1946.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.66847,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "bij \u2264 Nch g \u2212 Iin-ch g i\u2208Ig j\u2208J ch g (11d)",
        "type": "Formula"
    },
    {
        "element_id": "ff24458366fe1f293c82be8f132d2ba9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        158.4,
                        2032.8
                    ],
                    [
                        158.4,
                        2087.7
                    ],
                    [
                        818.0,
                        2087.7
                    ],
                    [
                        818.0,
                        2032.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.47633,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "bi (Ei + AEy + BEP) > O Vie Ty. Wi e Tg\" UTE (Ile)",
        "type": "Formula"
    },
    {
        "element_id": "c18d89fed4fe4c9accec34a969db2c12",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        775.0,
                        2045.3
                    ],
                    [
                        775.0,
                        2073.0
                    ],
                    [
                        833.4,
                        2073.0
                    ],
                    [
                        833.4,
                        2045.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "(11e)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "e66075407c4f563ec481a7eb1e9dcbbf",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        841.4,
                        1819.7
                    ],
                    [
                        841.4,
                        2079.9
                    ],
                    [
                        1568.0,
                        2079.9
                    ],
                    [
                        1568.0,
                        1819.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93905,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "To cope with this problem, we constrain the number of rebalanced EVs by balancing the demand-supply gap between adjacent grids. At time step t, the number of available EVs in grid g, h is denoted as Ig, Ih, and the number of , Jor order dispatches is denoted as Jor h , respectively. Then the g \u2212 Ig and Jor \u2212 Ih, demand-supply gap in these two grids is Jor g h respectively. Without any rebalancing between the two grids, we predict that the demand-supply gap in the two grids at time",
        "type": "NarrativeText"
    },
    {
        "element_id": "2d30717e517a91df08636383ff40b6e8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.4
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81285,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 5
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "7d953d9630358f7f446e1e855d9e082b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        82.6
                    ],
                    [
                        136.0,
                        102.1
                    ],
                    [
                        1126.3,
                        102.1
                    ],
                    [
                        1126.3,
                        82.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80339,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "LIANG et al.: MOBILITY-AWARE CHARGING SCHEDULING FOR SHARED ON-DEMAND EV FLEET USING DRL",
        "type": "Header"
    },
    {
        "element_id": "505979d51d5f9b6d3242886607131e4b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        153.3
                    ],
                    [
                        136.0,
                        319.8
                    ],
                    [
                        837.7,
                        319.8
                    ],
                    [
                        837.7,
                        153.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94467,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6,
            "parent_id": "7d953d9630358f7f446e1e855d9e082b"
        },
        "text": "step t + 1 will still be Jor \u2212 Ig and Jor \u2212 Ih. In order to sat- g h isfy more orders as a whole, we assume that after rebalancing Ire g\u2192h EVs from g to h at time step t, the demand-supply gap between the two grids will be balanced at time step t + 1 (as shown in Fig. 3(b)):",
        "type": "NarrativeText"
    },
    {
        "element_id": "9e4a507b4a172fccc62d51214331173b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        251.6,
                        338.7
                    ],
                    [
                        251.6,
                        397.1
                    ],
                    [
                        838.5,
                        397.1
                    ],
                    [
                        838.5,
                        338.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80995,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "Jor g \u2212 Ig \u2212 Ire g\u2192h = Jor h \u2212 Ih + Ire g\u2192h (12)",
        "type": "Formula"
    },
    {
        "element_id": "d83c6fd72d9b10792314b19a641d3bd6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        412.5
                    ],
                    [
                        136.0,
                        440.2
                    ],
                    [
                        296.5,
                        440.2
                    ],
                    [
                        296.5,
                        412.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.8968,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "Then we have",
        "type": "NarrativeText"
    },
    {
        "element_id": "99c1bbb0361c74e96721433ff035af00",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        293.6,
                        459.7
                    ],
                    [
                        293.6,
                        544.2
                    ],
                    [
                        838.9,
                        544.2
                    ],
                    [
                        838.9,
                        459.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.85625,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "Ire g\u2192h = Jor h \u2212 Ih \u2212 2 Jor g \u2212 Ig (13)",
        "type": "Formula"
    },
    {
        "element_id": "a0b52fa023e823b38eb97df9ade6485f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        558.2
                    ],
                    [
                        136.0,
                        985.2
                    ],
                    [
                        834.0,
                        985.2
                    ],
                    [
                        834.0,
                        558.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95411,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "Note that when the demand-supply gap of grids g and h are both positive, Ire g\u2192h may still be a positive number, but at this time, the best policy in grid g may be to let all EVs serve the orders, i.e., Ire g\u2192h should be 0. Therefore, we do not consider Ire g\u2192h obtained by (13) as the speci\ufb01c number of rebalanced EVs but the upper limit number. Since Ire g\u2192h may also be a fraction or a negative number, we round it up and set it to not less than 0, and \ufb01nally write it as the constraint form shown in (11f). Adding reasonable constraints to rebalancing in this way can eliminate unreasonable actions in the action space to improve the ef\ufb01ciency of exploration, which we call con- strained rebalancing (CR). Note that CR can also be applied to conventional scheduling policies.",
        "type": "NarrativeText"
    },
    {
        "element_id": "13a5554fec9859791e6ae8d96e203c63",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        159.3
                    ],
                    [
                        866.6,
                        519.1
                    ],
                    [
                        1568.8,
                        519.1
                    ],
                    [
                        1568.8,
                        159.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95303,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "Algorithm 1 shows the training process of neural network V(s; \u03b8 ). To improve the stability of training, one technique is to use a target network to calculate the TD target value [5]. During initialization, we create a copy of the neural network V(s; \u03b8 ), denoted as \u02c6V(s; \u02c6\u03b8 ). Network \u02c6V(s; \u02c6\u03b8 ) is called the tar- get network, and original network V(s; \u03b8 ) is called the online network. During the training process, the parameters \u03b8 of online network are updated every step, but the parameters \u02c6\u03b8 of target network are updated every C steps (making it equal to the current \u03b8 ). With the target network, TD target value can be calculated as:",
        "type": "NarrativeText"
    },
    {
        "element_id": "bde98babe4d4712f71aac7b65c41c4d2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1023.5,
                        529.1
                    ],
                    [
                        1023.5,
                        565.5
                    ],
                    [
                        1056.5,
                        565.5
                    ],
                    [
                        1056.5,
                        529.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "rij,",
        "type": "UncategorizedText"
    },
    {
        "element_id": "4e2f0b5b5716496d5a2dab099e62382c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        937.9,
                        535.1
                    ],
                    [
                        937.9,
                        622.6
                    ],
                    [
                        1573.6,
                        622.6
                    ],
                    [
                        1573.6,
                        535.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83422,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": ". Tij, Sij is terminal Y\u00fc = | ryt ys \u00f6). Sij is non-terminal (5)",
        "type": "Formula"
    },
    {
        "element_id": "e552b3deada71b4d81d078c47c9906c0",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        633.9
                    ],
                    [
                        866.6,
                        963.1
                    ],
                    [
                        1567.7,
                        963.1
                    ],
                    [
                        1567.7,
                        633.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95618,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "Another technique used to stabilize training and also improve data ef\ufb01ciency is the experience replay mecha- nism [29]. Speci\ufb01cally, we maintain a replay buffer D of capacity D for the entire EV \ufb02eet. After getting a dispatch assignment, each EV i will store transition (si, rij, sij) in the replay buffer D. At each step of training, we randomly choose M transitions from D to form a mini-batch M. With the mini- batch, we can calculate the loss function L(\u03b8 ), which is de\ufb01ned as the mean square error (MSE) between the TD target value and the estimated state value V(si; \u03b8 ):",
        "type": "NarrativeText"
    },
    {
        "element_id": "019b87bd250e247ff422ea019b18428f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1032.7
                    ],
                    [
                        136.0,
                        1060.4
                    ],
                    [
                        634.2,
                        1060.4
                    ],
                    [
                        634.2,
                        1032.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.66645,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "B. Policy Evaluation With Neural Networks",
        "type": "Title"
    },
    {
        "element_id": "43d7a907524c98aa498a8d3b57df69a7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        990.7,
                        976.5
                    ],
                    [
                        990.7,
                        1061.7
                    ],
                    [
                        1567.2,
                        1061.7
                    ],
                    [
                        1567.2,
                        976.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82068,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "L(\u03b8 ) = 1 M (si,rij,sij)\u2208M \u02c6yij \u2212 V(si; \u03b8 ) 2 (16)",
        "type": "Formula"
    },
    {
        "element_id": "c778ec43d16d91c9c59b08d7047ae667",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        1063.5
                    ],
                    [
                        163.7,
                        1102.3
                    ],
                    [
                        833.4,
                        1102.3
                    ],
                    [
                        833.4,
                        1063.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "Given an estimated value function \u02dcV(s) for policy \u03c0 , the",
        "type": "NarrativeText"
    },
    {
        "element_id": "416d5aebd5b8808d66203522a28f3b78",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1074.7
                    ],
                    [
                        136.0,
                        1235.1
                    ],
                    [
                        837.1,
                        1235.1
                    ],
                    [
                        837.1,
                        1074.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94915,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "process of policy evaluation is to change it to be more like the true value function V\u03c0 (s) for policy \u03c0 . Temporal-difference (TD) prediction [28] is a commonly used method for policy evaluation:",
        "type": "NarrativeText"
    },
    {
        "element_id": "8e358f104444ca7bee64044d04c5a8e1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        225.8,
                        1252.5
                    ],
                    [
                        225.8,
                        1301.8
                    ],
                    [
                        838.8,
                        1301.8
                    ],
                    [
                        838.8,
                        1252.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73601,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "Wp) \u2014 V(si) + ary + y\u00fc (si) \u2014 Vs) (14)",
        "type": "Formula"
    },
    {
        "element_id": "4ce1e1f002f09fa593a32cb1f18564fe",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1310.2
                    ],
                    [
                        136.0,
                        1515.3
                    ],
                    [
                        835.5,
                        1515.3
                    ],
                    [
                        835.5,
                        1310.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95307,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "where w is the step size. rij + yi Vsip \u2014 Wsp), called the TD error, is used to measure the difference between the esti- mated value of s; and the better estimated rj + AtjV (sip). rt AtyV (si) is also called TD target value. TD prediction bases its update in part on an existing estimate, so it is a bootstrapping method [24].",
        "type": "NarrativeText"
    },
    {
        "element_id": "58d9c4cd5ffa8cbb8311221f9d133f2a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1520.9
                    ],
                    [
                        136.0,
                        2079.9
                    ],
                    [
                        834.9,
                        2079.9
                    ],
                    [
                        834.9,
                        1520.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94776,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "Generally speaking, the value function can be a look-up table that directly stores values of states. However, in the cur- rent scheduling problem, the tabular method will suffer from the curse of dimensionality because of too many time steps and grids. In addition, the continuous variable Ei also makes the tabular method dif\ufb01cult to handle. To this end, we use neural networks to approximate the value function. Another problem is that the excessive number of EVs makes it dif\ufb01- cult for us to maintain a value function for each EV. In this article, we assume that all the EVs are homogeneous, which is a quite common case for shared on-demand EV \ufb02eets [8], [11]. In this way, all those EVs have the same battery capacity, power consumption, and travel speed, so that they can share the same value function V(s; \u03b8 ) approximated by the neural network, where \u03b8 are the parameters of the neural network. We train the network V(s; \u03b8 ) to make it more like the true value function of a given policy.",
        "type": "NarrativeText"
    },
    {
        "element_id": "03f66bab0c4d483416fee0bf4a81a2ae",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1075.9
                    ],
                    [
                        866.6,
                        1142.8
                    ],
                    [
                        1564.0,
                        1142.8
                    ],
                    [
                        1564.0,
                        1075.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92253,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "The parameters \u03b8 are updated by gradient descent to minimize the loss function:",
        "type": "NarrativeText"
    },
    {
        "element_id": "f7a52a761ab49e710d1aa5a70b7732de",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1101.1,
                        1162.6
                    ],
                    [
                        1101.1,
                        1196.2
                    ],
                    [
                        1312.9,
                        1196.2
                    ],
                    [
                        1312.9,
                        1162.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "\u03b8 \u2190 \u03b8 \u2212 lr\u2207\u03b8 L(\u03b8 )",
        "type": "Title"
    },
    {
        "element_id": "ac6da9c995405d6d97ba5078d27f95e8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1103.4,
                        1168.6
                    ],
                    [
                        1103.4,
                        1196.2
                    ],
                    [
                        1564.0,
                        1196.2
                    ],
                    [
                        1564.0,
                        1168.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.69651,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "(17)",
        "type": "Formula"
    },
    {
        "element_id": "4434921a5729d4049d06f6efa6678f50",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1216.0
                    ],
                    [
                        866.6,
                        1415.7
                    ],
                    [
                        1565.2,
                        1415.7
                    ],
                    [
                        1565.2,
                        1216.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94844,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "where lr is the learning rate. Since the parameters \u03b8 are contin- uously updated, the policy generated by the state value V(s; \u03b8 ) is also continuously updated, which means that the transitions stored in the replay buffer are not generated by the same pol- icy. This way in which the evaluated policy differs from the policy used to generate data is called off-policy learning.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a24f502f829d501ee051e5a3d00578e7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1421.2
                    ],
                    [
                        866.6,
                        1747.8
                    ],
                    [
                        1566.3,
                        1747.8
                    ],
                    [
                        1566.3,
                        1421.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95748,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "Since continuous exploration is the key to making policy evaluation work [28], we apply e-greedy policy to generate scheduling actions during the training process: Each grid g performs random action (randomly generate action a, under constraints (11a)-(11f)) with probability e, and greedy action (get action a, by solving (11)) with probability 1 \u2014 e. The probability e decays from | to 0.1 in steps of Ae and then remains unchanged at 0.1. Note that when testing a trained neural network, we do not add any exploration but apply a completely greedy policy, i.e., e = 0.",
        "type": "NarrativeText"
    },
    {
        "element_id": "59260f2c24f1205bd4909572a71244a3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1753.3
                    ],
                    [
                        866.6,
                        2079.9
                    ],
                    [
                        1564.6,
                        2079.9
                    ],
                    [
                        1564.6,
                        1753.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95139,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "Similar to most popular DRL algorithms (e.g., DQN, DDPG, SAC), the proposed method applies three elements to improve performance: function approximation (i.e., neural networks) for scalability and generalization, bootstrapping for computational and data ef\ufb01ciency [24], and off-policy learning for experience replay. However, combining these three ele- ments may lead to instability and divergence [30]. For this reason, we present a tabular method in the Appendix as a fallback option. The tabular method eschews function approx- imation and off-policy, so it is susceptible to the curse of",
        "type": "NarrativeText"
    },
    {
        "element_id": "8767d3690eaae82b1045e5a63c23d669",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.5
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79324,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f5563108e8295d88aef5020767df0a33",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1522.1,
                        80.0
                    ],
                    [
                        1522.1,
                        103.7
                    ],
                    [
                        1566.0,
                        103.7
                    ],
                    [
                        1566.0,
                        80.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80463,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 6
        },
        "text": "1385",
        "type": "Header"
    },
    {
        "element_id": "81a4bacaf4bc2f7afe3c2b9b362aa1c4",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        133.3,
                        79.9
                    ],
                    [
                        133.3,
                        103.5
                    ],
                    [
                        177.2,
                        103.5
                    ],
                    [
                        177.2,
                        79.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79104,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7
        },
        "text": "1386",
        "type": "Header"
    },
    {
        "element_id": "5e8575be4b15e5dd47e547b073645740",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        935.0,
                        82.6
                    ],
                    [
                        935.0,
                        102.0
                    ],
                    [
                        1564.0,
                        102.0
                    ],
                    [
                        1564.0,
                        82.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.85759,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7
        },
        "text": "IEEE TRANSACTIONS ON SMART GRID, VOL. 12, NO. 2, MARCH 2021",
        "type": "Header"
    },
    {
        "element_id": "029e8f9c616e9b048273e288c9252549",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        149.8,
                        161.2
                    ],
                    [
                        149.8,
                        188.9
                    ],
                    [
                        781.6,
                        188.9
                    ],
                    [
                        781.6,
                        161.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.34228,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7,
            "parent_id": "5e8575be4b15e5dd47e547b073645740"
        },
        "text": "Algorithm 1: Policy Evaluation With Neural Networks",
        "type": "NarrativeText"
    },
    {
        "element_id": "1061fbc9ec06e1abc3edc84ea56461e8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        197.7
                    ],
                    [
                        163.7,
                        1280.2
                    ],
                    [
                        817.3,
                        1280.2
                    ],
                    [
                        817.3,
                        197.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.76539,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7,
            "parent_id": "5e8575be4b15e5dd47e547b073645740"
        },
        "text": "Initialize e = 1; Initialize replay buffer D with a capacity of D; Initialize network V(s; 0) with random parameters 0; Initialize target network Ws; 6) with parameters 6 <6; for episode = | to number of episodes do Receive initial state s; for each EV i; for time step t= 0 to T\u20141 do foreach grid ge G do foreach EV i \u20ac TZ, do foreach dispatch j \u20ac Jz do Calculate AEj, rij, siz; | Calculate yi; according to (10); Draw a sample u from uniform distribution U(O, 1); if u < \u00a2 then Randomly generate ag = [DijlicT,.je J under constraints (11a)\u2014(11f); else Get ag = [bijlicT, jeg, by solving (11); foreach bij e a, do if bj = 1 then Assign dispatch j to EV i; | Store transition (6;, rij, 5i) in D; if e > 0.1 thene\u2014e\u2014 Ag; Randomly choose M transitions from D to forma mini-batch M; Calculate target value Yi; according to (15); Calculate loss function L(0) according to (16); Update parameters 06 \u2014 0 \u2014 IrVgL(0); Every C steps reset d\u00f6 6;",
        "type": "NarrativeText"
    },
    {
        "element_id": "f7e81eade9414421df143e134d6ce73a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1366.5
                    ],
                    [
                        136.0,
                        1660.5
                    ],
                    [
                        835.8,
                        1660.5
                    ],
                    [
                        835.8,
                        1366.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95791,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7,
            "parent_id": "5e8575be4b15e5dd47e547b073645740"
        },
        "text": "dimensionality and data inef\ufb01ciency, but it can theoretically converge to a near-optimal policy. We give the speci\ufb01c steps and convergence proofs of the tabular method in the Appendix. Fortunately, many experiments have shown that DRL algo- rithms like DQN and DDPG, which have no theoretical convergence guarantees, can learn near-optimal policies [31], [32]. We will show that the proposed method also achieves near-optimal performance in an experimental comparison with the convergent tabular method (Section IV-C).",
        "type": "NarrativeText"
    },
    {
        "element_id": "99966b18d88d24cf2603794c42bd955b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        382.5,
                        1701.5
                    ],
                    [
                        382.5,
                        1729.2
                    ],
                    [
                        587.0,
                        1729.2
                    ],
                    [
                        587.0,
                        1701.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80998,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7,
            "parent_id": "5e8575be4b15e5dd47e547b073645740"
        },
        "text": "IV. CASE STUDY",
        "type": "Title"
    },
    {
        "element_id": "7ebfa634968dcc8c4ab7223ba72036ab",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.9,
                        1743.4
                    ],
                    [
                        134.9,
                        1771.1
                    ],
                    [
                        424.1,
                        1771.1
                    ],
                    [
                        424.1,
                        1743.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.39916,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7,
            "parent_id": "99966b18d88d24cf2603794c42bd955b"
        },
        "text": "A. Experimental Settings",
        "type": "NarrativeText"
    },
    {
        "element_id": "483903a385aa57f29b2f791348ea8d35",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1785.3
                    ],
                    [
                        136.0,
                        2079.9
                    ],
                    [
                        837.2,
                        2079.9
                    ],
                    [
                        837.2,
                        1785.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95413,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7,
            "parent_id": "99966b18d88d24cf2603794c42bd955b"
        },
        "text": "The study area is the center of Haikou City as shown in Fig. 4, which is approximately divided into 133 hexag- onal grids. We assume that there are 20 grids equipped with chargers, which constitute three rechargeable areas (indicated by three different colors), denoted as Gch 1 {17, 46, 48, 65, 67, 80, 102}, Gch = {10, 12, 36, 51, 53, 56, 58} 2 and Gch = {89, 92, 105, 109, 112, 133}, respectively. All grids 3 in each charging area are set to have the same electricity = price. We appropriately scale the electricity price data of three",
        "type": "NarrativeText"
    },
    {
        "element_id": "3ee1010652a956a961c8b19dc3091068",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        915.3,
                        147.3
                    ],
                    [
                        915.3,
                        470.0
                    ],
                    [
                        1515.3,
                        470.0
                    ],
                    [
                        1515.3,
                        147.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-7-4.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "5cb0cd4aeec51c2a51c8a111f99321a7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        865.3,
                        502.5
                    ],
                    [
                        865.3,
                        524.6
                    ],
                    [
                        1503.4,
                        524.6
                    ],
                    [
                        1503.4,
                        502.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.50203,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7
        },
        "text": "Fig. 4. The center of Haikou City divided into 133 hexagonal grids.",
        "type": "NarrativeText"
    },
    {
        "element_id": "738c05ef1eba5f94910853b884feddb8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        904.2,
                        575.0
                    ],
                    [
                        904.2,
                        948.3
                    ],
                    [
                        1525.5,
                        948.3
                    ],
                    [
                        1525.5,
                        575.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-7-5.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7
        },
        "text": "time step sare value location ) \u00a9 one-hot Ni 4 neurons soc 4 eco <7 1 an \u00a9 one-hot | i = ; Ni i! 128 neurons",
        "type": "Image"
    },
    {
        "element_id": "82314227ef125d7da00c6d5c182290fc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        865.4,
                        980.8
                    ],
                    [
                        865.4,
                        1002.9
                    ],
                    [
                        1447.6,
                        1002.9
                    ],
                    [
                        1447.6,
                        980.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87805,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7
        },
        "text": "Fig. 5. Neural network architecture for estimating state value.",
        "type": "FigureCaption"
    },
    {
        "element_id": "16c27518b92aaf782370449b0958f301",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1089.1
                    ],
                    [
                        866.6,
                        1482.1
                    ],
                    [
                        1566.6,
                        1482.1
                    ],
                    [
                        1566.6,
                        1089.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95451,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7
        },
        "text": "different buses in PJM [33] to simulate charging electricity prices. We set the number of chargers in each rechargeable grid Nch g = 12, and the power of each charger Pch = 30kW. The total number of EVs is set to 800. The characteristics of EVs are modeled after Beiqi New Energy EU300 with a battery capacity of 45kWh and a range of 300km. The initial EV position is randomly placed, and the initial SOC bounded between 0.2 and 0.8 is sampled from N (0.5, 0.12) [19]. Each time step is set to 15 minutes, but higher accuracy can be used in actual scheduling. Considering that a charging behav- ior may affect the rewards for more than one day, we set each episode to one week, i.e., T = 672.",
        "type": "NarrativeText"
    },
    {
        "element_id": "4c6bcbc2de0dfe5a02b310cf048c197a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1487.7
                    ],
                    [
                        866.6,
                        2079.9
                    ],
                    [
                        1569.5,
                        2079.9
                    ],
                    [
                        1569.5,
                        1487.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94815,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7
        },
        "text": "The data provided by Didi Chuxing [9] includes on-demand orders in the center area of Haikou City for 26 consecu- tive weeks (2017/05/01\u20132017/10/29). The order information includes order generation time, price, origin, destination and duration. We randomly select about 1.6 \u00d7 105 orders at a time from the dataset and compose an episode (a week) based on the order generation time (day of week, time of day). Notice that the random seeds used in the training phase and the testing phase are different. We set that each order will be cancelled if it is not serviced within half an hour after it is generated. Fig. 6 shows the cumulative order requests for the entire study area within a week. It can be seen that there is more demand for orders on the right side of the area. Combined with the distri- bution of chargeable areas, we can \ufb01nd that Gch > Gch 2 3 in terms of order demand. Fig. 7 shows the change in order demand over time in the entire study area. It can be seen that 14:00\u201319:00 is the peak period of order demand > Gch 1 every day.",
        "type": "NarrativeText"
    },
    {
        "element_id": "7c505e5155095398facfde49884fda0a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.5
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79064,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 7
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "bfe1a161704a36273853e5ad948242e8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        82.6
                    ],
                    [
                        136.0,
                        102.1
                    ],
                    [
                        1126.3,
                        102.1
                    ],
                    [
                        1126.3,
                        82.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84125,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "LIANG et al.: MOBILITY-AWARE CHARGING SCHEDULING FOR SHARED ON-DEMAND EV FLEET USING DRL",
        "type": "Header"
    },
    {
        "element_id": "05464a1f1318e63953f60763106ad4cd",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        230.5,
                        147.3
                    ],
                    [
                        230.5,
                        403.3
                    ],
                    [
                        739.9,
                        403.3
                    ],
                    [
                        739.9,
                        147.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-8-6.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "9f05bf8245dca59b5df2e3af7de2e831",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        886.1,
                        148.0
                    ],
                    [
                        886.1,
                        420.0
                    ],
                    [
                        1544.8,
                        420.0
                    ],
                    [
                        1544.8,
                        148.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-8-7.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": ">. Proposed method \u00f6 \u2014-Proposed method without CR. \u00ab-DRL-based order and charging dispatch 3 4 5 6 7 8 9 10 Episode",
        "type": "Image"
    },
    {
        "element_id": "bf40af3ce6f96bcb4578f0977a5b0433",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        435.8
                    ],
                    [
                        136.0,
                        458.1
                    ],
                    [
                        817.6,
                        458.1
                    ],
                    [
                        817.6,
                        435.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.8551,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "Fig. 6. Number of order requests for different locations during the week.",
        "type": "FigureCaption"
    },
    {
        "element_id": "8de327c50ea6ad68e667348bca9fc7d1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        452.5
                    ],
                    [
                        866.6,
                        499.5
                    ],
                    [
                        1564.2,
                        499.5
                    ],
                    [
                        1564.2,
                        452.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90589,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "Fig. 8. Episodic average cumulative reward of EV \ufb02eet over 6 different random seeds during training. Error bars are the 95% con\ufb01dence intervals.",
        "type": "FigureCaption"
    },
    {
        "element_id": "66b5a1c8fe4e9150ea663880b8206c1b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        152.8,
                        510.6
                    ],
                    [
                        152.8,
                        734.6
                    ],
                    [
                        816.7,
                        734.6
                    ],
                    [
                        816.7,
                        510.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-8-8.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "0 96 192 288 384 480 576 672 t",
        "type": "Image"
    },
    {
        "element_id": "7a962ce9e6b20cab778be55fda09e711",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.5,
                        767.1
                    ],
                    [
                        134.5,
                        789.2
                    ],
                    [
                        745.2,
                        789.2
                    ],
                    [
                        745.2,
                        767.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.86123,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "Fig. 7. Number of order requests per time step in the study area.",
        "type": "FigureCaption"
    },
    {
        "element_id": "67bef65cd8f55cc2991a3bd6fe71c597",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        883.3,
                        533.6
                    ],
                    [
                        883.3,
                        808.3
                    ],
                    [
                        1547.3,
                        808.3
                    ],
                    [
                        1547.3,
                        533.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-8-9.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "g 400 a \u2014Proposed | Proposed without CR E 300 -\u2014DRL-based order and charging dispatch z \u2014REV a \u2014 REV with rebalancing g ZU \u2014REV with CR \u201c3 100 5 0 96 192 288 384 480 576 672 t",
        "type": "Image"
    },
    {
        "element_id": "a932b2ce0b1f702e9934c275425a090d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.6,
                        875.6
                    ],
                    [
                        134.6,
                        1235.4
                    ],
                    [
                        833.9,
                        1235.4
                    ],
                    [
                        833.9,
                        875.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9558,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "The neural network used to approximate the state value function is shown in Fig. 5, which has 3 hidden layers with 128, 64, and 32 neurons respectively. We apply rectified linear unit (ReLU) [34] to each layer. At the input layer, the discrete state variables (i.e., time step t and location /;,,) are represented with one-hot encoding. The Adam optimizer [35] is used for learning the neural network parameters with a learning rate Ir = 0.001. The other hyperparameters during training are as follows: the number of episodes is 10, the capacity of replay buffer D = 5 x 10\u00b0, the discount factor y = 0.9, and the decay step size of the exploration probability Ag = 1.5 x 10-4,",
        "type": "NarrativeText"
    },
    {
        "element_id": "b58c303e43e32e2f9ec3e731c350b3bc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        840.8
                    ],
                    [
                        866.6,
                        887.8
                    ],
                    [
                        1566.4,
                        887.8
                    ],
                    [
                        1566.4,
                        840.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90349,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "Fig. 9. Average cumulative reward of EV \ufb02eet over 6 different random seeds during testing.",
        "type": "FigureCaption"
    },
    {
        "element_id": "c593b47245e2f5a1e253b79adcc65bef",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        956.3
                    ],
                    [
                        894.3,
                        1150.0
                    ],
                    [
                        1566.6,
                        1150.0
                    ],
                    [
                        1566.6,
                        956.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94331,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "\u2022 DRL-based order and charging dispatch: This method is a state-of-the-art DRL-based EV \ufb02eet scheduling algo- rithm [11]. The method was proposed without taking into account the fact that the number of chargers is limited, so in this article there will be a queue of EVs waiting for charging.",
        "type": "ListItem"
    },
    {
        "element_id": "22ee5488a979ce0ba0069231678b9390",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        891.4,
                        1155.6
                    ],
                    [
                        891.4,
                        1249.7
                    ],
                    [
                        1570.6,
                        1249.7
                    ],
                    [
                        1570.6,
                        1155.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92216,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "\u2022 Proposed method without CR: The only difference from the proposed method is that we do not constrain the number of EVs rebalanced to other grids.",
        "type": "ListItem"
    },
    {
        "element_id": "d26cf4e9a47cea3bf3feca170e448c06",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1240.9
                    ],
                    [
                        136.0,
                        1401.4
                    ],
                    [
                        834.7,
                        1401.4
                    ],
                    [
                        834.7,
                        1240.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95342,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "The BLP problem is written and solved in Python with Gurobi [36], and the neural networks are trained in Python with Pytorch [37], an open source deep learning platform. All experiments are carried out on a computer with a 10-core 3.70 GHz Intel Core i9-10900X processor and 32 GB of RAM.",
        "type": "NarrativeText"
    },
    {
        "element_id": "02743fa89fe56fed0f3f3debe47d2283",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1478.9
                    ],
                    [
                        136.0,
                        1506.6
                    ],
                    [
                        462.4,
                        1506.6
                    ],
                    [
                        462.4,
                        1478.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.51227,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "B. Performance Comparison",
        "type": "ListItem"
    },
    {
        "element_id": "891176c2113897ad6fa017ed1e3d72de",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1520.9
                    ],
                    [
                        136.0,
                        1581.7
                    ],
                    [
                        839.4,
                        1581.7
                    ],
                    [
                        839.4,
                        1520.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91581,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "We veri\ufb01ed the performance of proposed method by com- paring with several benchmark algorithms:",
        "type": "NarrativeText"
    },
    {
        "element_id": "a7f527683cfc35288f5af023de75901e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        159.1,
                        1587.3
                    ],
                    [
                        159.1,
                        1847.4
                    ],
                    [
                        837.2,
                        1847.4
                    ],
                    [
                        837.2,
                        1587.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94439,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "\u2022 Revenue-based method (REV): This method is often used as a benchmark for order dispatching algorithms, meaning that orders with higher prices will be given pri- ority to get dispatched \ufb01rst [10], [13]. In order to apply to the EV \ufb02eet in this article, we set that each EV will be charged when there is no order in the current grid and there is a charger available, otherwise it will stay in the current grid.",
        "type": "ListItem"
    },
    {
        "element_id": "b7bcfb853dab1368b4858371b2a9be3a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        1851.3
                    ],
                    [
                        163.7,
                        1980.3
                    ],
                    [
                        844.3,
                        1980.3
                    ],
                    [
                        844.3,
                        1851.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92438,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "\u2022 REV with rebalancing: Based on REV, we set that when the current grid has no orders and no charger is avail- able, EV will move to the neighboring grid with a larger demand-supply gap.",
        "type": "ListItem"
    },
    {
        "element_id": "90a80db1474a1021c1652d7e27588391",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        162.3,
                        1983.0
                    ],
                    [
                        162.3,
                        2079.9
                    ],
                    [
                        847.0,
                        2079.9
                    ],
                    [
                        847.0,
                        1983.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92453,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "\u2022 REV with CR: Based on REV with rebalancing, we con- strain the number of EVs rebalanced to other grids as in (11f).",
        "type": "ListItem"
    },
    {
        "element_id": "f0f76e71b3ed49fc7d343c3f13e5271b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        892.8,
                        1254.7
                    ],
                    [
                        892.8,
                        1316.1
                    ],
                    [
                        1566.4,
                        1316.1
                    ],
                    [
                        1566.4,
                        1254.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89565,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "\u2022 Proposed method: Our proposed model as detailed in Section III.",
        "type": "ListItem"
    },
    {
        "element_id": "9654c8d18066272ccdf8c99d0a7567ee",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1321.6
                    ],
                    [
                        866.6,
                        1548.5
                    ],
                    [
                        1568.4,
                        1548.5
                    ],
                    [
                        1568.4,
                        1321.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95256,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "The training results of the three DRL-based methods are shown in Fig. 8. One can seen that the use of CR signi\ufb01cantly improves the ef\ufb01ciency of exploration (the performance of the initial episodes are improved) and increases the cumulative reward of \ufb01nal convergence. In addition, the method with- out rebalancing (i.e., DRL-based order and charging dispatch) performed worse than the other two methods.",
        "type": "NarrativeText"
    },
    {
        "element_id": "38ec6d215e9b4d65bd7cec500b5945a3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1554.1
                    ],
                    [
                        866.6,
                        1814.2
                    ],
                    [
                        1567.9,
                        1814.2
                    ],
                    [
                        1567.9,
                        1554.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95344,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "The test results of all methods are shown in Fig. 9. One can seen that the cumulative reward of proposed method is higher than other methods. In addition, the methods without rebalancing (REV, DRL-based order and charging dispatch) are relatively low, while the methods with CR (REV with CR, proposed method) are higher than the methods with conven- tional rebalancing (REV with rebalancing, proposed method without CR).",
        "type": "NarrativeText"
    },
    {
        "element_id": "185e9726b6e026ec5cb708457ddfa909",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1819.8
                    ],
                    [
                        866.6,
                        2079.9
                    ],
                    [
                        1564.7,
                        2079.9
                    ],
                    [
                        1564.7,
                        1819.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95261,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "The one-day trajectory of an EV during the testing phase of different methods is shown in Fig. 10. The starting loca- tion for this EV is the lower left corner of the map where order demand is low. Under the proposed method (Fig. 10(a)), the EV is gradually shifted from the lower left corner to a higher demand area for more order revenue by performing a series of rebalancing dispatches. For the proposed method without CR (Fig. 10(b)), the EV can be rebalanced to areas",
        "type": "NarrativeText"
    },
    {
        "element_id": "35dee0426804f12dcc182cdba8f3e512",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2121.8
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2121.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79653,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "1f0acaf6d2527914cfd8a2543d143f30",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1523.1,
                        80.1
                    ],
                    [
                        1523.1,
                        103.8
                    ],
                    [
                        1565.8,
                        103.8
                    ],
                    [
                        1565.8,
                        80.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.78707,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 8
        },
        "text": "1387",
        "type": "Header"
    },
    {
        "element_id": "4b5323bb75726590b5a9aff3e538bb55",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        133.5,
                        81.0
                    ],
                    [
                        133.5,
                        103.5
                    ],
                    [
                        176.1,
                        103.5
                    ],
                    [
                        176.1,
                        81.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73536,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9
        },
        "text": "1388",
        "type": "Header"
    },
    {
        "element_id": "2c33880af89974764d8717edc03823c1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        936.6,
                        82.6
                    ],
                    [
                        936.6,
                        102.3
                    ],
                    [
                        1564.0,
                        102.3
                    ],
                    [
                        1564.0,
                        82.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.85167,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9
        },
        "text": "IEEE TRANSACTIONS ON SMART GRID, VOL. 12, NO. 2, MARCH 2021",
        "type": "Header"
    },
    {
        "element_id": "e9a7df19c90b39c65c23d833d10b6314",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        156.9,
                        148.3
                    ],
                    [
                        156.9,
                        1678.3
                    ],
                    [
                        812.3,
                        1678.3
                    ],
                    [
                        812.3,
                        148.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-9-10.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9
        },
        "text": "\u2014 Order dispatch \u2014 Rebalancing dispatch 96> | Charging dispatch 72 ~ 48- 24 @",
        "type": "Image"
    },
    {
        "element_id": "42bae70e0f5c13559b03623634ef720e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        886.1,
                        147.2
                    ],
                    [
                        886.1,
                        417.2
                    ],
                    [
                        1544.1,
                        417.2
                    ],
                    [
                        1544.1,
                        147.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-9-11.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9
        },
        "text": "va aa 340 wv ze S$ -+-Proposed method Cumulative reward (k$) 320 Proposed method withont target network \u2014-Proposed method without experience replay 1 2 3 4 5 6 7 8 9 10 Episode",
        "type": "Image"
    },
    {
        "element_id": "b660f8b9dde41d0abbc0a0ea0e864da3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        449.7
                    ],
                    [
                        866.6,
                        521.6
                    ],
                    [
                        1564.7,
                        521.6
                    ],
                    [
                        1564.7,
                        449.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93803,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9
        },
        "text": "Fig. 11. Impact of the target network and experience replay mechanism on the proposed method. Error bars are the 95% con\ufb01dence intervals across 6 random seeds.",
        "type": "FigureCaption"
    },
    {
        "element_id": "65a68b263db8bf4e4547345d26082901",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        886.1,
                        552.6
                    ],
                    [
                        886.1,
                        823.3
                    ],
                    [
                        1544.1,
                        823.3
                    ],
                    [
                        1544.1,
                        552.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-9-12.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9
        },
        "text": "\u20ac 380 g = 360 z 2 2 340 z E320 \u00f6 1 2 3 4 5 6 7 8 9 10 Episode",
        "type": "Image"
    },
    {
        "element_id": "cbf0aa8247d44941d07b368ed8682f46",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.4,
                        855.7
                    ],
                    [
                        866.4,
                        902.8
                    ],
                    [
                        1564.4,
                        902.8
                    ],
                    [
                        1564.4,
                        855.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9
        },
        "text": "Fig. 12. Impact of the discount factor on the proposed method. Error bars are the 95% con\ufb01dence intervals across 6 random seeds.",
        "type": "FigureCaption"
    },
    {
        "element_id": "9c1aeee3479774ae2382b5f669638286",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        970.0
                    ],
                    [
                        866.6,
                        1030.9
                    ],
                    [
                        1564.6,
                        1030.9
                    ],
                    [
                        1564.6,
                        970.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91147,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9
        },
        "text": "lack of vehicle rebalancing prevents the EV from proactively shifting to high-demand areas for additional revenue.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a20b715dd4383989a2e202f984251a7e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1080.4
                    ],
                    [
                        866.6,
                        1108.1
                    ],
                    [
                        1134.4,
                        1108.1
                    ],
                    [
                        1134.4,
                        1080.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.60379,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9
        },
        "text": "C. Stability of Training",
        "type": "Title"
    },
    {
        "element_id": "79b3ba60913bd1861ec2ee789cc6ae0f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1122.4
                    ],
                    [
                        866.6,
                        1316.1
                    ],
                    [
                        1567.6,
                        1316.1
                    ],
                    [
                        1567.6,
                        1122.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94812,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9,
            "parent_id": "a20b715dd4383989a2e202f984251a7e"
        },
        "text": "This subsection analyzes the factors that affect the training stability of the proposed method, including the target network, experience replay mechanism, and discount factor. In addi- tion, comparison with a convergent tabular method is used to re\ufb02ect the near-optimal performance achieved by the proposed method.",
        "type": "NarrativeText"
    },
    {
        "element_id": "1ab5061b5d7a7ba17db66f120ac6cf30",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1321.6
                    ],
                    [
                        866.6,
                        1548.6
                    ],
                    [
                        1566.8,
                        1548.6
                    ],
                    [
                        1566.8,
                        1321.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.955,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9,
            "parent_id": "a20b715dd4383989a2e202f984251a7e"
        },
        "text": "Fig. 11 shows the impact of the target network and experi- ence replay mechanism on the proposed method. The absence of experience replay signi\ufb01cantly reduces the average cumu- lative reward (by 7.05%), while absence of target network reduces it not so much (by 0.86%). The absence of any of these increases the con\ufb01dence interval, i.e., makes the training unstable.",
        "type": "NarrativeText"
    },
    {
        "element_id": "8e173c715f6e27d9e0cd821c185f77f8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1710.8
                    ],
                    [
                        136.0,
                        1782.8
                    ],
                    [
                        833.5,
                        1782.8
                    ],
                    [
                        833.5,
                        1710.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9381,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9,
            "parent_id": "a20b715dd4383989a2e202f984251a7e"
        },
        "text": "Fig. 10. The one-day trajectory of an EV during the testing phase of different methods. (a) Proposed method; (b) Proposed method without CR; (c) REV with CR; (d) DRL-based order and charging dispatch.",
        "type": "FigureCaption"
    },
    {
        "element_id": "27ca55224fb88fd71162f63fb22060d4",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1548.1
                    ],
                    [
                        866.6,
                        1847.4
                    ],
                    [
                        1569.6,
                        1847.4
                    ],
                    [
                        1569.6,
                        1548.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95564,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9,
            "parent_id": "a20b715dd4383989a2e202f984251a7e"
        },
        "text": "Fig. 12 illustrates the impact of the discount factor \u03b3 on the performance of the proposed method. A low discount factor can cause agent to prioritize excessively immediate rewards and become myopic to future rewards [24]; however, targeting a high discount factor may lead to instability or divergence in the state value function estimates, yielding a poor quality policy [38]. Fig. 12 shows that when \u03b3 = 0.9, the proposed method achieves an effective tradeoff between the above two effects, converging to a more pro\ufb01table policy.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f321d1f9dd7c4199912ab7d2ca53ce34",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1853.0
                    ],
                    [
                        136.0,
                        2079.9
                    ],
                    [
                        836.7,
                        2079.9
                    ],
                    [
                        836.7,
                        1853.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95343,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9,
            "parent_id": "a20b715dd4383989a2e202f984251a7e"
        },
        "text": "of high demand but sometimes the rebalancing is repeated between adjacent grids (black dashed circles), resulting in a waste of energy. For REV with CR (Fig. 10(c)), the EV can also be rebalanced to areas of high demand, but this process is circuitous due to the lack of guidance from the state value function (see Fig. 15 for state values at different locations). As for DRL-based order and charge dispatch (Fig. 10(d)), the",
        "type": "NarrativeText"
    },
    {
        "element_id": "281457de06cb041f0be182e4b89560eb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1853.0
                    ],
                    [
                        866.6,
                        2079.9
                    ],
                    [
                        1567.2,
                        2079.9
                    ],
                    [
                        1567.2,
                        1853.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94706,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9,
            "parent_id": "a20b715dd4383989a2e202f984251a7e"
        },
        "text": "We compare the proposed method with the tabular method provided in the Appendix. In the tabular method set- i.e., Ei,t \u2208 ting, we discretize the SOC into 11 levels, {0, 0.1, 0.2, . . . , 1}, and set the thresholds \u03b4 = 2.0 and \u03b4 = 1.5, respectively. The threshold \u03b4 determines the accu- racy of the policy evaluation. Fig. 13 shows the experimental results. It can be seen that the smaller the threshold \u03b4, the",
        "type": "NarrativeText"
    },
    {
        "element_id": "47f8d787290aa053ec7faedb7d91de3c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.5
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.71712,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 9,
            "parent_id": "a20b715dd4383989a2e202f984251a7e"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "6e428baddf805ae46c35dd8569f0849f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        82.6
                    ],
                    [
                        136.0,
                        102.2
                    ],
                    [
                        1126.3,
                        102.2
                    ],
                    [
                        1126.3,
                        82.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83373,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10
        },
        "text": "LIANG et al.: MOBILITY-AWARE CHARGING SCHEDULING FOR SHARED ON-DEMAND EV FLEET USING DRL",
        "type": "Header"
    },
    {
        "element_id": "e7fc3129244af4852efebcecff587ed3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        155.5,
                        146.6
                    ],
                    [
                        155.5,
                        417.2
                    ],
                    [
                        813.5,
                        417.2
                    ],
                    [
                        813.5,
                        146.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-10-13.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10
        },
        "text": "380 w Ss Proposed method +-Tabular method (6 = 2. / \u2014-Tabular method (6 = 1.5) 1 10 20 30 40 50 Episode w Dsi Ss Cumulative reward (k$) we g s",
        "type": "Image"
    },
    {
        "element_id": "1ee843f26325c1a90a10d3b7538523e0",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        449.7
                    ],
                    [
                        136.0,
                        521.6
                    ],
                    [
                        833.4,
                        521.6
                    ],
                    [
                        833.4,
                        449.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93251,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10
        },
        "text": "Fig. 13. Episodic average cumulative reward of EV \ufb02eet for the proposed method and tabular method. Error bars are the 95% con\ufb01dence intervals across 6 random seeds.",
        "type": "FigureCaption"
    },
    {
        "element_id": "baafc2ab3329457f29539e46576b822d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        156.1,
                        552.1
                    ],
                    [
                        156.1,
                        624.4
                    ],
                    [
                        813.3,
                        624.4
                    ],
                    [
                        813.3,
                        552.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.86396,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10
        },
        "text": "TABLE I COMPUTATIONAL TIME TO REACH CONVERGENCE OF THE PROPOSED METHOD AND THE TABULAR METHOD",
        "type": "FigureCaption"
    },
    {
        "element_id": "9e521e9ee23b1719e82844594790af71",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        888.9,
                        148.8
                    ],
                    [
                        888.9,
                        672.8
                    ],
                    [
                        1541.6,
                        672.8
                    ],
                    [
                        1541.6,
                        148.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-10-14.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10
        },
        "text": "\u2014S$0C=0.8 \u2014SOC=0.4 \u2014SOC=0.05 vy ln nl Pe \\ / ig Fron, N 0 x \u2014+t = 60 (15:00) g t = 66 (17:30) 4 t = 76 (19:00) 5 ee a | oz n n 1 4 0 0.2 0.4 0.6 0.8 1 SOC (b)",
        "type": "Image"
    },
    {
        "element_id": "e86e1e3b9964a5cef05c1cfceb5ae9fa",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        143.0,
                        651.0
                    ],
                    [
                        143.0,
                        799.3
                    ],
                    [
                        829.9,
                        799.3
                    ],
                    [
                        829.9,
                        651.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91117,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/table-10-2.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10,
            "text_as_html": "<table><thead><tr><th>Method</th><th>Total time (min)</th><th>Number of . episodes o</th><th>Average time . N per episode (min)</th></tr></thead><tbody><tr><td>Proposed method</td><td>177.38</td><td>10</td><td>17.74</td></tr><tr><td>Tabular method (6 \u2014 2.0)</td><td>321.29</td><td>30</td><td>10.71</td></tr><tr><td>Tabular method (6 \u2014 1.5)</td><td>o 575.82</td><td>50</td><td>11.52</td></tr></tbody></table>"
        },
        "text": "Total time Number of Average time Method . . N (min) episodes o per episode (min) Proposed method 177.38 10 17.74 Tabular method (6 \u2014 2.0) 321.29 30 10.71 Tabular method (6 \u2014 1.5) o 575.82 50 11.52",
        "type": "Table"
    },
    {
        "element_id": "e83e41d7421d1d7f486940b2ad0b547f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        863.2,
                        705.3
                    ],
                    [
                        863.2,
                        752.3
                    ],
                    [
                        1564.0,
                        752.3
                    ],
                    [
                        1564.0,
                        705.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90825,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10
        },
        "text": "Fig. 14. Change in state value of grid 55 over time and SOC. (a) Time; (b) SOC.",
        "type": "FigureCaption"
    },
    {
        "element_id": "b71e364941069f92dc6d885ea383ba95",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.9,
                        869.2
                    ],
                    [
                        135.9,
                        1494.7
                    ],
                    [
                        834.7,
                        1494.7
                    ],
                    [
                        834.7,
                        869.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9492,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10
        },
        "text": "slower the convergence of the tabular method, but the higher the cumulative reward after convergence. In addition, the tab- ular method has a smaller con\ufb01dence interval, i.e., higher stability, but converges signi\ufb01cantly slower than the proposed method. Table I also shows that the total computational time required for the tabular method to reach convergence exceeds that of the proposed method. The slow convergence is due to the fact that the tabular method only updates one state value estimate per update, so EVs need to visit each state and try each action multiple times to get a good estimate. Therefore, the tabular method, although convergent, is computationally and data inef\ufb01cient and can be used as a fallback option in case the proposed method is not convergent. Fortunately, Fig. 13 shows that the proposed method converges well and outperforms the tabular method in terms of average cumula- tive rewards over 50 episodes. The tabular method has been proven to converge to a near-optimal policy (Appendix), which means that the proposed method also achieves a near-optimal performance.",
        "type": "NarrativeText"
    },
    {
        "element_id": "7e979930fc94ddaf35e76c0199a73f29",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        947.2,
                        787.9
                    ],
                    [
                        947.2,
                        1443.2
                    ],
                    [
                        1482.6,
                        1443.2
                    ],
                    [
                        1482.6,
                        787.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-10-15.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10
        },
        "text": "(b)",
        "type": "Image"
    },
    {
        "element_id": "f1508a2f0c95bb9e9fce7d4e80777014",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1470.9
                    ],
                    [
                        866.6,
                        1497.8
                    ],
                    [
                        1564.4,
                        1497.8
                    ],
                    [
                        1564.4,
                        1470.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87417,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10
        },
        "text": "Fig. 15. State value at different locations. (a) SOC = 0.8; (b) SOC = 0.05.",
        "type": "FigureCaption"
    },
    {
        "element_id": "ccc4931a23a0abb60f5f70928cb1e80b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.9,
                        1545.4
                    ],
                    [
                        135.9,
                        1573.1
                    ],
                    [
                        407.4,
                        1573.1
                    ],
                    [
                        407.4,
                        1545.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.53595,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10
        },
        "text": "D. State Value Analysis",
        "type": "Title"
    },
    {
        "element_id": "5ab9c6e3e740348c2afd33bfe3df48e8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1587.1
                    ],
                    [
                        136.0,
                        2079.9
                    ],
                    [
                        834.3,
                        2079.9
                    ],
                    [
                        834.3,
                        1587.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95133,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10,
            "parent_id": "ccc4931a23a0abb60f5f70928cb1e80b"
        },
        "text": "We analyze the changes in state value over time, SOC, and location based on trained neural network. Fig. 14 shows the state value in grid 55 as a function of time and SOC. Fig. 14(a) re\ufb02ects that the change in state value is similar every day: it is higher before the peak demand period and lower before the peak charge period (at about t = 96, i.e., 24:00). Figs. 14(a) and (b) both re\ufb02ect a positive correlation between state value and SOC. In addition, comparing curve t = 60 (15:00) and curve t = 66 (17:30) in Fig. 14(b), it can be found that when SOC > 0.2, the state value is similar, but as SOC approaches 0, the downward trend of curve t = 66 (17:30) is more obvi- ous. This is because it is only 1.5 hours from 17:30 to the end of the peak demand (as shown in Fig. 7), so the EV with small SOC will lose this important order revenue because it needs to be charged \ufb01rst.",
        "type": "NarrativeText"
    },
    {
        "element_id": "67a0234918d9640d94d4a5677283f1da",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1568.8
                    ],
                    [
                        866.6,
                        1795.7
                    ],
                    [
                        1569.5,
                        1795.7
                    ],
                    [
                        1569.5,
                        1568.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9582,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10,
            "parent_id": "ccc4931a23a0abb60f5f70928cb1e80b"
        },
        "text": "We next analyze the state value in different locations. Fig. 15 shows the state value of two different SOCs at 08:00 on Thursday. It can be seen that when SOC = 0.8, the state value near the high-demand area is higher, but when SOC = 0.05, the rechargeable grids, especially the grids with lower elec- tricity prices (see Fig. 16(a) for charging prices), have higher state value.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d23fd998f1c5b4dfb50b879c3e3099b7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1843.2
                    ],
                    [
                        866.6,
                        1871.9
                    ],
                    [
                        1485.6,
                        1871.9
                    ],
                    [
                        1485.6,
                        1843.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.56636,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10,
            "parent_id": "ccc4931a23a0abb60f5f70928cb1e80b"
        },
        "text": "E. Impact of Different Electricity Pricing Mechanisms",
        "type": "ListItem"
    },
    {
        "element_id": "02114f4466f0db95dfe8473a73281e85",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1886.2
                    ],
                    [
                        866.6,
                        1947.1
                    ],
                    [
                        1566.6,
                        1947.1
                    ],
                    [
                        1566.6,
                        1886.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89144,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10,
            "parent_id": "ccc4931a23a0abb60f5f70928cb1e80b"
        },
        "text": "We analyze the impact of four different electricity pricing mechanisms on charging behavior:",
        "type": "NarrativeText"
    },
    {
        "element_id": "01759d965e29952faac92d5dfa8acc8d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        891.4,
                        1952.6
                    ],
                    [
                        891.4,
                        2079.9
                    ],
                    [
                        1567.2,
                        2079.9
                    ],
                    [
                        1567.2,
                        1952.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93231,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10,
            "parent_id": "ccc4931a23a0abb60f5f70928cb1e80b"
        },
        "text": "\u2022 Price varies both with time and location. This is the default setting. As described in Section IV-A, the charg- ing price changes every time step and varies from one rechargeable area to another.",
        "type": "ListItem"
    },
    {
        "element_id": "4407b2021bdd720dacc96abdccb91a92",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2121.8
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2121.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.75632,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10,
            "parent_id": "ccc4931a23a0abb60f5f70928cb1e80b"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ffd81978e4dc1cf9ae90e229c6afc08e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1523.3,
                        81.3
                    ],
                    [
                        1523.3,
                        103.4
                    ],
                    [
                        1567.1,
                        103.4
                    ],
                    [
                        1567.1,
                        81.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.77536,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 10
        },
        "text": "1389",
        "type": "Header"
    },
    {
        "element_id": "00a091cc1102980d08f124e9fce6cd08",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        133.3,
                        80.8
                    ],
                    [
                        133.3,
                        102.9
                    ],
                    [
                        178.0,
                        102.9
                    ],
                    [
                        178.0,
                        80.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74614,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11
        },
        "text": "1390",
        "type": "Header"
    },
    {
        "element_id": "45e7f4ee881dfe48b141bd460e1948c9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        934.2,
                        82.6
                    ],
                    [
                        934.2,
                        102.3
                    ],
                    [
                        1564.0,
                        102.3
                    ],
                    [
                        1564.0,
                        82.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84256,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11
        },
        "text": "IEEE TRANSACTIONS ON SMART GRID, VOL. 12, NO. 2, MARCH 2021",
        "type": "Header"
    },
    {
        "element_id": "5de69d21547f4998465971d75e0f0bdb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        143.0,
                        147.3
                    ],
                    [
                        143.0,
                        1470.0
                    ],
                    [
                        827.7,
                        1470.0
                    ],
                    [
                        827.7,
                        147.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-11-16.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11
        },
        "text": "250 Hs Number of charging EVs in Gi (BE Number of charging EVs in Gi 55 Number of charging EVs in G\u00f6\u00bb 200 \u2014Total number of available orders / 10 \u2014 Charging price in G# \u2014Charging price in G3\" Sharging price in Gj? 0 4 8 12 16 20 24 Hour (b) 150 S\u0130 bi 048 \u00a9 & 100 ROJ \u0130zi a 028 50 a 0 0 0 4 8 12 16 20 24 Hour (d)",
        "type": "Image"
    },
    {
        "element_id": "ee139acd71c1900825bc58086cacb4db",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.4,
                        1502.5
                    ],
                    [
                        135.4,
                        1599.3
                    ],
                    [
                        833.5,
                        1599.3
                    ],
                    [
                        833.5,
                        1502.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94832,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11
        },
        "text": "Fig. 16. The variation in the number of charging EVs during a typical day for different pricing mechanisms. (a) Price varies both with time and location; (b) Price does not vary with time but with location; (c) Price varies with time but not with location; (d) Price varies neither with time nor with location.",
        "type": "FigureCaption"
    },
    {
        "element_id": "b5765e7e52f355529583e258cce1e0ca",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        159.3
                    ],
                    [
                        866.6,
                        187.0
                    ],
                    [
                        1563.9,
                        187.0
                    ],
                    [
                        1563.9,
                        159.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11
        },
        "text": "also plotted the total number of available orders and the elec-",
        "type": "NarrativeText"
    },
    {
        "element_id": "58564d59e82ef9d077d4b498cb6ca83a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        167.1
                    ],
                    [
                        866.6,
                        953.1
                    ],
                    [
                        1566.7,
                        953.1
                    ],
                    [
                        1566.7,
                        167.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94599,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11
        },
        "text": "tricity price of each rechargeable area during this period. For prices that vary with time and location, Fig. 16(a) shows that in the early morning hours when electricity prices and demand are lower, there are more EVs charged, while in the after- noon and evening hours when electricity prices and demand are higher, fewer EVs are charged. In addition, it can be seen that the number of charging EVs in area Gch is generally the 1 largest. This shows that although area Gch is far from the 1 high-demand area, its lower electricity price still attracts a large number of EVs by choosing a series of movable dis- patches (order or rebalancing dispatch) to be recharged here. Comparing Figs. 16(a) and (b), it can be seen that the charg- ing behavior does not change much after the price change cycle becomes one day. This is because the impact of price and demand on charging behavior is similar. For example, the order demand and electricity price every afternoon are high, and any of these factors will hinder EV charging. Figs. 16(c) and (d) re\ufb02ect that when the price of the entire area is the same, the number of EVs selected to charge in area Gch 1 greatly reduced, which is because area Gch 1 is far from the high- is demand area. In addition, Fig. 16(d) re\ufb02ects that the charging distribution is no longer affected by price \ufb02uctuations and the randomness is reduced.",
        "type": "NarrativeText"
    },
    {
        "element_id": "881d142a575fb8b7716b1881191e3f1d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1116.0,
                        998.0
                    ],
                    [
                        1116.0,
                        1025.7
                    ],
                    [
                        1314.8,
                        1025.7
                    ],
                    [
                        1314.8,
                        998.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11
        },
        "text": "V. CONCLUSION",
        "type": "Title"
    },
    {
        "element_id": "6f56170979b7731dbef88ef9e2c2e975",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1039.9
                    ],
                    [
                        866.6,
                        1599.0
                    ],
                    [
                        1568.6,
                        1599.0
                    ],
                    [
                        1568.6,
                        1039.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94897,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11,
            "parent_id": "881d142a575fb8b7716b1881191e3f1d"
        },
        "text": "In this article, we model the joint optimization framework combining charging scheduling, order dispatching and vehi- cle rebalancing for large-scale shared on-demand EV \ufb02eet operator as a POMDP, and develop a near-optimal solution method based on DRL and BLP. A simulation experiment based on city-scale real-world data from Haikou City shows that the overall pro\ufb01t can be signi\ufb01cantly increased by coordi- nating those scheduling decisions and dynamically responding to order demand and charging prices, such as rebalancing EVs to high demand areas (or low electricity price areas) to increase order revenue (or reduce charging costs). In addition, the proposed constrained rebalancing method signif- icantly improves the exploration ef\ufb01ciency of training and can improve the performance of conventional policies. Moreover, we provide a tabular method with proved convergence as a fallback option to demonstrate the near-optimal characteristics of the proposed approach.",
        "type": "NarrativeText"
    },
    {
        "element_id": "4b2e69a6985680ef8e9e69af61d2febc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        160.2,
                        1686.3
                    ],
                    [
                        160.2,
                        1781.0
                    ],
                    [
                        835.4,
                        1781.0
                    ],
                    [
                        835.4,
                        1686.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9214,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11,
            "parent_id": "881d142a575fb8b7716b1881191e3f1d"
        },
        "text": "\u2022 Price does not vary with time but with location. The new charging price is the average price of all time steps in one day.",
        "type": "ListItem"
    },
    {
        "element_id": "79e4df8cb9defb60be74a988c07152d5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        160.5,
                        1786.5
                    ],
                    [
                        160.5,
                        1880.6
                    ],
                    [
                        840.1,
                        1880.6
                    ],
                    [
                        840.1,
                        1786.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92647,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11,
            "parent_id": "881d142a575fb8b7716b1881191e3f1d"
        },
        "text": "\u2022 Price varies with time but not with location. The new charging price is the average price for the entire study area.",
        "type": "ListItem"
    },
    {
        "element_id": "76b9f54f97cac7ba43439989c8e11eeb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1604.5
                    ],
                    [
                        866.6,
                        1864.7
                    ],
                    [
                        1567.4,
                        1864.7
                    ],
                    [
                        1567.4,
                        1604.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95739,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11,
            "parent_id": "881d142a575fb8b7716b1881191e3f1d"
        },
        "text": "Future work can be model the scheduling process in more detail: For order dispatching, we will consider that an EV can simultaneously carry multiple passengers with different des- tinations; for charging scheduling, we will consider that EVs can be discharged to the grid for participating power mar- ket. In addition, we will consider bene\ufb01ts to participants other than EV \ufb02eet operator, such as passenger waiting costs, to maximize social welfare.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d13ade60c7de1899f5ad153ebf60a6c4",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        162.7,
                        1886.2
                    ],
                    [
                        162.7,
                        1980.3
                    ],
                    [
                        842.8,
                        1980.3
                    ],
                    [
                        842.8,
                        1886.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91637,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11,
            "parent_id": "881d142a575fb8b7716b1881191e3f1d"
        },
        "text": "\u2022 Price varies neither with time nor with location. The new charging price is the average price of all time steps throughout the study area in one day.",
        "type": "ListItem"
    },
    {
        "element_id": "09591abe97f963a1e6d44de5c0b155e1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1153.8,
                        1910.7
                    ],
                    [
                        1153.8,
                        1938.4
                    ],
                    [
                        1277.0,
                        1938.4
                    ],
                    [
                        1277.0,
                        1910.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11
        },
        "text": "APPENDIX",
        "type": "Title"
    },
    {
        "element_id": "bcf003c4fe429c8540a52728a2d19437",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1011.6,
                        1943.9
                    ],
                    [
                        1011.6,
                        1971.5
                    ],
                    [
                        1418.8,
                        1971.5
                    ],
                    [
                        1418.8,
                        1943.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.62732,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11
        },
        "text": "CONVERGENT TABULAR METHOD",
        "type": "Title"
    },
    {
        "element_id": "3ddcbae4c9d5135d67afef90a48451f9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1985.5
                    ],
                    [
                        136.0,
                        2079.9
                    ],
                    [
                        844.8,
                        2079.9
                    ],
                    [
                        844.8,
                        1985.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9045,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11,
            "parent_id": "bcf003c4fe429c8540a52728a2d19437"
        },
        "text": "The variation in the number of charging EVs during a typi- cal day for different pricing mechanisms is shown in Fig. 16. In order to analyze the distribution of charging behavior, we",
        "type": "NarrativeText"
    },
    {
        "element_id": "5681abaf5325fdcabc5d9cd07b9c183c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1985.8
                    ],
                    [
                        866.6,
                        2079.9
                    ],
                    [
                        1566.1,
                        2079.9
                    ],
                    [
                        1566.1,
                        1985.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92271,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11,
            "parent_id": "bcf003c4fe429c8540a52728a2d19437"
        },
        "text": "We provide a tabular method for the EV \ufb02eet scheduling problem as shown in Algorithm 2. Due to the use of tables, we have to discretize the continuous state variable SOC, which",
        "type": "NarrativeText"
    },
    {
        "element_id": "0c1eed3a588e109b34e0d345c618ffdf",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.1
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72386,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 11,
            "parent_id": "bcf003c4fe429c8540a52728a2d19437"
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "024afba2f3f7e868da2c6e4a402c9253",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        82.6
                    ],
                    [
                        136.0,
                        102.2
                    ],
                    [
                        1126.3,
                        102.2
                    ],
                    [
                        1126.3,
                        82.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84571,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "LIANG et al.: MOBILITY-AWARE CHARGING SCHEDULING FOR SHARED ON-DEMAND EV FLEET USING DRL",
        "type": "Header"
    },
    {
        "element_id": "603dc76192e4bfeed2a5b6421042a8de",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1522.6,
                        80.2
                    ],
                    [
                        1522.6,
                        103.6
                    ],
                    [
                        1565.4,
                        103.6
                    ],
                    [
                        1565.4,
                        80.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80397,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "1391",
        "type": "Header"
    },
    {
        "element_id": "c1a6d68c93f7a64f0a88fb90363b4757",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        149.8,
                        161.2
                    ],
                    [
                        149.8,
                        188.9
                    ],
                    [
                        782.7,
                        188.9
                    ],
                    [
                        782.7,
                        161.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "603dc76192e4bfeed2a5b6421042a8de"
        },
        "text": "Algorithm 2: Tabular Method for EV Fleet Scheduling",
        "type": "Title"
    },
    {
        "element_id": "1927a265f824f0e28136813cd651c37c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        140.2,
                        172.5
                    ],
                    [
                        140.2,
                        891.9
                    ],
                    [
                        816.2,
                        891.9
                    ],
                    [
                        816.2,
                        172.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.60623,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "c1a6d68c93f7a64f0a88fb90363b4757"
        },
        "text": "Algorithm EV Scheduling 1 For all se S, V(s) \u2014 0, V\u2019(s) \u2014 oo; 2 Policy Evaluation: For all s e S, N(s) \u2014 0; while ||V\u2019 \u2014 Vil.o > 5 do Vel; for time step t= 0 to T\u20141 do foreach a; \u20ac 7(s,) do Take action a;, observe rj and sjj; N(si) \u2014 N(si) + 1; V(si) \u2014 Vos) + yoy ly ty iV(sy) \u2014 Vis] 3 Policy Improvement: policy-stable \u2014 true; foreach s, \u20ac S, do old-action \u2014 1 (Sg); (8g) \u2014 argmax,, Diez, [ij + yIV (sis if old-action # (sg) then policy-stable < false; if policy-stable then stop and return V and z else go to 2;",
        "type": "NarrativeText"
    },
    {
        "element_id": "56fd0bb3f2816d95a5eb88bc5b3ad5eb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        159.3
                    ],
                    [
                        866.6,
                        220.2
                    ],
                    [
                        1569.6,
                        220.2
                    ],
                    [
                        1569.6,
                        159.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91768,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "c1a6d68c93f7a64f0a88fb90363b4757"
        },
        "text": "converges to zero with probability 1 (w.p.1) under the follow- ing assumptions: leftmargin=*",
        "type": "NarrativeText"
    },
    {
        "element_id": "784fe00085025a9ef88a5d808b4204c7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        225.7
                    ],
                    [
                        894.3,
                        253.4
                    ],
                    [
                        1211.0,
                        253.4
                    ],
                    [
                        1211.0,
                        225.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "c1a6d68c93f7a64f0a88fb90363b4757"
        },
        "text": "1) The state space is \ufb01nite;",
        "type": "ListItem"
    },
    {
        "element_id": "056e978c76711e703476e90cb95b6e26",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        252.9
                    ],
                    [
                        894.3,
                        289.3
                    ],
                    [
                        1103.9,
                        289.3
                    ],
                    [
                        1103.9,
                        252.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "c1a6d68c93f7a64f0a88fb90363b4757"
        },
        "text": "2) 0 \u2264 \u03b1n(x) \u2264 1,",
        "type": "ListItem"
    },
    {
        "element_id": "9132a78a0f2b879a17b529f8f41f5b57",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1154.0,
                        252.9
                    ],
                    [
                        1154.0,
                        289.3
                    ],
                    [
                        1338.7,
                        289.3
                    ],
                    [
                        1338.7,
                        252.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "603dc76192e4bfeed2a5b6421042a8de"
        },
        "text": "\u03b1n(x) = \u221e, and",
        "type": "Title"
    },
    {
        "element_id": "ca4fb0d6d1123cdcde073b17ab7ecab6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1393.8,
                        252.9
                    ],
                    [
                        1393.8,
                        280.6
                    ],
                    [
                        1421.3,
                        280.6
                    ],
                    [
                        1421.3,
                        252.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "603dc76192e4bfeed2a5b6421042a8de"
        },
        "text": "\u03b12",
        "type": "Title"
    },
    {
        "element_id": "ecb77aae820837a8de5c29ef2b4f2252",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1422.6,
                        252.9
                    ],
                    [
                        1422.6,
                        286.6
                    ],
                    [
                        1528.6,
                        286.6
                    ],
                    [
                        1528.6,
                        252.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "ca4fb0d6d1123cdcde073b17ab7ecab6"
        },
        "text": "(x) < \u221e;",
        "type": "UncategorizedText"
    },
    {
        "element_id": "63026660dddd6361f87cc18b4978a0b9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        896.9,
                        261.4
                    ],
                    [
                        896.9,
                        285.8
                    ],
                    [
                        1543.7,
                        285.8
                    ],
                    [
                        1543.7,
                        261.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.74659,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "ca4fb0d6d1123cdcde073b17ab7ecab6"
        },
        "text": "2) 0 < a(x) < 1,0, n(x) = 00, and X,, a2 (x) < 00;",
        "type": "ListItem"
    },
    {
        "element_id": "c71322a4f73d1491d56bf71c73eec4e9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1409.7,
                        271.6
                    ],
                    [
                        1409.7,
                        292.6
                    ],
                    [
                        1420.2,
                        292.6
                    ],
                    [
                        1420.2,
                        271.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "603dc76192e4bfeed2a5b6421042a8de"
        },
        "text": "n",
        "type": "Title"
    },
    {
        "element_id": "35ca69eefc9c48d3aa4171a8a1e1668f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1137.5,
                        272.1
                    ],
                    [
                        1137.5,
                        293.1
                    ],
                    [
                        1148.0,
                        293.1
                    ],
                    [
                        1148.0,
                        272.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "603dc76192e4bfeed2a5b6421042a8de"
        },
        "text": "n",
        "type": "Title"
    },
    {
        "element_id": "17f70b64b89597be9b11f399e603723f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1377.3,
                        272.1
                    ],
                    [
                        1377.3,
                        293.1
                    ],
                    [
                        1387.9,
                        293.1
                    ],
                    [
                        1387.9,
                        272.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "603dc76192e4bfeed2a5b6421042a8de"
        },
        "text": "n",
        "type": "Title"
    },
    {
        "element_id": "14e7748366e014ec41c180a3043e5ccf",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        286.1
                    ],
                    [
                        894.3,
                        355.7
                    ],
                    [
                        1564.0,
                        355.7
                    ],
                    [
                        1564.0,
                        286.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83376,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "17f70b64b89597be9b11f399e603723f"
        },
        "text": "3) |ELFn@)|Falllw <vllOnllw +en, where y \u20ac (0, 1) and Cn converges to zero w.p.1;",
        "type": "ListItem"
    },
    {
        "element_id": "0ddf59337b2b47820d16a78d8502ac3c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        352.6
                    ],
                    [
                        866.6,
                        488.6
                    ],
                    [
                        1564.0,
                        488.6
                    ],
                    [
                        1564.0,
                        352.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9355,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "17f70b64b89597be9b11f399e603723f"
        },
        "text": "4) var[Fn(x)|Fn] < KA + Onl?) with constant K > 0. Here F, denotes the filtration of an increasing sequence of o-fields including the history of processes; a, On, Fn \u20ac Fn and || - ||w is a weighted maximum norm [39].",
        "type": "NarrativeText"
    },
    {
        "element_id": "3185b9c0fc98751561dfca7a4609f5f5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        491.4
                    ],
                    [
                        866.6,
                        552.3
                    ],
                    [
                        1567.0,
                        552.3
                    ],
                    [
                        1567.0,
                        491.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89781,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "17f70b64b89597be9b11f399e603723f"
        },
        "text": "Proof: See [40, Th. 1] and [41, Corollary 5] for detailed derivation.",
        "type": "NarrativeText"
    },
    {
        "element_id": "2b3708e3255f78d016224873fc8d325f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        548.4
                    ],
                    [
                        894.3,
                        585.5
                    ],
                    [
                        1564.0,
                        585.5
                    ],
                    [
                        1564.0,
                        548.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "17f70b64b89597be9b11f399e603723f"
        },
        "text": "Lemma 2: Let 7 and x\u2019 be any pair of deterministic",
        "type": "NarrativeText"
    },
    {
        "element_id": "c0838c7bae2aa740b2f7521798ce57be",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        560.0
                    ],
                    [
                        866.6,
                        618.7
                    ],
                    [
                        1564.4,
                        618.7
                    ],
                    [
                        1564.4,
                        560.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91741,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "17f70b64b89597be9b11f399e603723f"
        },
        "text": "policies such that, for all s \u2208 SG,",
        "type": "NarrativeText"
    },
    {
        "element_id": "b50872ebdadb9dcab1a5b296277b4d84",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        981.0,
                        630.4
                    ],
                    [
                        981.0,
                        691.2
                    ],
                    [
                        1431.2,
                        691.2
                    ],
                    [
                        1431.2,
                        630.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.82232,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "x\u2019 (s) = arg max E[r, + y Vz (8;41)|8, a] a",
        "type": "Formula"
    },
    {
        "element_id": "a11a0984bc256fd464f54225e35deb41",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        697.1
                    ],
                    [
                        866.6,
                        764.0
                    ],
                    [
                        1563.9,
                        764.0
                    ],
                    [
                        1563.9,
                        697.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91372,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "Then V, > Vx. Moreover if 7 is not optimal, strict inequality holds in this inequality for at least one state.",
        "type": "NarrativeText"
    },
    {
        "element_id": "873dcbaebd6143befa6a46d9371cadcc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        769.6
                    ],
                    [
                        894.3,
                        797.2
                    ],
                    [
                        1077.6,
                        797.2
                    ],
                    [
                        1077.6,
                        769.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.69929,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "Proof: See [24].",
        "type": "NarrativeText"
    },
    {
        "element_id": "4192a1b28371d5373d0cece80049ad91",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        802.8
                    ],
                    [
                        866.6,
                        896.9
                    ],
                    [
                        1564.1,
                        896.9
                    ],
                    [
                        1564.1,
                        802.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92272,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "For the policy evaluation in Algorithm 2, we de\ufb01ne the n-th updated value of N(s) to be \u03b1n(s), then \u03b1n(s) = 1 1 n . We next prove that the policy evaluation is convergent:",
        "type": "NarrativeText"
    },
    {
        "element_id": "f100cc186cce527d9d7a4bdd7409f39c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1548.0,
                        775.0
                    ],
                    [
                        1548.0,
                        791.0
                    ],
                    [
                        1564.0,
                        791.0
                    ],
                    [
                        1564.0,
                        775.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "m",
        "type": "Title"
    },
    {
        "element_id": "e7743b904d5f5d4bc35737253d7bddc2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        960.7
                    ],
                    [
                        136.0,
                        1220.8
                    ],
                    [
                        834.9,
                        1220.8
                    ],
                    [
                        834.9,
                        960.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95401,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "f100cc186cce527d9d7a4bdd7409f39c"
        },
        "text": "is often used in previous methods [1], [20]. In this way, the scheduling problem satis\ufb01es the de\ufb01nition of a \ufb01nite MDP: the sets of states, actions, and rewards all have a \ufb01nite number of elements. In addition, the tabular setting no longer relies on the experience replay mechanism, which is used to stabilize the training of neural networks but requires off-policy learning. Based on these, we will prove the convergence of the tabular method.",
        "type": "NarrativeText"
    },
    {
        "element_id": "e278a25e3e92e9c5ba9b388f99e92a6b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        896.4
                    ],
                    [
                        866.6,
                        996.5
                    ],
                    [
                        1567.9,
                        996.5
                    ],
                    [
                        1567.9,
                        896.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93402,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12,
            "parent_id": "f100cc186cce527d9d7a4bdd7409f39c"
        },
        "text": "Theorem 1: For any \ufb01nite MDP with a given policy \u03c0 and the current estimated value function V(s), the policy evaluation algorithm given by",
        "type": "NarrativeText"
    },
    {
        "element_id": "0648084bd2ccccefc9a683f86c56da2b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        903.0,
                        1008.2
                    ],
                    [
                        903.0,
                        1052.7
                    ],
                    [
                        1564.0,
                        1052.7
                    ],
                    [
                        1564.0,
                        1008.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.66872,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "Vu (si) = Vals) + ns) [ry y\u00fc Va (si) \u2014 Vn(si)] (18)",
        "type": "Formula"
    },
    {
        "element_id": "17307827d15be5610175537ef4d1149e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1063.2
                    ],
                    [
                        866.6,
                        1138.4
                    ],
                    [
                        1563.9,
                        1138.4
                    ],
                    [
                        1563.9,
                        1063.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9046,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "converges to the true value function V\u03c0 (s) w.p.1 provided \u03b1n(s) = 1 n and \u03b3 \u2208 [0, 1).",
        "type": "NarrativeText"
    },
    {
        "element_id": "41211203403b99151a384c4ac20f87c9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        1135.6
                    ],
                    [
                        894.3,
                        1163.3
                    ],
                    [
                        1309.9,
                        1163.3
                    ],
                    [
                        1309.9,
                        1135.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83753,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "Proof: We start by rewriting (18) as",
        "type": "NarrativeText"
    },
    {
        "element_id": "0238375e1ac6f6605d68f2453395e1ef",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        886.4,
                        1175.0
                    ],
                    [
                        886.4,
                        1216.2
                    ],
                    [
                        1526.0,
                        1216.2
                    ],
                    [
                        1526.0,
                        1175.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.58276,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "Vn41(si) = (1 \u2014 pls) Vasi) + on(si) [rj + \u00a5*\"Vn(sif)]",
        "type": "Formula"
    },
    {
        "element_id": "49c77179a24b8b790ead355fe9cc5409",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1226.4
                    ],
                    [
                        136.0,
                        1428.1
                    ],
                    [
                        833.4,
                        1428.1
                    ],
                    [
                        833.4,
                        1226.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93717,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "In order to facilitate the proof, we first describe the joint scheduling problem from the perspective of the entire fleet: At each time step t the EV fleet receives a global state s, \u20ac Sg, takes an action a; = aile, TI and receives a scalar reward =). Yer; Fi\u015f, Where Tf denotes the set of all EVs (including available and unavailable EVs) in grid g.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c41e23c45b83dbfa16c1187b35c0b737",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        1433.6
                    ],
                    [
                        163.7,
                        1461.3
                    ],
                    [
                        655.7,
                        1461.3
                    ],
                    [
                        655.7,
                        1433.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.56236,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "We start from introducing the assumptions:",
        "type": "NarrativeText"
    },
    {
        "element_id": "70a0fb9282fdde69758e9a9aafa504c8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        1466.8
                    ],
                    [
                        163.7,
                        1494.5
                    ],
                    [
                        765.4,
                        1494.5
                    ],
                    [
                        765.4,
                        1466.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.56936,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "Assumption 1: Each state is visited in\ufb01nitely often.",
        "type": "NarrativeText"
    },
    {
        "element_id": "667a47b41e20bd9b14b352eb48f04f9a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1500.1
                    ],
                    [
                        136.0,
                        1603.7
                    ],
                    [
                        833.4,
                        1603.7
                    ],
                    [
                        833.4,
                        1500.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90232,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "Assumption 2: The state value function of the entire EV fleet V,,(s) equals the summation of the individual EVs\u2019 state value functions, i.e., Vz(s) = >, Bir\u015f V (si).",
        "type": "NarrativeText"
    },
    {
        "element_id": "9777b0ee9cf75d098b1fdd8628dbc7c1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1229.9
                    ],
                    [
                        866.6,
                        1366.0
                    ],
                    [
                        1565.2,
                        1366.0
                    ],
                    [
                        1565.2,
                        1229.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92539,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "To apply Lemma 1 we subtract V,(5) from both sides of the above equation. If we write \u00a9,(s) = V,(s) \u2014 Vr(s) and Fy(s) = ry + y\u201cVn(si) \u2014 Vz (5), we have On41(s) = (1 = an(s))On(s) + On()Fn(s).",
        "type": "NarrativeText"
    },
    {
        "element_id": "ca2c3d8b5ae187aed3ad72657105ae95",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1368.8
                    ],
                    [
                        866.6,
                        1527.1
                    ],
                    [
                        1564.0,
                        1527.1
                    ],
                    [
                        1564.0,
                        1368.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93428,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "The harmonic series is a divergent infinite series, i.e., nel i = oo. Notice that since a,(s) = i < 1, y, An(s) = o requires that all states be visited infinitely often. 17, @2(s) = DD \u0130S convergent with an exact sum of 7 [42],",
        "type": "NarrativeText"
    },
    {
        "element_id": "c846a2861fb4a458559c206b492304d9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        872.0,
                        1502.1
                    ],
                    [
                        872.0,
                        1538.1
                    ],
                    [
                        950.7,
                        1538.1
                    ],
                    [
                        950.7,
                        1502.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "6 [42].",
        "type": "UncategorizedText"
    },
    {
        "element_id": "10a6d5cd37357f40c7701d24cc92518b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1535.3
                    ],
                    [
                        866.6,
                        1598.9
                    ],
                    [
                        1563.9,
                        1598.9
                    ],
                    [
                        1563.9,
                        1535.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90338,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "The error reduction property of multi-step returns [24] guarantees that for any Af; > 1,",
        "type": "NarrativeText"
    },
    {
        "element_id": "bdc63322c3290346aba8ca187f4efe37",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        135.4,
                        1600.6
                    ],
                    [
                        135.4,
                        1727.9
                    ],
                    [
                        833.3,
                        1727.9
                    ],
                    [
                        833.3,
                        1600.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93656,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "Assumption 3: All EVs are homogeneous, i.e., they have same the battery capacity, power consumption, and travel speed, so that they can share the same state value func- tion V(s).",
        "type": "NarrativeText"
    },
    {
        "element_id": "6a95314c8e4c0eabe5094cfb0ee97e2b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1733.4
                    ],
                    [
                        136.0,
                        1960.3
                    ],
                    [
                        833.4,
                        1960.3
                    ],
                    [
                        833.4,
                        1733.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9509,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "Note that Assumptions 2 and 3 have been used to address the curse of dimensionality of dealing with the entire \ufb02eet\u2019s state domain [8], [11], [13]. We have also used these two assumptions in our proposed DRL-based method: Assumption 2 for formulating a decentralized scheduling pol- icy (Section II-E) and Assumption 3 for sharing the neural network (Section III-B).",
        "type": "NarrativeText"
    },
    {
        "element_id": "34613210e37d8387c5fb49ac1d51e551",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        932.8,
                        1612.3
                    ],
                    [
                        932.8,
                        1769.4
                    ],
                    [
                        1506.7,
                        1769.4
                    ],
                    [
                        1506.7,
                        1612.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89491,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "max|E, [Fn(si)|si = sll = max| Ezlrij + yy, (sy)lsi > 8] \u2014 Vx (s)]| = yi maxl V, (5) \u2014 Ve (3)|",
        "type": "Formula"
    },
    {
        "element_id": "0cfa440966969836ed284d213553d2be",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1782.2
                    ],
                    [
                        866.6,
                        1876.3
                    ],
                    [
                        1564.0,
                        1876.3
                    ],
                    [
                        1564.0,
                        1782.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93387,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "which means the multi-step look-ahead reward gives a smaller worst-case error in the estimation of the true value function. It is now immediate from the above formula that",
        "type": "NarrativeText"
    },
    {
        "element_id": "9c1b1d264821259ff834e71120b5f030",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        973.9,
                        1888.0
                    ],
                    [
                        973.9,
                        1973.1
                    ],
                    [
                        1458.0,
                        1973.1
                    ],
                    [
                        1458.0,
                        1888.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.77582,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "ELF n(s)|Fallloo < \u00a5 \"I Vn (8) \u2014 Vir (Yag < Y\u0130V) \u2014 Vela = Yl @nlloo",
        "type": "Formula"
    },
    {
        "element_id": "6fbf87f301d1eab177d3b0538b4eaf89",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        160.5,
                        1965.9
                    ],
                    [
                        160.5,
                        2029.5
                    ],
                    [
                        808.8,
                        2029.5
                    ],
                    [
                        808.8,
                        1965.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91285,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "Our proof is also built upon the two lemmas as follows: Lemma 1: The random process {@,} defined in R as",
        "type": "NarrativeText"
    },
    {
        "element_id": "bfe2b1879dd4d732cb629625ad3425f0",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        234.6,
                        2046.2
                    ],
                    [
                        234.6,
                        2082.6
                    ],
                    [
                        718.2,
                        2082.6
                    ],
                    [
                        718.2,
                        2046.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "On) = CL \u2014 Gn (X))On(\u00ae) + On (0) Fn)",
        "type": "UncategorizedText"
    },
    {
        "element_id": "fef8bfefcdde20f51071ad8605d8034e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        894.3,
                        1990.5
                    ],
                    [
                        894.3,
                        2018.2
                    ],
                    [
                        978.8,
                        2018.2
                    ],
                    [
                        978.8,
                        1990.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84303,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "Finally,",
        "type": "NarrativeText"
    },
    {
        "element_id": "e21b6960b64f0148ab20e5a648ec6955",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        909.3,
                        2029.9
                    ],
                    [
                        909.3,
                        2090.5
                    ],
                    [
                        1419.3,
                        2090.5
                    ],
                    [
                        1419.3,
                        2029.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.75022,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "var[Fn(s)|Fn] = E (Fn(s) \u2212 E[Fn(s)])2|Fn",
        "type": "Formula"
    },
    {
        "element_id": "c04c79e74529b38302535757fe1f0c87",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.3
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.83456,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 12
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "de8800b47c10a880908b49ae410386ba",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        133.0,
                        81.0
                    ],
                    [
                        133.0,
                        103.3
                    ],
                    [
                        177.6,
                        103.3
                    ],
                    [
                        177.6,
                        81.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.77543,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "1392",
        "type": "Header"
    },
    {
        "element_id": "d2ffafbe1842a67a0a708c7869b75073",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        935.9,
                        82.6
                    ],
                    [
                        935.9,
                        102.2
                    ],
                    [
                        1564.0,
                        102.2
                    ],
                    [
                        1564.0,
                        82.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.86127,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "IEEE TRANSACTIONS ON SMART GRID, VOL. 12, NO. 2, MARCH 2021",
        "type": "Header"
    },
    {
        "element_id": "4204f019ea0c2b2767c0f2efccdedfac",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        185.8,
                        148.5
                    ],
                    [
                        185.8,
                        363.1
                    ],
                    [
                        788.1,
                        363.1
                    ],
                    [
                        788.1,
                        148.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88202,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "= B| (ri + yi Vn(sis) \u2014 Vz(5) = Elry + v4 Va(sig)] + Ve OZ) = B\u0130 (ry + v9 Vasi) \u2014 El + \"Val si)]) IF] = varlrij yasi Arl",
        "type": "Formula"
    },
    {
        "element_id": "a39766ddd4d35568797c1fe73cb79a37",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        159.3
                    ],
                    [
                        866.6,
                        286.6
                    ],
                    [
                        1566.7,
                        286.6
                    ],
                    [
                        1566.7,
                        159.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9397,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "Noting that Assumption 1 is dif\ufb01cult to implement in prac- tice, we use a small threshold \u03b4, as shown in Algorithm 2, to determine the accuracy of policy evaluation. Therefore, Algorithm 2 converges to a near-optimal policy in practice.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a341df7073d9019cfdbaca2487c8aff7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1094.6,
                        334.1
                    ],
                    [
                        1094.6,
                        361.8
                    ],
                    [
                        1336.3,
                        361.8
                    ],
                    [
                        1336.3,
                        334.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "ACKNOWLEDGMENT",
        "type": "Title"
    },
    {
        "element_id": "fb21c14810e7a8ce7af3e3e49c3c7caf",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        384.3
                    ],
                    [
                        136.0,
                        414.7
                    ],
                    [
                        786.3,
                        414.7
                    ],
                    [
                        786.3,
                        384.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.88445,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13,
            "parent_id": "a341df7073d9019cfdbaca2487c8aff7"
        },
        "text": "which, due to the fact that rij is bounded, clearly veri\ufb01es",
        "type": "NarrativeText"
    },
    {
        "element_id": "9110b6c8b3834d6064b0eda24eb79149",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        376.0
                    ],
                    [
                        866.6,
                        436.9
                    ],
                    [
                        1564.0,
                        436.9
                    ],
                    [
                        1564.0,
                        376.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92206,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13,
            "parent_id": "a341df7073d9019cfdbaca2487c8aff7"
        },
        "text": "The authors thanks for the support of data source from Didi Chuxing GAIA Initiative.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ff23b16eba56061c40e886a397964649",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        289.3,
                        439.2
                    ],
                    [
                        289.3,
                        493.2
                    ],
                    [
                        659.4,
                        493.2
                    ],
                    [
                        659.4,
                        439.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.78011,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "varlFy(s)|Fnl < K(1 + Nesli)",
        "type": "Formula"
    },
    {
        "element_id": "55490c49039dd9108c086b568e43526f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        134.7,
                        509.2
                    ],
                    [
                        134.7,
                        536.8
                    ],
                    [
                        374.9,
                        536.8
                    ],
                    [
                        374.9,
                        509.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.84328,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "for some constant K.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f2a10065f9e125691d348d17d5ff4240",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        536.4
                    ],
                    [
                        163.7,
                        572.8
                    ],
                    [
                        833.4,
                        572.8
                    ],
                    [
                        833.4,
                        536.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "Then, by Lemma 1, \u00a9, converges to zero w.p.1, i.e., V,(s)",
        "type": "NarrativeText"
    },
    {
        "element_id": "1808fcf4899ab40aae1ef0de88e11bde",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        547.7
                    ],
                    [
                        136.0,
                        603.2
                    ],
                    [
                        832.8,
                        603.2
                    ],
                    [
                        832.8,
                        547.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89291,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "converges to V\u03c0 (s) w.p.1.",
        "type": "NarrativeText"
    },
    {
        "element_id": "0b6ddb92333502e04848a986971a2028",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        163.7,
                        608.8
                    ],
                    [
                        163.7,
                        636.5
                    ],
                    [
                        732.1,
                        636.5
                    ],
                    [
                        732.1,
                        608.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.73926,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "We \ufb01nally prove the convergence of Algorithm 2:",
        "type": "NarrativeText"
    },
    {
        "element_id": "4884976ceefea29e36f63d018db5266d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        642.0
                    ],
                    [
                        136.0,
                        702.9
                    ],
                    [
                        835.5,
                        702.9
                    ],
                    [
                        835.5,
                        642.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90552,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "Theorem 2: Algorithm 2 converges to an optimal policy under Assumptions 1, 2, and 3.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9c034f82a5c9a0442f4948bbe321c9e5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1137.8,
                        484.4
                    ],
                    [
                        1137.8,
                        512.1
                    ],
                    [
                        1293.0,
                        512.1
                    ],
                    [
                        1293.0,
                        484.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "REFERENCES",
        "type": "Title"
    },
    {
        "element_id": "00cfcda433e576de7b3800e81e4c92de",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.6,
                        530.4
                    ],
                    [
                        877.6,
                        627.3
                    ],
                    [
                        1564.0,
                        627.3
                    ],
                    [
                        1564.0,
                        530.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93188,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13,
            "parent_id": "9c034f82a5c9a0442f4948bbe321c9e5"
        },
        "text": "[1] F. Rossi, R. Iglesias, M. Alizadeh, and M. Pavone, \u201cOn the interaction between autonomous mobility-on-demand systems and the power network: Models and coordination algorithms,\u201d IEEE Trans. Control Netw. Syst., vol. 7, no. 1, pp. 384\u2013397, Jan. 2019.",
        "type": "ListItem"
    },
    {
        "element_id": "fa7a7480765214b3617c651b9cfcc83f",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.7,
                        630.4
                    ],
                    [
                        877.7,
                        702.4
                    ],
                    [
                        1564.0,
                        702.4
                    ],
                    [
                        1564.0,
                        630.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92253,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13,
            "parent_id": "9c034f82a5c9a0442f4948bbe321c9e5"
        },
        "text": "[2] R. Zhang, F. Rossi, and M. Pavone, \u201cModel predictive control of autonomous mobility-on-demand systems,\u201d in Proc. IEEE Int. Conf. Robot. Autom. (ICRA), 2016, pp. 1382\u20131389.",
        "type": "ListItem"
    },
    {
        "element_id": "441faacc68acb38f24e85d6061ec67f3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        708.4
                    ],
                    [
                        136.0,
                        904.8
                    ],
                    [
                        835.2,
                        904.8
                    ],
                    [
                        835.2,
                        708.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.94795,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13,
            "parent_id": "9c034f82a5c9a0442f4948bbe321c9e5"
        },
        "text": "Proof: The goal of the joint optimization problem should be \ufb01nding the optimal policy to maximize the expected total return of EV \ufb02eet, i.e., state value V\u03c0 (s). According to Lemma 2, maximizing E[rt + \u03b3 V\u03c0 (st+1)|s, a] can achieve non-decreasing V\u03c0 (s), and we decompose maxa E[rt + \u03b3 V\u03c0 (st+1)|s, a] as follows:",
        "type": "NarrativeText"
    },
    {
        "element_id": "7a8e072cc7c601de0910eb92f2d7b6e3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        237.5,
                        925.6
                    ],
                    [
                        237.5,
                        974.7
                    ],
                    [
                        833.4,
                        974.7
                    ],
                    [
                        833.4,
                        925.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72632,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "E rt + \u03b3 V\u03c0 (st+1)|s, a max a (19a)",
        "type": "Formula"
    },
    {
        "element_id": "af9ca3ac1dd7936ea3005a828114edc8",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        259.0,
                        978.2
                    ],
                    [
                        259.0,
                        1056.7
                    ],
                    [
                        833.4,
                        1056.7
                    ],
                    [
                        833.4,
                        978.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.79399,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "= max E ri,t + \u03b3 V\u03c0 si,t+1 a i\u2208I+ g g |si, ai (19b)",
        "type": "Formula"
    },
    {
        "element_id": "f8dedc0a855bb7c2cf0cdb59be32de06",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        259.0,
                        1066.8
                    ],
                    [
                        259.0,
                        1142.8
                    ],
                    [
                        833.4,
                        1142.8
                    ],
                    [
                        833.4,
                        1066.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.72898,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "ri,t + \u03b3 V\u03c0 = E si,t+1 max ag i\u2208I+ g g |si, ai (19c)",
        "type": "Formula"
    },
    {
        "element_id": "651082b1db1ef2742fb1301ffe5daaeb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        258.4,
                        1155.2
                    ],
                    [
                        258.4,
                        1312.1
                    ],
                    [
                        833.4,
                        1312.1
                    ],
                    [
                        833.4,
                        1155.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.8194,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "= = max X Eli + \u00a5 Vie (Sir41) 15%. ai] = XI Vit ty Va (si, ij) ieT, 8 ieT; (19d)",
        "type": "Formula"
    },
    {
        "element_id": "5dd031ae79d7324df23b62aadf8aea08",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.7,
                        705.5
                    ],
                    [
                        877.7,
                        802.3
                    ],
                    [
                        1564.0,
                        802.3
                    ],
                    [
                        1564.0,
                        705.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93419,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[3] L. Duan, Y. Wei, J. Zhang, and Y. Xia, \u201cCentralized and decentralized autonomous dispatching strategy for dynamic autonomous taxi opera- tion in hybrid request mode,\u201d Transp. Res. C Emerg. Technol., vol. 111, pp. 397\u2013420, Jan. 2020.",
        "type": "ListItem"
    },
    {
        "element_id": "b21f1d78bd2eb5463ef15dcc1e91ebbc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.7,
                        805.4
                    ],
                    [
                        877.7,
                        877.4
                    ],
                    [
                        1564.0,
                        877.4
                    ],
                    [
                        1564.0,
                        805.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92863,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[4] M. Tsao, R. Iglesias, and M. Pavone, \u201cStochastic model predictive con- trol for autonomous mobility on demand,\u201d in Proc. IEEE 21st Int. Conf. Intell. Transport. Syst. (ITSC), 2018, pp. 3941\u20133948.",
        "type": "ListItem"
    },
    {
        "element_id": "d9df5136763a75d525a85f1d8bc280dc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.7,
                        880.5
                    ],
                    [
                        877.7,
                        927.5
                    ],
                    [
                        1564.0,
                        927.5
                    ],
                    [
                        1564.0,
                        880.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90662,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[5] V. Mnih et al., \u201cHuman-level control through deep reinforcement learning,\u201d Nature, vol. 518, no. 7540, pp. 529\u2013533, 2015.",
        "type": "ListItem"
    },
    {
        "element_id": "b9af04eb13732f2776238c27e5832557",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.7,
                        930.7
                    ],
                    [
                        877.7,
                        977.7
                    ],
                    [
                        1564.4,
                        977.7
                    ],
                    [
                        1564.4,
                        930.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91961,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[6] D. Silver et al., \u201cMastering the game of go with deep neural networks and tree search,\u201d Nature, vol. 529, no. 7587, p. 484, 2016.",
        "type": "ListItem"
    },
    {
        "element_id": "9f872c9d6eeba3852256976febb7a13c",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.7,
                        980.8
                    ],
                    [
                        877.7,
                        1027.8
                    ],
                    [
                        1564.0,
                        1027.8
                    ],
                    [
                        1564.0,
                        980.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9119,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[7] D. Silver et al., \u201cMastering the game of go without human knowledge,\u201d Nature, vol. 550, no. 7676, pp. 354\u2013359, 2017.",
        "type": "ListItem"
    },
    {
        "element_id": "6f52a6a8cfe7f35cad2f0717250d0871",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.6,
                        1031.0
                    ],
                    [
                        877.6,
                        1102.9
                    ],
                    [
                        1564.5,
                        1102.9
                    ],
                    [
                        1564.5,
                        1031.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92511,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[8] Z. Xu et al., \u201cLarge-scale order dispatch in on-demand ride-hailing plat- forms: A learning and planning approach,\u201d in Proc. 24th ACM SIGKDD Int. Conf. Knowl. Disc. Data Min., 2018, pp. 905\u2013913.",
        "type": "ListItem"
    },
    {
        "element_id": "ffc846a0d76f30db93681a269108bd3d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        877.7,
                        1106.0
                    ],
                    [
                        877.7,
                        1153.1
                    ],
                    [
                        1564.1,
                        1153.1
                    ],
                    [
                        1564.1,
                        1106.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90517,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[9] Data Source: Didi Chuxing GAIA Initiative. Accessed: Nov. 17, 2019. [Online]. Available: https://gaia.didichuxing.com",
        "type": "ListItem"
    },
    {
        "element_id": "8ad0d9abd18fb7664020792d495ab4d3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1156.2
                    ],
                    [
                        866.6,
                        1228.1
                    ],
                    [
                        1564.0,
                        1228.1
                    ],
                    [
                        1564.0,
                        1156.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.924,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[10] J. Jin et al., \u201cCORIDE: Joint order dispatching and \ufb02eet management for multi-scale ride-hailing platforms,\u201d in Proc. 28th ACM Int. Conf. Inf. Knowl. Manag., 2019, pp. 1983\u20131992.",
        "type": "ListItem"
    },
    {
        "element_id": "8dd3cd3d905efab6fab47afd7d66c894",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1231.2
                    ],
                    [
                        866.6,
                        1328.1
                    ],
                    [
                        1564.8,
                        1328.1
                    ],
                    [
                        1564.8,
                        1231.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9327,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[11] J. Shi, Y. Gao, W. Wang, N. Yu, and P. A. Ioannou, \u201cOperating electric vehicle \ufb02eet for ride-hailing services with reinforcement learn- ing,\u201d IEEE Trans. Intell. Transp. Syst., early access, Oct. 21, 2019, doi: 10.1109/TITS.2019.2947408.",
        "type": "ListItem"
    },
    {
        "element_id": "224c931a0ebe5bb877953dc1a71cbbc3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1329.2
                    ],
                    [
                        136.0,
                        1366.3
                    ],
                    [
                        291.7,
                        1366.3
                    ],
                    [
                        291.7,
                        1329.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "where i \u2208 I\u2212",
        "type": "NarrativeText"
    },
    {
        "element_id": "86ffee6aef0fc915df6c2cc87b57c7c2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1338.1
                    ],
                    [
                        136.0,
                        1820.2
                    ],
                    [
                        834.6,
                        1820.2
                    ],
                    [
                        834.6,
                        1338.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9492,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "where i e Z, denotes the set of unavailable EVs (in service or charging) in grid g. Based on Assumptions 2 and 3, we can rewrite (19a) as (19b). Since only available action for each EV i \u20ac Zz is to continue to execute its current dispatch, we can decompose (19c) into (19d), and only need to maximize the first item of (19d). For the same reason, deciding the action of EV i \u20ac TZ, at the next time step is equivalent to deciding which dispatch the EV will perform next, ice., maXa, Lier, Elri, 4 Vx (Sit+1)Ii, Gi] = maxa, Diez, Elrij + Y\u0130V Gsi)lsi, a. In the current scheduling problem, the reward rj and th new state sj obtained after taking action a; can be deter- mined in advance, which means that the expected value is sti equal to itself, ie., maxa, Diet, E[ry + yO V! (sipsi, ai] = maxa, ier, [rg V\u0130VE Gi). ie I",
        "type": "NarrativeText"
    },
    {
        "element_id": "188d2fbfe0caa8b9fd0074e2836e9fd0",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1331.2
                    ],
                    [
                        866.6,
                        1403.1
                    ],
                    [
                        1564.0,
                        1403.1
                    ],
                    [
                        1564.0,
                        1331.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93429,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[12] X. Tang et al., \u201cA deep value-network based approach for multi-driver order dispatching,\u201d in Proc. 25th ACM SIGKDD Int. Conf. Knowl. Disc. Data Min., 2019, pp. 1780\u20131790.",
        "type": "ListItem"
    },
    {
        "element_id": "b8dbc7cfc0cb6deedf3ec93f0dda1fc6",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1406.2
                    ],
                    [
                        866.6,
                        1478.2
                    ],
                    [
                        1564.0,
                        1478.2
                    ],
                    [
                        1564.0,
                        1406.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93334,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[13] M. Li et al., \u201cEf\ufb01cient ridesharing order dispatching with mean \ufb01eld multi-agent reinforcement learning,\u201d in Proc. World Wide Web Conf., 2019, pp. 983\u2013994.",
        "type": "ListItem"
    },
    {
        "element_id": "42385f00172815fb22888c1e7fc2719a",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1481.3
                    ],
                    [
                        866.6,
                        1528.4
                    ],
                    [
                        1564.0,
                        1528.4
                    ],
                    [
                        1564.0,
                        1481.3
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91309,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[14] J. Munkres, \u201cAlgorithms for the assignment and transportation prob- lems,\u201d J. Soc. Ind. Appl. Math., vol. 5, no. 1, pp. 32\u201338, 1957.",
        "type": "ListItem"
    },
    {
        "element_id": "250a6a13622b9ee6ba26d14aaa7ca00e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1531.4
                    ],
                    [
                        866.6,
                        1603.4
                    ],
                    [
                        1564.0,
                        1603.4
                    ],
                    [
                        1564.0,
                        1531.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93364,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[15] Y. Yang, R. Luo, M. Li, M. Zhou, W. Zhang, and J. Wang, \u201cMean \ufb01eld multi-agent reinforcement learning,\u201d 2018. [Online]. Available: arXiv:1802.05438.",
        "type": "ListItem"
    },
    {
        "element_id": "c44ff76b8b6f7c9170feca62f61460dc",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1606.5
                    ],
                    [
                        866.6,
                        1678.5
                    ],
                    [
                        1564.0,
                        1678.5
                    ],
                    [
                        1564.0,
                        1606.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93483,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[16] K. Lin, R. Zhao, Z. Xu, and J. Zhou, \u201cEf\ufb01cient large-scale \ufb02eet manage- ment via multi-agent deep reinforcement learning,\u201d in Proc. 24th ACM SIGKDD Int. Conf. Knowl. Disc. Data Min., 2018, pp. 1774\u20131783.",
        "type": "ListItem"
    },
    {
        "element_id": "7f91d6e8944e708239d95eac246a000b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1681.6
                    ],
                    [
                        866.6,
                        1778.4
                    ],
                    [
                        1565.0,
                        1778.4
                    ],
                    [
                        1565.0,
                        1681.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93586,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[17] S. Vandael, B. Claessens, D. Ernst, T. Holvoet, and G. Deconinck, \u201cReinforcement learning of heuristic EV \ufb02eet charging in a day- ahead electricity market,\u201d IEEE Trans. Smart Grid, vol. 6, no. 4, pp. 1795\u20131805, Mar. 2015.",
        "type": "ListItem"
    },
    {
        "element_id": "2ba25fed7f578bb8d09fd390174ec590",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1809.9
                    ],
                    [
                        136.0,
                        2079.9
                    ],
                    [
                        833.4,
                        2079.9
                    ],
                    [
                        833.4,
                        1809.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95081,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "In summary, maximizing Lier, [rig + yi vi 5, (Sij)] for each grid is equivalent to maximizing Elr, + yVx(s;+1)ls, al. According to Lemma 2, we can conclude that for all s \u20ac S, n'(s) = Vier, [rg + y\u00f6\u00fcvi (sil, then Vz > V,. Policy 2\u2019 is guaranteed to be a strict improvement over 7 (unless 7 is already optimal). Because a finite MDP has only a finite num- ber of policies [24], Algorithm 2 must converge to an optimal policy in a finite number of iterations.",
        "type": "NarrativeText"
    },
    {
        "element_id": "0f311d3e8eb24f9e2f4ca35f3de7e9eb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1781.5
                    ],
                    [
                        866.6,
                        1878.4
                    ],
                    [
                        1564.9,
                        1878.4
                    ],
                    [
                        1564.9,
                        1781.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.935,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[18] T. Ding, Z. Zeng, J. Bai, B. Qin, Y. Yang, and M. Shahidehpour, \u201cOptimal electric vehicle charging strategy with Markov decision pro- cess and reinforcement learning technique,\u201d IEEE Trans. Ind. Appl., vol. 56, no. 5, pp. 5811\u20135823, Sep./Oct. 2020.",
        "type": "ListItem"
    },
    {
        "element_id": "c892832cd26c661b9df6a022b1f593e3",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1881.5
                    ],
                    [
                        866.6,
                        1953.5
                    ],
                    [
                        1564.4,
                        1953.5
                    ],
                    [
                        1564.4,
                        1881.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93081,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[19] Z. Wan, H. Li, H. He, and D. Prokhorov, \u201cModel-free real-time EV charging scheduling based on deep reinforcement learning,\u201d IEEE Trans. Smart Grid, vol. 10, no. 5, pp. 5246\u20135257, Nov. 2018.",
        "type": "ListItem"
    },
    {
        "element_id": "03c221abf82b571f2348e76002677600",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1956.6
                    ],
                    [
                        866.6,
                        2028.5
                    ],
                    [
                        1565.1,
                        2028.5
                    ],
                    [
                        1565.1,
                        1956.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93207,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[20] B. Turan, R. Pedarsani, and M. Alizadeh, \u201cDynamic pricing and man- agement for electric autonomous mobility on demand systems using reinforcement learning,\u201d 2019. [Online]. Available: arXiv:1909.06962.",
        "type": "ListItem"
    },
    {
        "element_id": "60ead87872aaa311e0e6d3575c580c12",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        2030.9
                    ],
                    [
                        866.6,
                        2078.7
                    ],
                    [
                        1564.0,
                        2078.7
                    ],
                    [
                        1564.0,
                        2030.9
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.89436,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "[21] T. P. Lillicrap et al., \u201cContinuous control with deep reinforcement learning,\u201d 2015. [Online]. Available: arXiv:1509.02971.",
        "type": "ListItem"
    },
    {
        "element_id": "dd6a478b105d44ed9805901fa01a7a3d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        144.8,
                        2122.5
                    ],
                    [
                        144.8,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.7786,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 13
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ab9a1ddd5ccdea09b8372abe85e172e1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        82.6
                    ],
                    [
                        136.0,
                        102.1
                    ],
                    [
                        1126.3,
                        102.1
                    ],
                    [
                        1126.3,
                        82.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80808,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "LIANG et al.: MOBILITY-AWARE CHARGING SCHEDULING FOR SHARED ON-DEMAND EV FLEET USING DRL",
        "type": "Header"
    },
    {
        "element_id": "8f587d01c772e29ab7fd97b3616e32e5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1522.4,
                        80.7
                    ],
                    [
                        1522.4,
                        103.6
                    ],
                    [
                        1566.0,
                        103.6
                    ],
                    [
                        1566.0,
                        80.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.80257,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "1393",
        "type": "Header"
    },
    {
        "element_id": "41f7c9985483a5214db6bb7caa1749aa",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        163.7
                    ],
                    [
                        136.0,
                        235.6
                    ],
                    [
                        833.7,
                        235.6
                    ],
                    [
                        833.7,
                        163.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93332,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14,
            "parent_id": "8f587d01c772e29ab7fd97b3616e32e5"
        },
        "text": "[22] T. Haarnoja, A. Zhou, P. Abbeel, and S. Levine, \u201cSoft actor\u2013critic: Off- policy maximum entropy deep reinforcement learning with a stochastic actor,\u201d 2018. [Online]. Available: arXiv:1801.01290.",
        "type": "ListItem"
    },
    {
        "element_id": "341884d51db42f560768a85a2a132f7e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        238.4
                    ],
                    [
                        136.0,
                        285.4
                    ],
                    [
                        835.4,
                        285.4
                    ],
                    [
                        835.4,
                        238.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90852,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14,
            "parent_id": "8f587d01c772e29ab7fd97b3616e32e5"
        },
        "text": "[23] M. L. Littman, \u201cMarkov games as a framework for multi-agent rein- forcement learning,\u201d in Proc. Mach. Learn., 1994, pp. 157\u2013163.",
        "type": "ListItem"
    },
    {
        "element_id": "43bf05b4c5f9366f6733b28679d1cb1e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        288.2
                    ],
                    [
                        136.0,
                        335.4
                    ],
                    [
                        838.8,
                        335.4
                    ],
                    [
                        838.8,
                        288.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91428,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14,
            "parent_id": "8f587d01c772e29ab7fd97b3616e32e5"
        },
        "text": "[24] R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction. Cambridge, MA, USA: MIT Press, 2018.",
        "type": "ListItem"
    },
    {
        "element_id": "075b07b91569c5bd45993cbebe67e844",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        338.0
                    ],
                    [
                        136.0,
                        409.9
                    ],
                    [
                        840.3,
                        409.9
                    ],
                    [
                        840.3,
                        338.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92856,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14,
            "parent_id": "8f587d01c772e29ab7fd97b3616e32e5"
        },
        "text": "[25] C. P. Birch, S. P. Oom, and J. A. Beecham, \u201cRectangular and hexagonal grids used for observation, experiment and simulation in ecology,\u201d Ecol. Model., vol. 206, nos. 3\u20134, pp. 347\u2013359, 2007.",
        "type": "ListItem"
    },
    {
        "element_id": "a9e1c2891c41656f7a7b7a3dd7e54ec2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        412.7
                    ],
                    [
                        136.0,
                        484.7
                    ],
                    [
                        838.5,
                        484.7
                    ],
                    [
                        838.5,
                        412.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92779,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14,
            "parent_id": "8f587d01c772e29ab7fd97b3616e32e5"
        },
        "text": "[26] J. Ke et al., \u201cHexagon-based convolutional neural network for supply- demand forecasting of ride-sourcing services,\u201d IEEE Trans. Intell. Transp. Syst., vol. 20, no. 11, pp. 4160\u20134173, Dec. 2018.",
        "type": "ListItem"
    },
    {
        "element_id": "0ede5a51fc2617113d59c9076f8f3851",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        166.6
                    ],
                    [
                        866.6,
                        416.6
                    ],
                    [
                        1066.6,
                        416.6
                    ],
                    [
                        1066.6,
                        166.6
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-14-17.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "5fd3e8298994b319205ee2b1870025d9",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1088.8,
                        163.7
                    ],
                    [
                        1088.8,
                        310.3
                    ],
                    [
                        1575.2,
                        310.3
                    ],
                    [
                        1575.2,
                        163.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9273,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "Zhaohao Ding (Senior Member, IEEE) received the B.S. degree in electrical engineering and the B.A. degree in \ufb01nance from Shandong University, Jinan, China, in 2010, and the Ph.D. degree in elec- trical engineering from the University of Texas at Arlington, Arlington, TX, USA, in 2015.",
        "type": "NarrativeText"
    },
    {
        "element_id": "603258effec06fe4f44cc4379d1cfbb5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1084.7,
                        313.1
                    ],
                    [
                        1084.7,
                        434.8
                    ],
                    [
                        1575.9,
                        434.8
                    ],
                    [
                        1575.9,
                        313.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92922,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "He is currently an Associate Professor with North China Electric Power University, Beijing, China. His research interests include power system planning and operation, power market, and electric transportation system.",
        "type": "NarrativeText"
    },
    {
        "element_id": "78a0a21293084e7283d87f0136e8305e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        487.4
                    ],
                    [
                        136.0,
                        559.4
                    ],
                    [
                        837.9,
                        559.4
                    ],
                    [
                        837.9,
                        487.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93262,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[27] R. S. Sutton, D. Precup, and S. Singh, \u201cBetween MDPS and semi- MDPS: A framework for temporal abstraction in reinforcement learn- ing,\u201d Artif. Intell., vol. 112, nos. 1\u20132, pp. 181\u2013211, 1999.",
        "type": "ListItem"
    },
    {
        "element_id": "0e725f08fea42f96e439af45e7cd83f4",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        562.2
                    ],
                    [
                        136.0,
                        609.9
                    ],
                    [
                        836.0,
                        609.9
                    ],
                    [
                        836.0,
                        562.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91255,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[28] R. S. Sutton, \u201cLearning to predict by the methods of temporal differ- ences,\u201d Mach. Learn., vol. 3, no. 1, pp. 9\u201344, 1988.",
        "type": "ListItem"
    },
    {
        "element_id": "e5bbebf013cbfcc3482bca7bbfe84393",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        612.0
                    ],
                    [
                        136.0,
                        683.9
                    ],
                    [
                        837.9,
                        683.9
                    ],
                    [
                        837.9,
                        612.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93109,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[29] L.-J. Lin, \u201cReinforcement learning for robots using neural networks,\u201d Dept. School Comput. Sci., Carnegie\u2013Mellon Univ., Pittsburgh, PA, USA, Rep. CMU-CS-93-103, 1993.",
        "type": "ListItem"
    },
    {
        "element_id": "0fdd915a33428d6da42d1702ec4a4da1",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        686.7
                    ],
                    [
                        136.0,
                        758.6
                    ],
                    [
                        836.3,
                        758.6
                    ],
                    [
                        836.3,
                        686.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93566,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[30] J. Tsitsiklis and B. Van Roy, \u201cAn analysis of temporal-difference learning with function approximationtechnical,\u201d Lab. Inf. Decis. Syst., Massachusetts Inst. Technol., Rep. LIDS-P-2322, 1996.",
        "type": "ListItem"
    },
    {
        "element_id": "154f6b059f5958861cac3fd118ff192e",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        761.4
                    ],
                    [
                        136.0,
                        858.3
                    ],
                    [
                        837.5,
                        858.3
                    ],
                    [
                        837.5,
                        761.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93768,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[31] Y. Liang, C. Guo, Z. Ding, and H. Hua, \u201cAgent-based modeling in electricity market using deep deterministic policy gradient algo- rithm,\u201d IEEE Trans. Power Syst., early access, Jun. 2, 2020, doi: 10.1109/TPWRS.2020.2999536.",
        "type": "ListItem"
    },
    {
        "element_id": "36c1884a0df42d708a834b4747190a57",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        861.0
                    ],
                    [
                        136.0,
                        933.0
                    ],
                    [
                        834.8,
                        933.0
                    ],
                    [
                        834.8,
                        861.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93467,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[32] H. Lee, M. Girnyk, and J. Jeong, \u201cDeep reinforcement learning approach to MIMO precoding problem: Optimality and robustness,\u201d 2020. [Online]. Available: arXiv:2006.16646.",
        "type": "ListItem"
    },
    {
        "element_id": "8dc26eb0cb2eed2c650d856a3fabaa94",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        935.7
                    ],
                    [
                        136.0,
                        982.8
                    ],
                    [
                        833.4,
                        982.8
                    ],
                    [
                        833.4,
                        935.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91842,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[33] PJM Market Data. Accessed: Nov. 25, 2019. [Online]. Available: https://www.pjm.com/",
        "type": "ListItem"
    },
    {
        "element_id": "a5c08f6d20e2c0025e5dfdad049a9ca2",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        985.5
                    ],
                    [
                        136.0,
                        1032.6
                    ],
                    [
                        833.4,
                        1032.6
                    ],
                    [
                        833.4,
                        985.5
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91969,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[34] X. Glorot, A. Bordes, and Y. Bengio, \u201cDeep sparse recti\ufb01er neural networks,\u201d in Proc. 14th Int. Conf. Artif. Intell. Stat., 2011, pp. 315\u2013323.",
        "type": "ListItem"
    },
    {
        "element_id": "ecd8b82dcb79a544d70a4fb555b49481",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1035.4
                    ],
                    [
                        136.0,
                        1107.3
                    ],
                    [
                        833.8,
                        1107.3
                    ],
                    [
                        833.8,
                        1035.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93735,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[35] D. P. Kingma and J. Ba, \u201cAdam: A method for stochastic optimization,\u201d in Proc. 3rd Int. Conf. Learn. Rep. (ICLR), San Diego, CA, USA, May 2015, p. 6.",
        "type": "ListItem"
    },
    {
        "element_id": "5f2d7e28430b84888032479b07e8a847",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1110.1
                    ],
                    [
                        136.0,
                        1132.2
                    ],
                    [
                        753.7,
                        1132.2
                    ],
                    [
                        753.7,
                        1110.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.87261,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[36] (2019). Gurobi. [Online]. Available: https://www.gurobi.com/",
        "type": "ListItem"
    },
    {
        "element_id": "3c97f9e89194bf3fc019c757387d1855",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1135.0
                    ],
                    [
                        136.0,
                        1206.9
                    ],
                    [
                        838.0,
                        1206.9
                    ],
                    [
                        838.0,
                        1135.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92856,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[37] A. Paszke et al., \u201cPytorch: An imperative style, high-performance deep learning library,\u201d in Proc. Adv. Neural Inf. Process. Syst., 2019, pp. 8026\u20138037.",
        "type": "ListItem"
    },
    {
        "element_id": "33ea9e50452b5cbbbd344e0cb8e44ac4",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1209.7
                    ],
                    [
                        136.0,
                        1281.7
                    ],
                    [
                        833.4,
                        1281.7
                    ],
                    [
                        833.4,
                        1209.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9339,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[38] V. Fran\u00e7ois-Lavet, R. Fonteneau, and D. Ernst, \u201cHow to discount deep reinforcement learning: Towards new dynamic strategies,\u201d 2015. [Online]. Available: arXiv:1512.02011.",
        "type": "ListItem"
    },
    {
        "element_id": "0efcb94237a7bf46f063f680085998d0",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        861.0
                    ],
                    [
                        866.6,
                        1306.6
                    ],
                    [
                        1566.0,
                        1306.6
                    ],
                    [
                        1566.0,
                        861.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.95329,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "Tao Ding (Senior Member, IEEE) received the B.S.E.E. and M.S.E.E. degrees from Southeast University, Nanjing, China, in 2009 and 2012, respectively, and the Ph.D. degree from Tsinghua University, Beijing, China, in 2015. From 2013 to 2014, he was a Visiting Scholar with the Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, TN, USA. He is currently an Associate Professor with the State Key Laboratory of Electrical Insulation and Power Equipment, School of Electrical Engineering, Xi\u2019an Jiaotong University. He has published more than 60 technical papers and authored by \u201cSpringer Theses\u201d recognizing outstanding Ph.D. research around the world and across the physical sciences\u2014Power System Operation with Large Scale Stochastic Wind Power Integration. His current research interests include electricity markets, power system economics and optimization meth- ods, and power system planning and reliability evaluation. He received the Excellent Master and Doctoral Dissertation from Southeast University and Tsinghua University, and the Outstanding Graduate Award of Beijing City. He is an Editor of IEEE TRANSACTIONS ON POWER SYSTEMS, IET Generation, Transmission and Distribution, and CSEE Journal of Power and Energy Systems.",
        "type": "NarrativeText"
    },
    {
        "element_id": "1a483966390f10c1bda1ba6669af5ed7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1284.4
                    ],
                    [
                        136.0,
                        1381.3
                    ],
                    [
                        835.1,
                        1381.3
                    ],
                    [
                        835.1,
                        1284.4
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.9384,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[39] D. P. Bertsekas, \u201cWeighted sup-norm contractions in dynamic pro- gramming: A review and some new applications,\u201d Dept. Elect. Eng. Comput. Sci., Massachusetts Inst. Technol., Cambridge, MA, USA, Rep. LIDS-P-2884, 2012.",
        "type": "ListItem"
    },
    {
        "element_id": "d1a5c37856ebe23ff159ad1b4819c782",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1384.1
                    ],
                    [
                        136.0,
                        1456.0
                    ],
                    [
                        833.9,
                        1456.0
                    ],
                    [
                        833.9,
                        1384.1
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93432,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[40] T. Jaakkola, M. I. Jordan, and S. P. Singh, \u201cConvergence of stochastic iterative dynamic programming algorithms,\u201d in Proc. Adv. Neural Inf. Process. Syst., 1994, pp. 703\u2013710.",
        "type": "ListItem"
    },
    {
        "element_id": "9f0ca53b2202aa9df424f76a6c375108",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1458.8
                    ],
                    [
                        136.0,
                        1530.7
                    ],
                    [
                        833.4,
                        1530.7
                    ],
                    [
                        833.4,
                        1458.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.93389,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[41] C. Szepesv\u00e1ri and M. L. Littman, \u201cA uni\ufb01ed analysis of value-function- based reinforcement-learning algorithms,\u201d Neural Comput., vol. 11, no. 8, pp. 2017\u20132060, 1999.",
        "type": "ListItem"
    },
    {
        "element_id": "c881fc2549c9f419f56384a6cbd9e0f5",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1528.7
                    ],
                    [
                        136.0,
                        1580.5
                    ],
                    [
                        833.4,
                        1580.5
                    ],
                    [
                        833.4,
                        1528.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91671,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "[42] T. M. Apostol, \u201cA proof that Euler missed: Evaluating \u03b6 (2) the easy way,\u201d Math. Intell., vol. 5, no. 3, pp. 59\u201360, 1983.",
        "type": "ListItem"
    },
    {
        "element_id": "0cfb4590cd69cb60aa18f2c125bd1a38",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        136.0,
                        1822.2
                    ],
                    [
                        136.0,
                        2072.2
                    ],
                    [
                        336.0,
                        2072.2
                    ],
                    [
                        336.0,
                        1822.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-14-18.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "e03ef44bab9b652c2cebac9ebe20312d",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        359.3,
                        1819.0
                    ],
                    [
                        359.3,
                        1966.0
                    ],
                    [
                        838.4,
                        1966.0
                    ],
                    [
                        838.4,
                        1819.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.92332,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "Yanchang Liang (Student Member, IEEE) received the B.S. degree from the College of Electrical Engineering, North China Electric Power University, Baoding, China, in 2018. He is currently pursuing the M.S. degree with North China Electric Power University, Beijing, China.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d3a4588e9418f12ce3a8af90d2e544f7",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        361.5,
                        1968.7
                    ],
                    [
                        361.5,
                        2065.6
                    ],
                    [
                        839.4,
                        2065.6
                    ],
                    [
                        839.4,
                        1968.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.91937,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "His current research interests include control, optimization, reinforcement learning, with applica- tions to power systems, and electric transportation systems.",
        "type": "NarrativeText"
    },
    {
        "element_id": "68a5b8296f14ebe635dc5c8d12f1ac59",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        1735.7
                    ],
                    [
                        866.6,
                        1985.7
                    ],
                    [
                        1066.6,
                        1985.7
                    ],
                    [
                        1066.6,
                        1735.7
                    ]
                ],
                "system": "PixelSpace"
            },
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "image_path": "/home/msunkur/dev/projects/uol/Module5/midterm/CM3020_Artificial_Intelligence/parta/docs/tmp/tmp_ingest/output/figure-14-19.jpg",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "",
        "type": "Image"
    },
    {
        "element_id": "b3d93c8b2ce4a8fb5a52e2dc02d09885",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        1093.2,
                        1732.8
                    ],
                    [
                        1093.2,
                        2015.4
                    ],
                    [
                        1566.4,
                        2015.4
                    ],
                    [
                        1566.4,
                        1732.8
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.90539,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "Wei-Jen Lee (Fellow, IEEE) received the B.S. and M.S. degrees in electrical engineering from National Taiwan University, Taipei, Taiwan, in 1978 and 1980, respectively, and the Ph.D. degree in elec- trical engineering from the University of Texas at Arlington, Arlington, TX, USA, in 1985. In 1986, he joined the University of Texas at Arlington, where he is currently a Professor with the Department of Electrical Engineering and the Director of the Energy Systems Research Center. He has been involved in research on power \ufb02ow, transient and",
        "type": "NarrativeText"
    },
    {
        "element_id": "9e5960adcfbcf079550348ebdf719efb",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        866.6,
                        2005.0
                    ],
                    [
                        866.6,
                        2078.7
                    ],
                    [
                        1574.1,
                        2078.7
                    ],
                    [
                        1574.1,
                        2005.0
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.51058,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "dynamic stability, voltage stability, short circuit, relay coordination, power quality analysis, renewable energy, and deregulation for utility companies. He is a registered Professional Engineer in the State of Texas.",
        "type": "NarrativeText"
    },
    {
        "element_id": "be65d191c1acf3e65617c1aa23a6f93b",
        "metadata": {
            "coordinates": {
                "layout_height": 2200,
                "layout_width": 1700,
                "points": [
                    [
                        130.6,
                        2122.2
                    ],
                    [
                        130.6,
                        2143.2
                    ],
                    [
                        1555.2,
                        2143.2
                    ],
                    [
                        1555.2,
                        2122.2
                    ]
                ],
                "system": "PixelSpace"
            },
            "detection_class_prob": 0.81868,
            "file_directory": "./uol-docs",
            "filename": "Mobility-Aware_Charging_Scheduling_for_Shared_On-Demand_Electric_Vehicle_Fleet_Using_Deep_Reinforcement_Learning.pdf",
            "languages": [
                "eng",
                "tur"
            ],
            "last_modified": "2024-12-28T23:22:04",
            "page_number": 14
        },
        "text": "Authorized licensed use limited to: University of London: Online Library. Downloaded on December 28,2024 at 23:18:31 UTC from IEEE Xplore. Restrictions apply.",
        "type": "NarrativeText"
    }
]